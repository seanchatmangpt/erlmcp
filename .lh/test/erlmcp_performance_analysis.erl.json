{
    "sourceFile": "test/erlmcp_performance_analysis.erl",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1756188161126,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1756188161126,
            "name": "Commit-0",
            "content": "-module(erlmcp_performance_analysis).\n\n-behaviour(gen_server).\n\n-include_lib(\"common_test/include/ct.hrl\").\n-include_lib(\"eunit/include/eunit.hrl\").\n\n%% API exports\n-export([start_link/0, stop/0,\n         run_throughput_test/3, run_latency_test/3, run_concurrent_test/4,\n         run_stress_test/3, monitor_resources/2, generate_test_data/1,\n         measure_registry_performance/0, optimize_hot_paths/0,\n         profile_message_routing/2, benchmark_ets_operations/0,\n         collect_gc_metrics/1, analyze_memory_patterns/1]).\n\n%% gen_server callbacks\n-export([init/1, handle_call/3, handle_cast/2, handle_info/2, terminate/2,\n         code_change/3]).\n\n%% Performance test records\n-record(perf_config, {\n    target_throughput = 10000 :: pos_integer(),  % Messages per second\n    target_latency_p99 = 1000 :: pos_integer(),  % Microseconds\n    max_memory_growth = 50 :: pos_integer(),     % MB\n    test_duration = 30000 :: pos_integer(),      % Milliseconds\n    sample_interval = 1000 :: pos_integer()     % Milliseconds\n}).\n\n-record(perf_metrics, {\n    throughput = 0 :: non_neg_integer(),\n    latency_samples = [] :: [non_neg_integer()],\n    memory_samples = [] :: [non_neg_integer()],\n    cpu_samples = [] :: [float()],\n    error_count = 0 :: non_neg_integer(),\n    start_time :: integer(),\n    end_time :: integer()\n}).\n\n-record(benchmark_result, {\n    test_name :: atom(),\n    config :: #perf_config{},\n    metrics :: #perf_metrics{},\n    passed :: boolean(),\n    details :: map()\n}).\n\n-record(optimization_result, {\n    optimization :: atom(),\n    before_metrics :: #perf_metrics{},\n    after_metrics :: #perf_metrics{},\n    improvement_percent :: float(),\n    recommendations :: [binary()]\n}).\n\n%% State record\n-record(state, {\n    active_tests = #{} :: #{reference() => {atom(), pid()}},\n    metrics_history = [] :: [#perf_metrics{}],\n    config = #perf_config{} :: #perf_config{},\n    ets_cache_table :: ets:tid() | undefined,\n    optimization_cache = #{} :: #{atom() => #optimization_result{}}\n}).\n\n%%====================================================================\n%% API Functions\n%%====================================================================\n\n-spec start_link() -> {ok, pid()} | {error, term()}.\nstart_link() ->\n    gen_server:start_link({local, ?MODULE}, ?MODULE, [], []).\n\n-spec stop() -> ok.\nstop() ->\n    case whereis(?MODULE) of\n        undefined -> ok;\n        Pid -> gen_server:stop(Pid)\n    end.\n\n%% Comprehensive throughput testing\n-spec run_throughput_test(atom(), pos_integer(), pos_integer()) -> \n    {ok, float()} | {error, term()}.\nrun_throughput_test(Transport, MessageCount, MessageSize) ->\n    gen_server:call(?MODULE, {throughput_test, Transport, MessageCount, MessageSize}, 60000).\n\n%% Advanced latency testing with percentile analysis\n-spec run_latency_test(atom(), pos_integer(), pos_integer()) -> \n    {ok, {float(), float(), float()}} | {error, term()}.\nrun_latency_test(Transport, MessageCount, MessageSize) ->\n    gen_server:call(?MODULE, {latency_test, Transport, MessageCount, MessageSize}, 60000).\n\n%% Concurrent load testing\n-spec run_concurrent_test(atom(), pos_integer(), pos_integer(), pos_integer()) -> \n    {ok, map()} | {error, term()}.\nrun_concurrent_test(Transport, ConnectionCount, MessageCount, MessageSize) ->\n    gen_server:call(?MODULE, \n        {concurrent_test, Transport, ConnectionCount, MessageCount, MessageSize}, 120000).\n\n%% Stress testing with sustained load\n-spec run_stress_test(atom(), pos_integer(), pos_integer()) -> \n    {ok, map()} | {error, term()}.\nrun_stress_test(Transport, Duration, ConcurrentWorkers) ->\n    gen_server:call(?MODULE, {stress_test, Transport, Duration, ConcurrentWorkers}, \n                   Duration + 30000).\n\n%% Resource monitoring\n-spec monitor_resources(pos_integer(), pos_integer()) -> {ok, pid()} | {error, term()}.\nmonitor_resources(Duration, Interval) ->\n    gen_server:call(?MODULE, {monitor_resources, Duration, Interval}).\n\n%% Test data generation\n-spec generate_test_data(pos_integer()) -> binary().\ngenerate_test_data(Size) ->\n    crypto:strong_rand_bytes(Size).\n\n%% Registry performance measurement\n-spec measure_registry_performance() -> {ok, map()} | {error, term()}.\nmeasure_registry_performance() ->\n    gen_server:call(?MODULE, measure_registry_performance, 30000).\n\n%% Hot path optimization\n-spec optimize_hot_paths() -> {ok, [#optimization_result{}]} | {error, term()}.\noptimize_hot_paths() ->\n    gen_server:call(?MODULE, optimize_hot_paths, 60000).\n\n%% Message routing profiling\n-spec profile_message_routing(pos_integer(), pos_integer()) -> {ok, map()} | {error, term()}.\nprofile_message_routing(MessageCount, MessageSize) ->\n    gen_server:call(?MODULE, {profile_routing, MessageCount, MessageSize}, 30000).\n\n%% ETS benchmarking\n-spec benchmark_ets_operations() -> {ok, map()} | {error, term()}.\nbenchmark_ets_operations() ->\n    gen_server:call(?MODULE, benchmark_ets_operations, 30000).\n\n%% GC metrics collection\n-spec collect_gc_metrics(pos_integer()) -> {ok, map()} | {error, term()}.\ncollect_gc_metrics(Duration) ->\n    gen_server:call(?MODULE, {collect_gc_metrics, Duration}).\n\n%% Memory pattern analysis\n-spec analyze_memory_patterns(pos_integer()) -> {ok, map()} | {error, term()}.\nanalyze_memory_patterns(Duration) ->\n    gen_server:call(?MODULE, {analyze_memory_patterns, Duration}).\n\n%%====================================================================\n%% gen_server callbacks\n%%====================================================================\n\ninit([]) ->\n    process_flag(trap_exit, true),\n    \n    % Create ETS table for caching performance data\n    EtsTable = ets:new(perf_cache, [set, private, {keypos, 1}]),\n    \n    % Enable scheduler statistics for CPU monitoring\n    erlang:system_flag(scheduler_wall_time, true),\n    \n    logger:info(\"Performance analysis module started\"),\n    \n    {ok, #state{ets_cache_table = EtsTable}}.\n\nhandle_call({throughput_test, Transport, MessageCount, MessageSize}, _From, State) ->\n    Result = execute_throughput_test(Transport, MessageCount, MessageSize, State),\n    {reply, Result, State};\n\nhandle_call({latency_test, Transport, MessageCount, MessageSize}, _From, State) ->\n    Result = execute_latency_test(Transport, MessageCount, MessageSize, State),\n    {reply, Result, State};\n\nhandle_call({concurrent_test, Transport, ConnectionCount, MessageCount, MessageSize}, \n           _From, State) ->\n    Result = execute_concurrent_test(Transport, ConnectionCount, MessageCount, \n                                   MessageSize, State),\n    {reply, Result, State};\n\nhandle_call({stress_test, Transport, Duration, ConcurrentWorkers}, _From, State) ->\n    Result = execute_stress_test(Transport, Duration, ConcurrentWorkers, State),\n    {reply, Result, State};\n\nhandle_call({monitor_resources, Duration, Interval}, _From, State) ->\n    {ok, Pid} = start_resource_monitor(Duration, Interval),\n    {reply, {ok, Pid}, State};\n\nhandle_call(measure_registry_performance, _From, State) ->\n    Result = measure_registry_performance_impl(State),\n    {reply, Result, State};\n\nhandle_call(optimize_hot_paths, _From, State) ->\n    Result = execute_hot_path_optimizations(State),\n    {reply, Result, State};\n\nhandle_call({profile_routing, MessageCount, MessageSize}, _From, State) ->\n    Result = profile_message_routing_impl(MessageCount, MessageSize, State),\n    {reply, Result, State};\n\nhandle_call(benchmark_ets_operations, _From, State) ->\n    Result = benchmark_ets_operations_impl(State),\n    {reply, Result, State};\n\nhandle_call({collect_gc_metrics, Duration}, _From, State) ->\n    Result = collect_gc_metrics_impl(Duration),\n    {reply, Result, State};\n\nhandle_call({analyze_memory_patterns, Duration}, _From, State) ->\n    Result = analyze_memory_patterns_impl(Duration),\n    {reply, Result, State};\n\nhandle_call(_Request, _From, State) ->\n    {reply, {error, unknown_request}, State}.\n\nhandle_cast({reset_metrics}, State) ->\n    {noreply, State#state{metrics_history = []}};\n\nhandle_cast(_Msg, State) ->\n    {noreply, State}.\n\nhandle_info({'EXIT', Pid, Reason}, State) ->\n    logger:warning(\"Performance test process ~p exited: ~p\", [Pid, Reason]),\n    {noreply, State};\n\nhandle_info(_Info, State) ->\n    {noreply, State}.\n\nterminate(_Reason, State) ->\n    case State#state.ets_cache_table of\n        undefined -> ok;\n        Table -> ets:delete(Table)\n    end,\n    logger:info(\"Performance analysis module terminating\"),\n    ok.\n\ncode_change(_OldVsn, State, _Extra) ->\n    {ok, State}.\n\n%%====================================================================\n%% Internal Implementation Functions\n%%====================================================================\n\n%% Execute comprehensive throughput testing\nexecute_throughput_test(Transport, MessageCount, MessageSize, State) ->\n    Config = State#state.config,\n    TestData = generate_test_data(MessageSize),\n    \n    logger:info(\"Starting throughput test: ~p transport, ~p messages, ~p bytes\",\n               [Transport, MessageCount, MessageSize]),\n    \n    StartTime = erlang:system_time(microsecond),\n    \n    try\n        Results = case Transport of\n            stdio -> run_stdio_throughput(MessageCount, TestData);\n            tcp -> run_tcp_throughput(MessageCount, TestData);\n            http -> run_http_throughput(MessageCount, TestData);\n            _ -> {error, unsupported_transport}\n        end,\n        \n        EndTime = erlang:system_time(microsecond),\n        Duration = EndTime - StartTime,\n        \n        case Results of\n            {ok, ProcessedCount} ->\n                ThroughputBytesPerSec = (ProcessedCount * MessageSize * 1000000) / Duration,\n                \n                logger:info(\"Throughput test completed: ~.2f bytes/sec, ~.2f msg/sec\",\n                           [ThroughputBytesPerSec, (ProcessedCount * 1000000) / Duration]),\n                \n                % Cache results for analysis\n                cache_performance_data(throughput_test, \n                    #{transport => Transport, throughput => ThroughputBytesPerSec,\n                      duration => Duration, message_count => ProcessedCount}, State),\n                      \n                {ok, ThroughputBytesPerSec};\n            Error ->\n                logger:error(\"Throughput test failed: ~p\", [Error]),\n                Error\n        end\n    catch\n        Class:Reason:Stacktrace ->\n            logger:error(\"Throughput test crashed: ~p:~p~n~p\", \n                        [Class, Reason, Stacktrace]),\n            {error, {crash, Class, Reason}}\n    end.\n\n%% Execute latency testing with percentile analysis\nexecute_latency_test(Transport, MessageCount, MessageSize, State) ->\n    TestData = generate_test_data(MessageSize),\n    \n    logger:info(\"Starting latency test: ~p transport, ~p messages, ~p bytes\",\n               [Transport, MessageCount, MessageSize]),\n    \n    LatencySamples = lists:map(fun(_) ->\n        StartTime = erlang:system_time(microsecond),\n        \n        Result = case Transport of\n            stdio -> simulate_stdio_operation(TestData);\n            tcp -> simulate_tcp_operation(TestData);\n            http -> simulate_http_operation(TestData);\n            _ -> {error, unsupported_transport}\n        end,\n        \n        EndTime = erlang:system_time(microsecond),\n        Latency = EndTime - StartTime,\n        \n        case Result of\n            ok -> Latency;\n            {error, _} -> -1  % Mark as error\n        end\n    end, lists:seq(1, MessageCount)),\n    \n    ValidSamples = [L || L <- LatencySamples, L >= 0],\n    \n    case length(ValidSamples) of\n        0 ->\n            {error, no_valid_samples};\n        ValidCount ->\n            SortedSamples = lists:sort(ValidSamples),\n            \n            P50 = percentile(SortedSamples, 50),\n            P95 = percentile(SortedSamples, 95),\n            P99 = percentile(SortedSamples, 99),\n            \n            logger:info(\"Latency test completed: P50=~p μs, P95=~p μs, P99=~p μs\",\n                       [P50, P95, P99]),\n            \n            % Cache latency data\n            cache_performance_data(latency_test, \n                #{transport => Transport, p50 => P50, p95 => P95, p99 => P99,\n                  valid_samples => ValidCount, total_samples => MessageCount}, State),\n                  \n            {ok, {P50, P95, P99}}\n    end.\n\n%% Execute concurrent load testing\nexecute_concurrent_test(Transport, ConnectionCount, MessageCount, MessageSize, State) ->\n    TestData = generate_test_data(MessageSize),\n    \n    logger:info(\"Starting concurrent test: ~p connections, ~p messages each, ~p bytes\",\n               [ConnectionCount, MessageCount, MessageSize]),\n    \n    Parent = self(),\n    StartTime = erlang:system_time(microsecond),\n    \n    % Spawn concurrent workers\n    Workers = lists:map(fun(WorkerId) ->\n        spawn_link(fun() ->\n            WorkerResults = lists:map(fun(_) ->\n                WorkerStartTime = erlang:system_time(microsecond),\n                \n                Result = case Transport of\n                    stdio -> simulate_stdio_operation(TestData);\n                    tcp -> simulate_tcp_operation(TestData);\n                    http -> simulate_http_operation(TestData);\n                    _ -> {error, unsupported_transport}\n                end,\n                \n                WorkerEndTime = erlang:system_time(microsecond),\n                \n                {Result, WorkerEndTime - WorkerStartTime}\n            end, lists:seq(1, MessageCount)),\n            \n            Parent ! {worker_done, WorkerId, WorkerResults}\n        end)\n    end, lists:seq(1, ConnectionCount)),\n    \n    % Collect results from all workers\n    AllResults = collect_worker_results(Workers, ConnectionCount, []),\n    EndTime = erlang:system_time(microsecond),\n    \n    % Analyze results\n    TotalOps = length(AllResults),\n    SuccessfulOps = length([1 || {ok, _} <- AllResults]),\n    SuccessRate = (SuccessfulOps / TotalOps) * 100,\n    \n    Duration = EndTime - StartTime,\n    Throughput = (SuccessfulOps * 1000000) / Duration,\n    \n    Result = #{total_operations => TotalOps,\n              successful_operations => SuccessfulOps,\n              success_rate => SuccessRate,\n              throughput => Throughput,\n              duration_microseconds => Duration},\n    \n    logger:info(\"Concurrent test completed: ~p ops, ~.1f%% success, ~.2f ops/sec\",\n               [TotalOps, SuccessRate, Throughput]),\n    \n    cache_performance_data(concurrent_test, Result#{transport => Transport}, State),\n    \n    {ok, Result}.\n\n%% Execute stress testing with sustained load\nexecute_stress_test(Transport, Duration, ConcurrentWorkers, State) ->\n    logger:info(\"Starting stress test: ~p ms duration, ~p workers\",\n               [Duration, ConcurrentWorkers]),\n    \n    Parent = self(),\n    EndTime = erlang:system_time(millisecond) + Duration,\n    \n    % Start resource monitoring\n    {ok, MonitorPid} = start_resource_monitor(Duration, 1000),\n    \n    % Spawn stress workers\n    Workers = lists:map(fun(WorkerId) ->\n        spawn_link(fun() ->\n            stress_worker_loop(Transport, WorkerId, EndTime, [])\n        end)\n    end, lists:seq(1, ConcurrentWorkers)),\n    \n    % Wait for completion\n    timer:sleep(Duration + 1000),\n    \n    % Collect results\n    WorkerResults = collect_stress_results(Workers, ConcurrentWorkers, []),\n    \n    % Analyze stress test results\n    TotalOps = lists:sum([length(Ops) || Ops <- WorkerResults]),\n    SuccessfulOps = lists:sum([length([1 || {ok, _} <- Ops]) || Ops <- WorkerResults]),\n    \n    OpsPerSecond = (TotalOps * 1000) / Duration,\n    SuccessRate = case TotalOps of\n        0 -> 0.0;\n        _ -> (SuccessfulOps / TotalOps) * 100\n    end,\n    \n    Result = #{operations_per_second => OpsPerSecond,\n              success_rate => SuccessRate,\n              total_operations => TotalOps,\n              duration_ms => Duration,\n              concurrent_workers => ConcurrentWorkers},\n    \n    logger:info(\"Stress test completed: ~.2f ops/sec, ~.1f%% success rate\",\n               [OpsPerSecond, SuccessRate]),\n    \n    cache_performance_data(stress_test, Result#{transport => Transport}, State),\n    \n    {ok, Result}.\n\n%% Registry performance measurement\nmeasure_registry_performance_impl(State) ->\n    logger:info(\"Measuring registry performance\"),\n    \n    % Test registry operations under load\n    TestCases = [\n        {register_operations, fun() -> test_registry_registrations(1000) end},\n        {lookup_operations, fun() -> test_registry_lookups(10000) end},\n        {routing_operations, fun() -> test_registry_routing(5000) end},\n        {concurrent_access, fun() -> test_concurrent_registry_access(10, 1000) end}\n    ],\n    \n    Results = lists:map(fun({TestName, TestFun}) ->\n        StartTime = erlang:system_time(microsecond),\n        TestResult = TestFun(),\n        EndTime = erlang:system_time(microsecond),\n        \n        Duration = EndTime - StartTime,\n        \n        {TestName, #{result => TestResult, duration_microseconds => Duration}}\n    end, TestCases),\n    \n    RegistryStats = #{performance_tests => Results,\n                     timestamp => erlang:system_time(millisecond)},\n    \n    cache_performance_data(registry_performance, RegistryStats, State),\n    \n    {ok, RegistryStats}.\n\n%% Hot path optimization implementation\nexecute_hot_path_optimizations(State) ->\n    logger:info(\"Executing hot path optimizations\"),\n    \n    Optimizations = [\n        {registry_ets_optimization, fun optimize_registry_ets/0},\n        {message_routing_optimization, fun optimize_message_routing/0},\n        {process_pool_optimization, fun optimize_process_pools/0},\n        {memory_allocation_optimization, fun optimize_memory_allocation/0}\n    ],\n    \n    Results = lists:map(fun({OptName, OptFun}) ->\n        logger:info(\"Applying optimization: ~p\", [OptName]),\n        \n        % Measure before\n        BeforeMetrics = collect_baseline_metrics(),\n        \n        try\n            OptResult = OptFun(),\n            \n            % Wait for optimization to take effect\n            timer:sleep(2000),\n            \n            % Measure after\n            AfterMetrics = collect_baseline_metrics(),\n            \n            Improvement = calculate_improvement(BeforeMetrics, AfterMetrics),\n            \n            #optimization_result{\n                optimization = OptName,\n                before_metrics = BeforeMetrics,\n                after_metrics = AfterMetrics,\n                improvement_percent = Improvement,\n                recommendations = generate_recommendations(OptName, Improvement)\n            }\n        catch\n            Class:Reason:Stacktrace ->\n                logger:error(\"Optimization ~p failed: ~p:~p~n~p\", \n                            [OptName, Class, Reason, Stacktrace]),\n                #optimization_result{\n                    optimization = OptName,\n                    before_metrics = BeforeMetrics,\n                    after_metrics = BeforeMetrics,\n                    improvement_percent = 0.0,\n                    recommendations = [<<\"Optimization failed\">>]\n                }\n        end\n    end, Optimizations),\n    \n    % Cache optimization results\n    lists:foreach(fun(OptResult) ->\n        cache_performance_data(optimization_result, OptResult, State)\n    end, Results),\n    \n    {ok, Results}.\n\n%%====================================================================\n%% Performance Test Implementations\n%%====================================================================\n\n%% STDIO transport throughput testing\nrun_stdio_throughput(MessageCount, TestData) ->\n    try\n        % Simulate STDIO operations with minimal delay\n        ProcessedCount = lists:foldl(fun(_, Acc) ->\n            % Simulate message processing\n            timer:sleep(0),  % Yield to scheduler\n            Acc + 1\n        end, 0, lists:seq(1, MessageCount)),\n        \n        {ok, ProcessedCount}\n    catch\n        Class:Reason ->\n            {error, {Class, Reason}}\n    end.\n\n%% TCP transport throughput testing\nrun_tcp_throughput(MessageCount, TestData) ->\n    try\n        % Simulate TCP operations with network delay\n        ProcessedCount = lists:foldl(fun(_, Acc) ->\n            % Simulate network delay\n            timer:sleep(1),\n            Acc + 1\n        end, 0, lists:seq(1, MessageCount)),\n        \n        {ok, ProcessedCount}\n    catch\n        Class:Reason ->\n            {error, {Class, Reason}}\n    end.\n\n%% HTTP transport throughput testing\nrun_http_throughput(MessageCount, TestData) ->\n    try\n        % Simulate HTTP operations with higher latency\n        ProcessedCount = lists:foldl(fun(_, Acc) ->\n            % Simulate HTTP request/response cycle\n            timer:sleep(10),\n            Acc + 1\n        end, 0, lists:seq(1, MessageCount)),\n        \n        {ok, ProcessedCount}\n    catch\n        Class:Reason ->\n            {error, {Class, Reason}}\n    end.\n\n%% Simulate transport operations for latency testing\nsimulate_stdio_operation(_TestData) ->\n    timer:sleep(0),\n    ok.\n\nsimulate_tcp_operation(_TestData) ->\n    timer:sleep(rand:uniform(5)),\n    ok.\n\nsimulate_http_operation(_TestData) ->\n    timer:sleep(rand:uniform(20) + 10),\n    ok.\n\n%% Registry performance testing functions\ntest_registry_registrations(Count) ->\n    try\n        lists:foreach(fun(N) ->\n            ServerId = list_to_atom(\"test_server_\" ++ integer_to_list(N)),\n            ServerPid = spawn(fun() -> timer:sleep(100) end),\n            Config = #{capabilities => undefined, options => #{}},\n            \n            % Test registration performance\n            case erlmcp_registry:register_server(ServerId, ServerPid, Config) of\n                ok -> ok;\n                {error, _} -> error\n            end\n        end, lists:seq(1, Count)),\n        \n        ok\n    catch\n        _:_ -> error\n    end.\n\ntest_registry_lookups(Count) ->\n    try\n        lists:foldl(fun(N, Acc) ->\n            ServerId = list_to_atom(\"test_server_\" ++ integer_to_list(N rem 100 + 1)),\n            \n            case erlmcp_registry:find_server(ServerId) of\n                {ok, _} -> Acc + 1;\n                {error, not_found} -> Acc\n            end\n        end, 0, lists:seq(1, Count))\n    catch\n        _:_ -> 0\n    end.\n\ntest_registry_routing(Count) ->\n    try\n        lists:foreach(fun(N) ->\n            ServerId = list_to_atom(\"test_server_\" ++ integer_to_list(N rem 10 + 1)),\n            TransportId = list_to_atom(\"test_transport_\" ++ integer_to_list(N rem 5 + 1)),\n            Message = generate_test_data(256),\n            \n            % Test routing performance\n            erlmcp_registry:route_to_server(ServerId, TransportId, Message)\n        end, lists:seq(1, Count)),\n        \n        ok\n    catch\n        _:_ -> error\n    end.\n\ntest_concurrent_registry_access(WorkerCount, OpsPerWorker) ->\n    Parent = self(),\n    \n    Workers = lists:map(fun(WorkerId) ->\n        spawn_link(fun() ->\n            Results = lists:map(fun(N) ->\n                ServerId = list_to_atom(\"test_server_\" ++ integer_to_list(N rem 10 + 1)),\n                \n                StartTime = erlang:system_time(microsecond),\n                Result = erlmcp_registry:find_server(ServerId),\n                EndTime = erlang:system_time(microsecond),\n                \n                {Result, EndTime - StartTime}\n            end, lists:seq(1, OpsPerWorker)),\n            \n            Parent ! {worker_done, WorkerId, Results}\n        end)\n    end, lists:seq(1, WorkerCount)),\n    \n    AllResults = collect_worker_results(Workers, WorkerCount, []),\n    \n    SuccessCount = length([1 || {ok, _} <- [Res || {Res, _} <- AllResults]]),\n    AvgLatency = case length(AllResults) of\n        0 -> 0;\n        Total -> lists:sum([Lat || {_, Lat} <- AllResults]) / Total\n    end,\n    \n    #{success_count => SuccessCount, average_latency => AvgLatency}.\n\n%%====================================================================\n%% Optimization Implementations\n%%====================================================================\n\n%% ETS table optimization for registry\noptimize_registry_ets() ->\n    logger:info(\"Optimizing registry ETS tables\"),\n    \n    % These optimizations would be applied to the actual registry module\n    Recommendations = [\n        \"Use ordered_set for sorted lookups\",\n        \"Enable compression for large datasets\",\n        \"Consider partitioned tables for high concurrency\",\n        \"Implement read concurrency optimizations\"\n    ],\n    \n    {ok, Recommendations}.\n\n%% Message routing optimization\noptimize_message_routing() ->\n    logger:info(\"Optimizing message routing paths\"),\n    \n    % These would be actual optimizations to the routing logic\n    Recommendations = [\n        \"Cache routing decisions for frequently used paths\",\n        \"Implement message batching for improved throughput\",\n        \"Use direct process messaging where possible\",\n        \"Optimize message serialization/deserialization\"\n    ],\n    \n    {ok, Recommendations}.\n\n%% Process pool optimization\noptimize_process_pools() ->\n    logger:info(\"Optimizing process pool configurations\"),\n    \n    Recommendations = [\n        \"Adjust pool sizes based on system load\",\n        \"Implement work-stealing between pools\",\n        \"Use process hibernation for idle workers\",\n        \"Optimize process spawn/death cycles\"\n    ],\n    \n    {ok, Recommendations}.\n\n%% Memory allocation optimization\noptimize_memory_allocation() ->\n    logger:info(\"Optimizing memory allocation patterns\"),\n    \n    Recommendations = [\n        \"Pre-allocate frequently used data structures\",\n        \"Implement memory pooling for large messages\",\n        \"Optimize garbage collection settings\",\n        \"Use binary data structures where appropriate\"\n    ],\n    \n    {ok, Recommendations}.\n\n%%====================================================================\n%% Helper Functions\n%%====================================================================\n\n%% Calculate percentiles\npercentile([], _) -> 0;\npercentile(SortedList, Percentile) ->\n    Length = length(SortedList),\n    Index = max(1, min(Length, round(Length * Percentile / 100))),\n    lists:nth(Index, SortedList).\n\n%% Collect worker results\ncollect_worker_results(Workers, Count, Acc) when length(Acc) >= Count ->\n    Acc;\ncollect_worker_results(Workers, Count, Acc) ->\n    receive\n        {worker_done, WorkerId, Results} ->\n            collect_worker_results(Workers, Count, Results ++ Acc)\n    after 30000 ->\n        logger:warning(\"Timeout waiting for worker results\"),\n        Acc\n    end.\n\n%% Collect stress test results\ncollect_stress_results(Workers, Count, Acc) when length(Acc) >= Count ->\n    Acc;\ncollect_stress_results(Workers, Count, Acc) ->\n    receive\n        {worker_done, WorkerId, Results} ->\n            collect_stress_results(Workers, Count, [Results | Acc])\n    after 60000 ->\n        logger:warning(\"Timeout waiting for stress test results\"),\n        Acc\n    end.\n\n%% Stress worker loop\nstress_worker_loop(Transport, WorkerId, EndTime, Operations) ->\n    case erlang:system_time(millisecond) >= EndTime of\n        true ->\n            erlang:get(parent) ! {worker_done, WorkerId, Operations};\n        false ->\n            TestData = generate_test_data(512),\n            StartTime = erlang:system_time(microsecond),\n            \n            Result = case Transport of\n                stdio -> simulate_stdio_operation(TestData);\n                tcp -> simulate_tcp_operation(TestData);\n                http -> simulate_http_operation(TestData);\n                _ -> {error, unsupported_transport}\n            end,\n            \n            EndOpTime = erlang:system_time(microsecond),\n            Operation = {Result, EndOpTime - StartTime},\n            \n            stress_worker_loop(Transport, WorkerId, EndTime, [Operation | Operations])\n    end.\n\n%% Start resource monitor\nstart_resource_monitor(Duration, Interval) ->\n    spawn_link(fun() ->\n        resource_monitor_loop(erlang:system_time(millisecond) + Duration, Interval, [])\n    end).\n\nresource_monitor_loop(EndTime, Interval, Samples) ->\n    case erlang:system_time(millisecond) >= EndTime of\n        true ->\n            logger:info(\"Resource monitoring completed with ~p samples\", [length(Samples)]);\n        false ->\n            Sample = #{timestamp => erlang:system_time(millisecond),\n                      memory => erlang:memory(total),\n                      process_count => erlang:system_info(process_count),\n                      reductions => element(1, erlang:statistics(reductions))},\n            \n            timer:sleep(Interval),\n            resource_monitor_loop(EndTime, Interval, [Sample | Samples])\n    end.\n\n%% Cache performance data\ncache_performance_data(TestType, Data, State) ->\n    case State#state.ets_cache_table of\n        undefined -> ok;\n        Table ->\n            Timestamp = erlang:system_time(millisecond),\n            Key = {TestType, Timestamp},\n            ets:insert(Table, {Key, Data})\n    end.\n\n%% Collect baseline metrics for optimization comparison\ncollect_baseline_metrics() ->\n    #perf_metrics{\n        start_time = erlang:system_time(microsecond),\n        memory_samples = [erlang:memory(total)],\n        cpu_samples = [get_cpu_usage()]\n    }.\n\n%% Calculate improvement percentage\ncalculate_improvement(BeforeMetrics, AfterMetrics) ->\n    BeforeMemory = hd(BeforeMetrics#perf_metrics.memory_samples),\n    AfterMemory = hd(AfterMetrics#perf_metrics.memory_samples),\n    \n    case BeforeMemory of\n        0 -> 0.0;\n        _ -> ((BeforeMemory - AfterMemory) / BeforeMemory) * 100.0\n    end.\n\n%% Generate optimization recommendations\ngenerate_recommendations(OptName, ImprovementPercent) ->\n    BaseRecommendations = case OptName of\n        registry_ets_optimization when ImprovementPercent > 10 ->\n            [<<\"ETS optimization was successful, consider applying to production\">>];\n        registry_ets_optimization ->\n            [<<\"ETS optimization had minimal impact, investigate other bottlenecks\">>];\n        message_routing_optimization when ImprovementPercent > 15 ->\n            [<<\"Routing optimization shows promise, expand to more code paths\">>];\n        _ ->\n            [<<\"Monitor performance impact in production environment\">>]\n    end,\n    \n    BaseRecommendations.\n\n%% Get current CPU usage\nget_cpu_usage() ->\n    case erlang:statistics(scheduler_wall_time) of\n        undefined -> 0.0;\n        Stats ->\n            % Simplified CPU calculation\n            TotalActive = lists:sum([A || {_, A, _} <- Stats]),\n            TotalTime = lists:sum([T || {_, _, T} <- Stats]),\n            case TotalTime of\n                0 -> 0.0;\n                _ -> (TotalActive / TotalTime) * 100.0\n            end\n    end.\n\n%% Profiling and benchmarking implementations\nprofile_message_routing_impl(MessageCount, MessageSize, State) ->\n    logger:info(\"Profiling message routing with ~p messages of ~p bytes\", \n               [MessageCount, MessageSize]),\n    \n    TestData = generate_test_data(MessageSize),\n    \n    % Profile different routing scenarios\n    Scenarios = [\n        {direct_routing, fun() -> profile_direct_routing(MessageCount, TestData) end},\n        {registry_routing, fun() -> profile_registry_routing(MessageCount, TestData) end},\n        {batched_routing, fun() -> profile_batched_routing(MessageCount, TestData) end}\n    ],\n    \n    Results = lists:map(fun({ScenarioName, ProfileFun}) ->\n        StartTime = erlang:system_time(microsecond),\n        ScenarioResult = ProfileFun(),\n        EndTime = erlang:system_time(microsecond),\n        \n        Duration = EndTime - StartTime,\n        \n        {ScenarioName, #{result => ScenarioResult, \n                        duration_microseconds => Duration,\n                        messages_per_second => (MessageCount * 1000000) / Duration}}\n    end, Scenarios),\n    \n    ProfileData = #{routing_scenarios => Results,\n                   message_count => MessageCount,\n                   message_size => MessageSize,\n                   timestamp => erlang:system_time(millisecond)},\n    \n    cache_performance_data(routing_profile, ProfileData, State),\n    \n    {ok, ProfileData}.\n\nprofile_direct_routing(MessageCount, TestData) ->\n    lists:foreach(fun(_) ->\n        % Simulate direct process messaging\n        self() ! {test_message, TestData},\n        receive {test_message, _} -> ok after 100 -> timeout end\n    end, lists:seq(1, MessageCount)),\n    ok.\n\nprofile_registry_routing(MessageCount, TestData) ->\n    lists:foreach(fun(N) ->\n        ServerId = test_server,\n        TransportId = list_to_atom(\"transport_\" ++ integer_to_list(N rem 3 + 1)),\n        \n        % Use actual registry routing (if available)\n        try\n            erlmcp_registry:route_to_server(ServerId, TransportId, TestData)\n        catch\n            _:_ -> ok  % Registry might not be running in test\n        end\n    end, lists:seq(1, MessageCount)),\n    ok.\n\nprofile_batched_routing(MessageCount, TestData) ->\n    BatchSize = 10,\n    Batches = MessageCount div BatchSize,\n    \n    lists:foreach(fun(_) ->\n        Batch = lists:duplicate(BatchSize, TestData),\n        % Simulate batched message processing\n        lists:foreach(fun(Message) ->\n            % Process message\n            byte_size(Message)\n        end, Batch)\n    end, lists:seq(1, Batches)),\n    ok.\n\nbenchmark_ets_operations_impl(State) ->\n    logger:info(\"Benchmarking ETS operations\"),\n    \n    % Create test table\n    TestTable = ets:new(benchmark_table, [set, public]),\n    \n    try\n        % Benchmark different ETS operations\n        InsertResults = benchmark_ets_inserts(TestTable, 10000),\n        LookupResults = benchmark_ets_lookups(TestTable, 50000),\n        UpdateResults = benchmark_ets_updates(TestTable, 5000),\n        DeleteResults = benchmark_ets_deletes(TestTable, 2000),\n        \n        Results = #{insert_ops => InsertResults,\n                   lookup_ops => LookupResults,\n                   update_ops => UpdateResults,\n                   delete_ops => DeleteResults,\n                   timestamp => erlang:system_time(millisecond)},\n        \n        cache_performance_data(ets_benchmark, Results, State),\n        \n        {ok, Results}\n    after\n        ets:delete(TestTable)\n    end.\n\nbenchmark_ets_inserts(Table, Count) ->\n    StartTime = erlang:system_time(microsecond),\n    \n    lists:foreach(fun(N) ->\n        Key = list_to_atom(\"key_\" ++ integer_to_list(N)),\n        Value = {test_data, N, generate_test_data(64)},\n        ets:insert(Table, {Key, Value})\n    end, lists:seq(1, Count)),\n    \n    EndTime = erlang:system_time(microsecond),\n    Duration = EndTime - StartTime,\n    \n    #{operations => Count,\n      duration_microseconds => Duration,\n      ops_per_second => (Count * 1000000) / Duration}.\n\nbenchmark_ets_lookups(Table, Count) ->\n    % First ensure we have data to lookup\n    ExistingKeys = [list_to_atom(\"key_\" ++ integer_to_list(N)) || N <- lists:seq(1, 1000)],\n    \n    StartTime = erlang:system_time(microsecond),\n    \n    HitCount = lists:foldl(fun(N, Acc) ->\n        Key = lists:nth((N rem length(ExistingKeys)) + 1, ExistingKeys),\n        case ets:lookup(Table, Key) of\n            [] -> Acc;\n            [_] -> Acc + 1\n        end\n    end, 0, lists:seq(1, Count)),\n    \n    EndTime = erlang:system_time(microsecond),\n    Duration = EndTime - StartTime,\n    \n    #{operations => Count,\n      hits => HitCount,\n      hit_rate => (HitCount / Count) * 100,\n      duration_microseconds => Duration,\n      ops_per_second => (Count * 1000000) / Duration}.\n\nbenchmark_ets_updates(Table, Count) ->\n    StartTime = erlang:system_time(microsecond),\n    \n    lists:foreach(fun(N) ->\n        Key = list_to_atom(\"key_\" ++ integer_to_list(N rem 1000 + 1)),\n        NewValue = {updated_data, N, erlang:system_time()},\n        ets:insert(Table, {Key, NewValue})\n    end, lists:seq(1, Count)),\n    \n    EndTime = erlang:system_time(microsecond),\n    Duration = EndTime - StartTime,\n    \n    #{operations => Count,\n      duration_microseconds => Duration,\n      ops_per_second => (Count * 1000000) / Duration}.\n\nbenchmark_ets_deletes(Table, Count) ->\n    StartTime = erlang:system_time(microsecond),\n    \n    DeletedCount = lists:foldl(fun(N, Acc) ->\n        Key = list_to_atom(\"key_\" ++ integer_to_list(N)),\n        case ets:delete(Table, Key) of\n            true -> Acc + 1;\n            false -> Acc\n        end\n    end, 0, lists:seq(1, Count)),\n    \n    EndTime = erlang:system_time(microsecond),\n    Duration = EndTime - StartTime,\n    \n    #{operations => Count,\n      actual_deletes => DeletedCount,\n      duration_microseconds => Duration,\n      ops_per_second => (Count * 1000000) / Duration}.\n\ncollect_gc_metrics_impl(Duration) ->\n    logger:info(\"Collecting GC metrics for ~p ms\", [Duration]),\n    \n    % Enable GC monitoring\n    InitialGcStats = erlang:statistics(garbage_collection),\n    InitialMemory = erlang:memory(),\n    \n    EndTime = erlang:system_time(millisecond) + Duration,\n    \n    % Generate memory pressure\n    spawn_link(fun() -> generate_memory_pressure(EndTime) end),\n    \n    % Monitor GC activity\n    timer:sleep(Duration),\n    \n    FinalGcStats = erlang:statistics(garbage_collection),\n    FinalMemory = erlang:memory(),\n    \n    {InitialGCs, InitialWordsReclaimed} = InitialGcStats,\n    {FinalGCs, FinalWordsReclaimed} = FinalGcStats,\n    \n    GcMetrics = #{gc_count => FinalGCs - InitialGCs,\n                 words_reclaimed => FinalWordsReclaimed - InitialWordsReclaimed,\n                 initial_memory => InitialMemory,\n                 final_memory => FinalMemory,\n                 memory_delta => calculate_memory_delta(InitialMemory, FinalMemory),\n                 duration_ms => Duration,\n                 timestamp => erlang:system_time(millisecond)},\n    \n    {ok, GcMetrics}.\n\nanalyze_memory_patterns_impl(Duration) ->\n    logger:info(\"Analyzing memory patterns for ~p ms\", [Duration]),\n    \n    EndTime = erlang:system_time(millisecond) + Duration,\n    Samples = collect_memory_pattern_samples(EndTime, []),\n    \n    Analysis = analyze_memory_samples(Samples),\n    \n    MemoryPatterns = #{samples => Samples,\n                      analysis => Analysis,\n                      duration_ms => Duration,\n                      timestamp => erlang:system_time(millisecond)},\n    \n    {ok, MemoryPatterns}.\n\ncollect_memory_pattern_samples(EndTime, Samples) ->\n    case erlang:system_time(millisecond) >= EndTime of\n        true -> lists:reverse(Samples);\n        false ->\n            Sample = #{timestamp => erlang:system_time(millisecond),\n                      memory => erlang:memory(),\n                      process_count => erlang:system_info(process_count),\n                      message_queue_len => get_total_message_queue_len()},\n            \n            timer:sleep(1000),\n            collect_memory_pattern_samples(EndTime, [Sample | Samples])\n    end.\n\nanalyze_memory_samples(Samples) ->\n    case length(Samples) of\n        0 -> #{trend => unknown, peak_memory => 0, avg_memory => 0};\n        1 -> #{trend => stable, peak_memory => 0, avg_memory => 0};\n        _ ->\n            MemoryValues = [maps:get(total, maps:get(memory, S)) || S <- Samples],\n            \n            PeakMemory = lists:max(MemoryValues),\n            AvgMemory = lists:sum(MemoryValues) / length(MemoryValues),\n            \n            % Simple trend analysis\n            FirstHalf = lists:sublist(MemoryValues, length(MemoryValues) div 2),\n            SecondHalf = lists:sublist(MemoryValues, length(MemoryValues) div 2 + 1, \n                                     length(MemoryValues)),\n            \n            FirstAvg = lists:sum(FirstHalf) / length(FirstHalf),\n            SecondAvg = lists:sum(SecondHalf) / length(SecondHalf),\n            \n            Trend = if\n                SecondAvg > FirstAvg * 1.1 -> increasing;\n                SecondAvg < FirstAvg * 0.9 -> decreasing;\n                true -> stable\n            end,\n            \n            #{trend => Trend,\n              peak_memory => PeakMemory,\n              avg_memory => AvgMemory,\n              first_half_avg => FirstAvg,\n              second_half_avg => SecondAvg}\n    end.\n\ngenerate_memory_pressure(EndTime) ->\n    case erlang:system_time(millisecond) >= EndTime of\n        true -> ok;\n        false ->\n            % Create temporary data structures\n            _LargeData = lists:duplicate(10000, generate_test_data(1024)),\n            timer:sleep(100),\n            generate_memory_pressure(EndTime)\n    end.\n\nget_total_message_queue_len() ->\n    Processes = erlang:processes(),\n    lists:sum([begin\n        case erlang:process_info(P, message_queue_len) of\n            {message_queue_len, Len} -> Len;\n            undefined -> 0\n        end\n    end || P <- lists:sublist(Processes, 100)]).\n\ncalculate_memory_delta(InitialMemory, FinalMemory) ->\n    maps:fold(fun(Type, FinalValue, Acc) ->\n        InitialValue = maps:get(Type, InitialMemory, 0),\n        Delta = FinalValue - InitialValue,\n        maps:put(Type, Delta, Acc)\n    end, #{}, FinalMemory).\n"
        }
    ]
}