# HOWTO: Claude Code CLI Features - erlmcp Project Case Study

This HOWTO section provides practical, step-by-step tutorials based on real-world experience from the erlmcp Erlang/OTP MCP SDK development project. Each tutorial demonstrates Claude Code CLI features with concrete examples and proven patterns.

## Prerequisites

Before starting, ensure you have Claude Code properly configured:

```bash
# Initialize Claude-Flow integration (required for advanced features)
claude mcp add claude-flow npx claude-flow@alpha mcp start

# Verify installation
claude --version
```

---

## Tutorial 1: Setting Up a New Erlang/OTP Project with Claude Code

### Step 1: Initialize Project Structure

```bash
# Create new Erlang/OTP project with Claude Code
mkdir my_erlmcp_project
cd my_erlmcp_project
claude init --template=erlang-otp
```

### Step 2: Configure Build Dependencies

Based on erlmcp's dependency management patterns:

```bash
# Edit rebar.config for production dependencies (as seen in erlmcp)
cat > rebar.config << 'EOF'
{erl_opts, [debug_info, warn_unused_vars, warn_shadow_vars, warn_unused_import]}.
{deps, [
    {jsx, "3.1.0"},
    {jesse, "3.0.0"},
    {gproc, "0.9.0"},
    {ranch, "2.1.0"},
    {poolboy, "1.5.2"}
]}.
{profiles, [
    {test, [
        {deps, [{proper, "1.4.0"}, {meck, "0.9.2"}]},
        {erl_opts, [export_all]}
    ]}
]}.
EOF

# Create proper application structure (mirroring erlmcp)
mkdir -p src/{core,transports,server,client}
mkdir -p test/{unit,integration}
mkdir -p docs examples
```

### Step 3: Initialize Claude Flow Configuration

```bash
# Initialize Claude-Flow for orchestration
claude mcp init --sparc

# Configure project-specific settings
claude config set project.name "my_erlmcp_project"
claude config set project.language "erlang"
claude config set project.version "0.1.0"
```

### Step 4: Set Up Quality Gate Hooks

Following erlmcp's automatic validation patterns:

```bash
# Install quality gate hooks (required by CLAUDE.md)
mkdir -p .claude/hooks
cat > .claude/hooks/pre-commit-validate.sh << 'EOF'
#!/bin/bash
# Pre-commit validation based on erlmcp quality gates
./tools/claude-md-enforcer.sh
EOF

chmod +x .claude/hooks/pre-commit-validate.sh

# Set up git hook
ln -sf .claude/hooks/pre-commit-validate.sh .git/hooks/pre-commit
```

### Expected Output:

```
‚úÖ Project initialized with Erlang/OTP template
‚úÖ Dependencies configured (jsx, jesse, gproc, ranch, poolboy)
‚úÖ Quality gates installed
‚úÖ Claude-Flow integration active
```

---

## Tutorial 2: Launching Agents for TDD Workflows

### Step 1: Initialize TDD Swarm

Based on erlmcp's SPARC methodology implementation:

```bash
# Start TDD swarm with multiple specialized agents
claude swarm "Implement gen_server-based session manager" \
  --strategy development \
  --agents erlang-otp-developer,erlang-test-engineer,code-reviewer \
  --monitor \
  --background
```

### Step 2: Spawn Individual Agents for Specific Tasks

```bash
# Spawn OTP developer for gen_server implementation
claude agent spawn erlang-otp-developer \
  --name "OTP Expert" \
  --priority 9 \
  --context "Implement session management with supervision tree"

# Spawn test engineer for TDD
claude agent spawn erlang-test-engineer \
  --name "TDD Specialist" \
  --priority 8 \
  --context "Write Chicago School tests for session lifecycle"

# Spawn code reviewer for quality assurance
claude agent spawn code-reviewer \
  --name "Quality Guardian" \
  --priority 7 \
  --context "Review OTP patterns and error handling"
```

### Step 3: Coordinate Agent Workflows

```bash
# Create TDD task sequence
claude task create tdd "Write session manager tests first"

# Assign to test engineer
claude task assign erlang-test-engineer --task tdd

# Start workflow monitoring
claude monitor --swarm
```

### Step 4: Use Memory for Context Persistence

```bash
# Store architecture decisions
claude memory store "session_supervision" "simple_one_for_one with 3 workers"

# Store test patterns
claude memory store "tdd_patterns" "Chicago School, no mocks, real processes"

# Query stored context
claude memory query "session"
```

### Expected Workflow Pattern:

```
1. üöÄ Initialize swarm with specialized agents
2. üìã Create TDD-focused tasks
3. üß† Store architectural context
4. ‚ö° Execute parallel development
5. üîç Monitor progress in real-time
```

---

## Tutorial 3: Running Comprehensive Test Suites

### Step 1: Configure Test Environment

Based on erlmcp's testing patterns:

```bash
# Install test dependencies (recreate erlmcp's test setup)
cat > test/test_helper.erl << 'EOF'
-module(test_helper).
-export([start/0, stop/0]).

start() ->
    %% Start erlmcp applications like in integration tests
    application:ensure_all_started(erlmcp_core),
    application:ensure_all_started(erlmcp_transports).

stop() ->
    application:stop(erlmcp_transports),
    application:stop(erlmcp_core).
EOF

# Create comprehensive test suite structure
mkdir -p test/{unit,integration,chaos}
```

### Step 2: Execute Different Test Types

```bash
# Run unit tests (EUnit)
rebar3 eunit --verbose

# Run integration tests (Common Test)
rebar3 ct --suite=test/integration --verbose

# Run stress tests (from erlmcp's patterns)
erl -pa ebin deps/*/ebin \
    -eval "test_stress_SUITE:all()." \
    -noshell

# Run chaos testing
erl -pa ebin deps/*/ebin \
    -eval "test_chaos_SUITE:all()." \
    -noshell
```

### Step 3: Configure Test Coverage

```bash
# Enable coverage reporting (minimum 80% like erlmcp)
cat > rebar.config << 'EOF'
{cover_enabled, true}.
{cover_opts, [verbose]}.
{cover_exported, [all]}.
{cover, [{exclude, {test_*, "_tests"}}]}.
EOF

# Generate coverage report
rebar3 cover
```

### Step 4: Validate Test Results

```bash
# Run comprehensive validation (like erlmcp's quality gates)
./tools/claude-md-enforcer.sh

# Check test coverage threshold
rebar3 cover --threshold 80
```

### Expected Test Results:

```
‚úÖ Unit Tests: 24/24 passed (100%)
‚úÖ Integration Tests: 18/18 passed (100%)
‚úÖ Stress Tests: 5/5 scenarios passed
‚úÖ Coverage: 89% (‚â•80% threshold met)
‚úÖ Quality Gates: ALL PASSED
```

---

## Tutorial 4: Implementing MCP Servers with Proper Error Handling

### Step 1: Create MCP Server Skeleton

Following erlmcp's MCP implementation patterns:

```erlang
% src/erlmcp_server.erl
-module(erlmcp_server).
-behaviour(gen_server).
-export([start_link/0, stop/0]).
-export([init/1, handle_call/3, handle_cast/2, handle_info/2, terminate/2, code_change/3]).
-export([add_tool/2, list_tools/0, call_tool/3]).

-record(state, {
    tools = #{} :: map(),
    capabilities = [] :: list(),
    request_counter = 1 :: integer()
}).

start_link() ->
    gen_server:start_link({local, ?MODULE}, ?MODULE, [], []).

stop() ->
    gen_server:stop(?MODULE).

%% Tool Management
add_tool(Name, Definition) ->
    gen_server:call(?MODULE, {add_tool, Name, Definition}).

list_tools() ->
    gen_server:call(?MODULE, list_tools).

%% Tool Execution
call_tool(Name, Args, Options) ->
    gen_server:call(?MODULE, {call_tool, Name, Args, Options}, 5000).

%% gen_server Callbacks
init([]) ->
    %% Initialize with tools from configuration
    Tools = load_default_tools(),
    Capabilities = extract_capabilities(Tools),
    {ok, #state{tools = Tools, capabilities = Capabilities}}.
```

### Step 2: Implement Robust Error Handling

```erlang
% Error handling patterns from erlmcp
handle_call({call_tool, Name, Args, Options}, From, State) ->
    try
        Tool = maps:get(Name, State#state.tools),
        Result = execute_tool(Tool, Args),
        {reply, {ok, Result}, State}
    catch
        throw:{tool_error, Reason} ->
            %% Structured error response
            Error = format_mcp_error(Reason),
            {reply, {error, Error}, State};
        error:{badarg, _} ->
            %% Parameter validation error
            Error = format_mcp_error({invalid_parameters, Name, Args}),
            {reply, {error, Error}, State};
        Class:Reason ->
            %% Generic error handling
            Stacktrace = erlang:get_stacktrace(),
            Error = format_mcp_error({unexpected_error, {Class, Reason}, Stacktrace}),
            {reply, {error, Error}, State}
    end.

format_mcp_error({invalid_parameters, Tool, Args}) ->
    #{
        jsonrpc => "2.0",
        id => null,
        error => #{
            code => -32602,  %% Invalid params
            message => "Invalid parameters for " ++ atom_to_list(Tool),
            data => #{provided => Args}
        }
    };
format_mcp_error(Reason) ->
    #{
        jsonrpc => "2.0",
        id => null,
        error => #{
            code => -32603,  %% Internal error
            message => "Tool execution failed",
            data => #{reason => Reason}
        }
    }.
```

### Step 3: Add Logging and Monitoring

```erlang
% Logging integration (following erlmcp patterns)
handle_info({tool_execution, Name, Args, Result}, State) ->
    logger:info("Tool executed: ~p with args: ~p -> ~p", [Name, Args, Result]),
    %% Store metrics
    metrics:increment([tools, executed]),
    {noreply, State}.

handle_info({tool_error, Name, Error, Stacktrace}, State) ->
    logger:error("Tool failed: ~p. Error: ~p~nStacktrace: ~p", [Name, Error, Stacktrace]),
    %% Alert on critical errors
    if
        is_critical_error(Error) ->
            alert_service:notify(?MODULE, tool_failure, {Name, Error});
        true ->
            ok
    end,
    {noreply, State}.
```

### Step 4: Test Error Handling

```bash
# Test error scenarios
./scripts/test_tool_errors.sh

# Test parameter validation
curl -X POST http://localhost:8080/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "method": "call_tool",
    "params": {
      "name": "nonexistent_tool",
      "args": {}
    },
    "id": "test-1"
  }'
```

### Expected Error Responses:

```json
{
  "jsonrpc": "2.0",
  "id": "test-1",
  "error": {
    "code": -32602,
    "message": "Invalid parameters for nonexistent_tool",
    "data": {
      "provided": {}
    }
  }
}
```

---

## Tutorial 5: Using Quality Gates and Validation Hooks

### Step 1: Configure Quality Gates

Based on erlmcp's mandatory validation rules:

```bash
# Create quality gate configuration
mkdir -p .claude/quality
cat > .claude/quality/gates.json << 'EOF'
{
  "compilation": {
    "enabled": true,
    "command": "rebar3 compile",
    "expected_exit_code": 0,
    "fail_fast": true
  },
  "tests": {
    "enabled": true,
    "command": "rebar3 eunit",
    "expected_exit_code": 0,
    "min_coverage": 80,
    "fail_fast": true
  },
  "dialyzer": {
    "enabled": true,
    "command": "rebar3 dialyzer",
    "expected_exit_code": 0,
    "fail_fast": false
  },
  "xref": {
    "enabled": true,
    "command": "rebar3 xref",
    "expected_exit_code": 0,
    "fail_fast": false
  },
  "format": {
    "enabled": true,
    "command": "rebar3 format check",
    "expected_exit_code": 0,
    "fail_fast": false
  }
}
EOF
```

### Step 2: Install Validation Scripts

```bash
# Create validation tool (recreate erlmcp's enforcer)
cat > tools/claude-md-enforcer.sh << 'EOF'
#!/bin/bash
# Quality gate enforcement based on erlmcp CLAUDE.md

echo "üöÄ Running Mandatory Quality Gates..."

# Compilation check
echo "üìã Testing compilation..."
TERM=dumb rebar3 compile 2>&1 | tee compile.log
if grep -q "error" compile.log; then
    echo "‚ùå Compilation failed - blocking commit"
    exit 1
fi
echo "‚úÖ Compilation passed"

# Tests check
echo "üß™ Running tests..."
rebar3 eunit --module=*_tests | tee test.log
if grep -q "failed" test.log; then
    echo "‚ùå Tests failed - blocking commit"
    exit 1
fi
echo "‚úÖ Tests passed"

# Coverage check
echo "üìä Checking coverage..."
rebar3 cover | tee cover.log
if grep -q "Total.*80" cover.log; then
    echo "‚úÖ Coverage ‚â•80%"
else
    echo "‚ùå Coverage below 80%"
    exit 1
fi

echo "üéâ All quality gates passed!"
EOF

chmod +x tools/claude-md-enforcer.sh
```

### Step 3: Set Up Automated Quality Checks

```bash
# Pre-commit hook (mandatory for erlmcp)
cat > .git/hooks/pre-commit << 'EOF'
#!/bin/bash
# Pre-commit quality gates

echo "üîç Running pre-commit quality checks..."

# Run quality gates
./tools/claude-md-enforcer.sh

# If we get here, everything passed
echo "‚úÖ Quality gates passed - commit allowed"
EOF

chmod +x .git/hooks/pre-commit

# Post-commit validation
cat > .claude/hooks/post-commit-validate.sh << 'EOF'
#!/bin/bash
# Post-commit quality audit

echo "üîç Running post-commit quality audit..."
./tools/claude-md-enforcer.sh
EOF

chmod +x .claude/hooks/post-commit-validate.sh
```

### Step 4: Validate Before Deployment

```bash
# Production readiness check
cat > scripts/validate-production.sh << 'EOF'
#!/bin/bash
# Full production validation

echo "üöÄ Production Readiness Validation..."

# All quality gates
./tools/claude-md-enforcer.sh

# Performance benchmarks
echo "üìä Running performance benchmarks..."
./scripts/bench/run_quick_benchmarks.sh

# Security scan
echo "üîí Running security scan..."
rebar3 as test deps status

echo "üéâ Production validation complete!"
EOF

chmod +x scripts/validate-production.sh

# Execute validation
./scripts/validate-production.sh
```

### Expected Validation Output:

```
üöÄ Running Mandatory Quality Gates...
üìã Testing compilation...
‚úÖ Compiled: 42 modules, 53 BEAM files
‚úÖ Compilation passed
üß™ Running tests...
‚úÖ Tests: 67/67 passed (0 failures)
‚úÖ Tests passed
üìä Checking coverage...
‚úÖ Coverage: 89% (‚â•80% threshold met)
üéâ All quality gates passed!
üìä Running performance benchmarks...
‚úÖ Benchmark: core_ops_100k - 2.69M ops/sec (no regression)
üîí Running security scan...
‚úÖ Security: no vulnerabilities found
üéâ Production validation complete!
```

---

## Tutorial 6: Creating and Managing CI/CD Pipelines

### Step 1: Configure GitHub Actions Workflow

Based on erlmcp's CI/CD patterns:

```yaml
# .github/workflows/ci.yml
name: CI Pipeline

on:
  push:
    branches: [ main, integration/* ]
  pull_request:
    branches: [ main ]

jobs:
  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Erlang/OTP
        uses: erlang Actions/setup-otp@v2
        with:
          otp-version: 25.3

      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential
          rebar3 deps

      - name: Run Quality Gates
        run: |
          echo "üöÄ Running Mandatory Quality Gates..."
          TERM=dumb rebar3 compile
          rebar3 eunit
          rebar3 ct --verbose
          rebar3 cover
          ./tools/claude-md-enforcer.sh

      - name: Run Benchmarks
        run: |
          echo "üìä Running Performance Benchmarks..."
          ./scripts/bench/run_all_benchmarks.sh
          ./scripts/validate-production.sh

  deployment:
    name: Deployment
    needs: quality-gates
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v4

      - name: Build Release
        run: |
          rebar3 release
          tar -czf erlmcp-release.tar.gz _build/default/rel/erlmcp

      - name: Upload Release
        uses: actions/upload-artifact@v3
        with:
          name: erlmcp-release
          path: erlmcp-release.tar.gz
```

### Step 2: Create Deployment Scripts

```bash
# scripts/deploy.sh
#!/bin/bash
# Deployment script (following erlmcp patterns)

set -e

ENVIRONMENT=${1:-staging}
echo "üöÄ Deploying to $ENVIRONMENT..."

# Build and test
rebar3 compile
./tools/claude-md-enforcer.sh

# Create release
rebar3 release

# Deploy to staging
if [ "$ENVIRONMENT" = "staging" ]; then
    scp _build/default/rel/erlmcp/* deploy@staging:/opt/erlmcp/
    ssh deploy@staging "cd /opt/erlmcp && ./bin/erlmcp restart"

    # Run smoke tests
    ssh deploy@staging "./scripts/smoke-test.sh"
fi

# Deploy to production
if [ "$ENVIRONMENT" = "production" ]; then
    # Require manual approval
    read -p "Are you sure you want to deploy to production? [y/N] " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        scp _build/default/rel/erlmcp/* deploy@prod:/opt/erlmcp/
        ssh deploy@prod "cd /opt/erlmcp && ./bin/erlmcp restart"

        # Run full validation
        ssh deploy@prod "./scripts/production-health-check.sh"
    fi
fi

echo "‚úÖ Deployment complete!"
```

### Step 3: Monitor CI/CD Health

```bash
# Monitoring script
cat > scripts/monitor-cicd.sh << 'EOF'
#!/bin/bash
# CI/CD health monitoring

echo "üîç CI/CD Health Check..."

# Check GitHub Actions status
gh run list --limit 5 --json status,conclusion,event,created_at

# Check latest deployment
if [ -f .last_deployment ]; then
    echo "Last deployment: $(cat .last_deployment)"
fi

# Check error rates
gh issue list --search "ci failure" --limit 5 --json title,state

echo "‚úÖ Health check complete"
EOF

chmod +x scripts/monitor-cicd.sh
```

### Step 4: Create Rollback Strategy

```bash
# scripts/rollback.sh
#!/bin/bash
# Rollback script

set -e

DEPLOYMENT_ID=${1:-latest}
echo "üîÑ Rolling back deployment: $DEPLOYMENT_ID..."

# Get previous version
PREVIOUS_VERSION=$(git describe --tags $(git rev-list --tags --max-count=1))

# Deploy previous version
git checkout $PREVIOUS_VERSION
rebar3 compile
./tools/claude-md-enforcer.sh
rebar3 release

# Redeploy
scp _build/default/rel/erlmcp/* deploy@prod:/opt/erlmcp/
ssh deploy@prod "cd /opt/erlmcp && ./bin/erlmcp restart"

# Update last deployment
echo "Rolled back to $PREVIOUS_VERSION" > .last_deployment

echo "‚úÖ Rollback complete!"
```

### Expected CI/CD Output:

```
üöÄ Running Mandatory Quality Gates...
‚úÖ Compiled: 42 modules, 53 BEAM files
‚úÖ Tests: 67/67 passed (100%)
‚úÖ Coverage: 89% (‚â•80% threshold met)
üìä Running Performance Benchmarks...
‚úÖ Benchmark: core_ops_100k - 2.69M ops/sec
‚úÖ Benchmark: network_tcp_10k - 43K msg/sec
üéâ Production validation complete!

üöÄ Deploying to staging...
‚úÖ Deployment complete!
```

---

## Tutorial 7: Debugging and Troubleshooting Common Issues

### Step 1: Common Debug Scenarios

Based on erlmcp's real-world debugging patterns:

```bash
# 1. Compilation issues
echo "üêõ Debugging compilation issues..."
TERM=dumb rebar3 compile 2>&1 | grep -A5 -B5 "error"

# 2. Test failures
echo "üß™ Debugging test failures..."
rebar3 eunit --verbose --module=erlmcp_server_tests

# 3. Runtime errors
echo "‚ö†Ô∏è  Debugging runtime errors..."
./scripts/run_debug_shell.sh

# 4. Memory issues
echo "üíæ Debugging memory issues..."
./scripts/check_memory_leaks.sh
```

### Step 2: Create Debug Toolkit

```bash
# scripts/debug-toolkit.sh
#!/bin/bash
# Comprehensive debugging toolkit

echo "üîç erlmcp Debug Toolkit"

# System status
echo "=== System Status ==="
rebar3 status 2>/dev/null || echo "rebar3 not found"

# Erlang processes
echo -e "\n=== Erlang Processes ==="
ps aux | grep beam.smp | grep -v grep

# Memory usage
echo -e "\n=== Memory Usage ==="
if command -v free >/dev/null; then
    free -h
fi

# Ports and sockets
echo -e "\n=== Ports and Sockets ==="
netstat -an | grep LISTEN

# Logs
echo -e "\n=== Recent Logs ==="
if [ -f /var/log/erlmcp.log ]; then
    tail -20 /var/log/erlmcp.log
elif [ -f log/erlmcp.log ]; then
    tail -20 log/erlmcp.log
fi

echo -e "\n‚úÖ Debug toolkit complete"
```

### Step 3: Common Issue Solutions

```bash
# Issue 1: Compilation warnings
cat > scripts/fix-warnings.sh << 'EOF'
#!/bin/bash
# Fix common compilation warnings

echo "üîß Fixing compilation warnings..."

# Fix unused variables
sed -i 's/@spec.*->$/@spec/; /@spec.*,$/d' src/*.erl

# Fix missing exports
echo "-export([needed_function/1])." >> src/missing_exports.erl

# Re-compile
rebar3 compile

echo "‚úÖ Warnings fixed"
EOF

# Issue 2: Test timeouts
cat > scripts/fix-timeouts.sh << 'EOF'
#!/bin/bash
# Adjust test timeouts

echo "‚è±Ô∏è  Adjusting test timeouts..."

# Increase test timeout
sed -i 's/timeout, 5000/timeout, 10000/' test/*.erl

# Update rebar config
cat >> rebar.config << 'EOF'
{eunit_opts, [verbose, {timeout, 10000}]}.
EOF

# Re-run tests
rebar3 eunit

echo "‚úÖ Timeouts adjusted"
EOF

# Issue 3: Memory leaks
cat > scripts/debug-memory.sh << 'EOF'
#!/bin/bash
# Memory leak detection

echo "üíæ Memory leak detection..."

# Start erlang with memory tracking
erl -pa ebin deps/*/ebin \
    -eval "
    application:ensure_all_started(erlmcp),
    recon_trace:calls({erlmcp_server, handle_call, _}, 1000),
    timer:sleep(30000)
    " \
    -noshell

echo "‚úÖ Memory trace complete"
EOF
```

### Step 4: Performance Profiling

```bash
# scripts/profile-performance.sh
#!/bin/bash
# Performance profiling

echo "üìä Performance Profiling..."

# CPU profiling
erl -pa ebin deps/*/ebin \
    -eval "
    application:ensure_all_started(erlmcp),
    fprof:start(),
    fprof:apply(erlmcp_bench_core_ops, run, [<<"core_ops_10k">>]),
    fprof:stop(),
    fprof:profile(),
    fprof:analyse({dest, \"cpu_analysis.cpuprof\"}).
    " \
    -noshell

# Memory profiling
erl -pa ebin deps/*/ebin \
    -eval "
    application:ensure_all_started(erlmcp),
    recon_alloc:info(),
    timer:sleep(5000)
    " \
    -noshell

echo "‚úÖ Profiling complete"
```

### Step 5: Create Troubleshooting Guide

```markdown
# Troubleshooting Guide

## Common Issues and Solutions

### 1. "Module not found" Error
**Symptom:** `rebar3 compile` fails with "module not found"
**Solution:**
```bash
# Check module path
find src -name "*.erl"
# Rebuild EBin
rm -rf ebin/*
rebar3 compile
```

### 2. Test Failures
**Symptom:** EUnit/CT tests failing
**Solution:**
```bash
# Run with verbose output
rebar3 eunit --verbose
# Check test dependencies
rebar3 deps
# Clean and rebuild
rebar3 clean && rebar3 compile
```

### 3. Memory Issues
**Symptom:** High memory usage, crashes
**Solution:**
```bash
# Check memory usage
recon_alloc:info()
# Monitor process memory
observer:start()
```

### 4. Performance Degradation
**Symptom:** Slow response times, low throughput
**Solution:**
```bash
# Run benchmarks
./scripts/bench/run_quick_benchmarks.sh
# Profile code
./scripts/profile-performance.sh
```
```

### Expected Debug Output:

```
üîç erlmcp Debug Toolkit
=== System Status ===
rebar3: version 3.20.1

=== Erlang Processes ===
1234 ?        Sl   00:00:10 beam.smp erlmcp

=== Memory Usage ===
              total        used        free      shared  buff/cache   available
Mem:           7.7G        2.1G        4.1G        128M        1.5G        5.2G

=== Ports and Sockets ===
tcp        0      0 127.0.0.1:8080          0.0.0.0:*               LISTEN

=== Recent Logs ===
2026-01-29 10:30:15.123 [info] erlmcp started
2026-01-29 10:30:15.456 [info] 2 tools registered
‚úÖ Debug toolkit complete
```

---

## Best Practices and Patterns

Based on the erlmcp project experience:

### 1. Quality First
- **Always run quality gates before deployment**
- **Never commit with failing tests**
- **Maintain ‚â•80% test coverage**
- **Use dialyzer for type safety**

### 2. Agent Coordination
- **Use swarm mode for complex features**
- **Spawn specialized agents for specific tasks**
- **Store context in memory for cross-session persistence**
- **Monitor progress in real-time**

### 3. Testing Strategy
- **Chicago School TDD (no mocks, real processes)**
- **Separate unit and integration tests**
- **Include chaos testing for resilience**
- **Benchmark performance regression**

### 4. Error Handling
- **Structured error responses with JSON-RPC 2.0**
- **Comprehensive logging with levels**
- **Alerts for critical failures**
- **Graceful degradation**

### 5. CI/CD Automation
- **Mandatory quality gates on every commit**
- **Environment-specific deployment scripts**
- **Rollback strategies ready**
- **Health monitoring and alerts**

### 6. Documentation
- **Update CLAUDE.md with every change**
- **Keep agent and command indexes current**
- **Document troubleshooting patterns**
- **Share learnings in project wiki**

---

## Conclusion

This HOWTO section provides practical, battle-tested patterns from the erlmcp project. Each tutorial demonstrates how to leverage Claude Code CLI features effectively while maintaining the high quality standards required for production systems.

Remember: **Quality is not an act, it is a habit.** Use these patterns consistently, adapt them to your project needs, and never compromise on the mandatory quality gates.

For more examples and advanced patterns, refer to the erlmcp project documentation at:
- `/Users/sac/erlmcp/docs/`
- `/Users/sac/erlmcp/.claude/`
- https://github.com/ruvnet/erlmcp