# Regression Prevention System

**TCPS Quality Gate: è‡ªåƒåŒ– (Jidoka) - Built-in Quality with Stop-the-Line Authority**

The erlmcp regression prevention system automatically detects quality regressions and blocks merges that would degrade code quality, performance, or reliability.

## Overview

The system consists of four components:

1. **Detection** - Automated metric collection and comparison
2. **Blocking** - Quality gates that prevent regressions from merging
3. **Reporting** - Detailed analysis and recommendations
4. **Allowlist** - Controlled exceptions with justification

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Pull Request Event                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Collect Baseline Metrics (from main branch)        â”‚
â”‚  - Compile and count warnings                                â”‚
â”‚  - Run tests and calculate pass rate                         â”‚
â”‚  - Measure code coverage                                     â”‚
â”‚  - Benchmark performance                                     â”‚
â”‚  - Calculate complexity metrics                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: Collect Current Metrics (from PR branch)           â”‚
â”‚  - Same metrics as baseline                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Detect Regressions                                  â”‚
â”‚  - Compare current vs baseline                               â”‚
â”‚  - Calculate severity (low/medium/high/critical)             â”‚
â”‚  - Generate regression report                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: Enforce Quality Gates                               â”‚
â”‚  - Check allowlist for exceptions                            â”‚
â”‚  - BLOCK if critical/high severity                           â”‚
â”‚  - WARN if medium severity                                   â”‚
â”‚  - ALLOW if low severity                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: Report & Status                                     â”‚
â”‚  - Post PR comment with details                              â”‚
â”‚  - Set GitHub status check                                   â”‚
â”‚  - Upload HTML report artifact                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Metrics Tracked

### 1. Test Pass Rate
**What:** Percentage of tests that pass
**Threshold:** 
- Critical: â‰¥5% drop
- Medium: â‰¥2% drop
- Low: <2% drop

**Example:**
```
Baseline: 100% (100/100 tests)
Current:  94% (94/100 tests)
Regression: -6% [CRITICAL] â† BLOCKS MERGE
```

### 2. Code Coverage
**What:** Percentage of code covered by tests
**Threshold:**
- Critical: â‰¥10% drop
- Medium: â‰¥5% drop
- Low: <5% drop

**Example:**
```
Baseline: 85% coverage
Current:  78% coverage
Regression: -7% [MEDIUM] â† REQUIRES JUSTIFICATION
```

### 3. Compilation Warnings
**What:** Number of compiler warnings
**Threshold:**
- High: â‰¥20% increase
- Medium: â‰¥10% increase
- Low: <10% increase

**Example:**
```
Baseline: 5 warnings
Current:  12 warnings
Regression: +140% [HIGH] â† BLOCKS MERGE
```

### 4. Performance Throughput
**What:** Operations per second (from benchmarks)
**Threshold:**
- Critical: â‰¥20% degradation
- High: â‰¥10% degradation
- Medium: â‰¥5% degradation

**Example:**
```
Baseline: 2,690,000 msg/s
Current:  2,100,000 msg/s
Regression: -22% [CRITICAL] â† BLOCKS MERGE
```

### 5. Code Complexity
**What:** Average lines per module
**Threshold:**
- Medium: â‰¥15% increase
- Low: <15% increase

**Example:**
```
Baseline: 250 lines/module
Current:  295 lines/module
Regression: +18% [MEDIUM] â† REQUIRES JUSTIFICATION
```

## Severity Levels

### Critical (BLOCKS MERGE)
- Test pass rate drops â‰¥5%
- Performance degrades â‰¥20%
- Requires VP Engineering approval to override

### High (BLOCKS MERGE)
- Warnings increase â‰¥20%
- Performance degrades â‰¥10%
- Requires Tech Lead + 2 Senior Engineers approval

### Medium (WARNING)
- Test pass rate drops 2-5%
- Coverage drops 5-10%
- Complexity increases â‰¥15%
- Requires justification in PR description

### Low (INFORMATIONAL)
- Minor regressions below thresholds
- Noted but doesn't block merge

## Blocking Criteria

**BLOCKS MERGE IF:**
1. Any CRITICAL regression detected
2. Any HIGH regression detected
3. Regression not in allowlist
4. No valid override approval

**ALLOWS MERGE WITH WARNING IF:**
1. Only MEDIUM or LOW regressions
2. Justification provided in PR
3. Regression documented

**ALLOWS MERGE IF:**
1. No regressions detected
2. All quality gates pass

## Using the System

### Local Testing (Before PR)

```bash
# Run regression detection locally
./tools/regression/detect-regression.sh

# Check if quality gates would pass
./tools/regression/block-on-regression.sh

# Generate HTML report
./tools/regression/generate-html-report.sh

# View report
open .metrics/regression-report.html
```

### CI/CD (Automatic)

The system runs automatically on every PR:

1. GitHub Action triggers on PR creation/update
2. Collects baseline from main branch
3. Collects current from PR branch
4. Runs regression detection
5. Posts comment to PR with results
6. Sets status check (pass/fail)
7. Uploads detailed HTML report

### PR Comments

The system posts a comment like:

```markdown
## ğŸ” Regression Detection Report

**Severity:** âŒ critical

### Regressions Detected

- **test_pass_rate** [critical]: Test pass rate dropped by 6.0%
  - Baseline: 100.0
  - Current: 94.0

- **performance** [high]: Performance degraded by 22%
  - Baseline: 2690000
  - Current: 2100000

### âŒ Quality Gate: FAILED

This PR is **BLOCKED** due to critical or high severity regressions.

To proceed:
1. Fix the regressions, or
2. Add to allowlist with justification, or
3. Request override from tech lead
```

## Override Process

### Adding to Allowlist

Edit `tools/regression/allowlist.json`:

```json
{
  "allowed_regressions": [
    {
      "metric": "performance",
      "severity": "medium",
      "justification": "Intentional tradeoff for improved correctness",
      "approved_by": "tech-lead",
      "approved_date": "2026-01-28",
      "expires": "2026-02-28",
      "ticket": "ERLMCP-123"
    }
  ]
}
```

**Requirements:**
- Must have clear justification
- Must have approval from appropriate level
- Must have expiration date
- Must link to ticket/issue

### Approval Levels

| Severity | Approval Required |
|----------|-------------------|
| Critical | VP Engineering |
| High | Tech Lead + 2 Senior Engineers |
| Medium | Tech Lead |
| Low | PR Reviewer |

## Periodic Review

The allowlist is reviewed monthly:

1. Tech Lead reviews all active exceptions
2. Expired exceptions are removed
3. Long-standing exceptions are investigated
4. Improvements are planned to eliminate need

## Best Practices

### For Developers

1. **Run locally before PR** - Catch issues early
2. **Fix don't workaround** - Address root causes
3. **Document intentional tradeoffs** - Clear justification
4. **Keep PRs focused** - Easier to analyze impact

### For Reviewers

1. **Check regression report** - Part of review process
2. **Question allowlist additions** - Ensure necessary
3. **Suggest improvements** - Help eliminate regressions
4. **Enforce standards** - Don't approve questionable overrides

### For Teams

1. **Monitor trends** - Track regression frequency
2. **Improve detection** - Add more metrics over time
3. **Automate fixes** - Build self-healing capabilities
4. **Continuous improvement** - Regular retrospectives

## Troubleshooting

### False Positives

If detection reports invalid regression:

1. Check baseline metrics collection
2. Verify test stability (no flakes)
3. Ensure consistent environment
4. Consider adjusting thresholds

### Flaky Tests

If tests are flaky:

1. Fix the flaky tests (priority)
2. Temporarily skip in baseline
3. Don't add to allowlist (forces fix)

### Performance Variance

If benchmarks vary too much:

1. Use longer benchmark runs
2. Run multiple times and average
3. Consider machine-specific baselines
4. Factor in measurement uncertainty

## Integration with TCPS

This system implements **è‡ªåƒåŒ– (Jidoka)** principle:

- **Built-in quality** - Automated detection, not manual
- **Stop-the-line** - Blocks bad merges immediately
- **Root cause focus** - Reports suggest fixes
- **Continuous improvement** - Metrics and trends tracked

Related TCPS commands:
- `/tcps-jidoka` - Quality checks (uses this system)
- `/poka-yoke-validate` - Error-proofing (prevention)
- `/tcps-andon` - Stop line (blocking)

## Files

```
tools/regression/
â”œâ”€â”€ detect-regression.sh      # Metric collection and comparison
â”œâ”€â”€ block-on-regression.sh    # Quality gate enforcement
â”œâ”€â”€ generate-html-report.sh   # HTML report generation
â””â”€â”€ allowlist.json            # Permitted exceptions

.github/workflows/
â””â”€â”€ regression-guard.yml      # CI/CD automation

docs/regression/
â””â”€â”€ PREVENTION_SYSTEM.md      # This file

.metrics/                     # Generated at runtime
â”œâ”€â”€ baseline.json             # Baseline metrics
â”œâ”€â”€ current.json              # Current metrics
â”œâ”€â”€ regression-report.json    # Detected regressions
â”œâ”€â”€ regression-report.html    # HTML report
â””â”€â”€ regression-summary.txt    # Text summary
```

## Metrics

Track system effectiveness:

- **Regression detection rate** - % of regressions caught
- **False positive rate** - % of invalid detections
- **Override rate** - % of regressions allowed via allowlist
- **Fix time** - Average time to fix detected regressions
- **Trend** - Regression frequency over time

## Future Enhancements

Planned improvements:

1. **Machine learning** - Predict regressions before they happen
2. **Auto-fix suggestions** - AI-generated fix recommendations
3. **Impact analysis** - Predict downstream effects
4. **Trend analysis** - Long-term quality tracking
5. **Benchmark improvements** - More comprehensive performance tests
6. **Security metrics** - CVE scanning, vulnerability detection
7. **Dependency tracking** - Monitor third-party library changes

## Support

Questions or issues:
1. Check this documentation
2. Review allowlist examples
3. Ask in #engineering channel
4. Create issue with `regression-system` label

---

**Remember:** The goal is not to block work, but to maintain quality. If the system blocks your PR, it's protecting users from regressions. Work with it, not against it.
