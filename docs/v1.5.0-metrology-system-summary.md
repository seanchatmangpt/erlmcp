# erlmcp v1.5.0 Metrology System Summary

**Version:** 1.5.0
**Agent:** erlang-architect
**Date:** 2026-01-27
**Status:** Design Complete - Ready for Implementation

---

## What Was Delivered

This design provides a **complete metrology validation system** that eliminates the 7 stop-the-line conditions plaguing performance artifacts:

1. ✅ **Naked numbers** (missing units)
2. ✅ **Ambiguous metrics** (msg/s vs req/s confusion)
3. ✅ **Undefined scope** (per-process vs per-node)
4. ✅ **Unanchored duration** (rate without time window)
5. ✅ **Mixed context** (session vs connection)
6. ✅ **Unlabeled memory** (heap only vs RSS)
7. ✅ **Zero sample size** (percentiles without N)

---

## Deliverables

### 1. Schema File (JSON Schema Draft-07)

**File:** `/Users/sac/erlmcp/shapes/metrology.schema.json`

**Features:**
- Canonical metric name registry (18 standard metrics)
- Required fields: metric_name, value, unit, scope, transport, duration_seconds
- Unit definitions with dimension + symbol
- Quality gate thresholds (throughput_min, latency_p99_max, etc.)
- Violation tracking (maps to 7 stop-line rules)

**Validation Engine:** jesse (Erlang JSON Schema validator)

**Key Design Decision:**
- JSON Schema chosen over SHACL for:
  - Better Erlang ecosystem support (jesse is mature)
  - Developer familiarity
  - Performance (<1ms per artifact)

### 2. Architecture Document

**File:** `/Users/sac/erlmcp/docs/v1.5.0-metrology-validation-architecture.md`

**Contents (80 pages):**
- Validation stages (build-time → test → CI → release)
- Validator architecture (gen_server with jesse integration)
- Rebar3 provider design (`rebar3 tcps metrology_validate`)
- Common Test hook (automatic validation in teardowns)
- CI integration (GitHub Actions gate)
- Backwards compatibility strategy (migration script)
- Supervision tree impact (minimal, single validator gen_server)
- 6-week implementation plan

**Key Components:**

**A. erlmcp_metrology_validator (gen_server)**
```erlang
-spec validate_measurement(map()) -> ok | {error, [violation()]}.
-spec validate_artifact(binary()) -> {ok, map()} | {error, [violation()]}.
-spec validate_directory(binary()) -> {ok, #{passed => integer(), failed => integer()}}.
-spec check_quality_gates(map(), map()) -> pass | {fail, [gate_violation()]}.
```

**B. rebar3 provider (tcps metrology_validate)**
```bash
rebar3 tcps metrology_validate
rebar3 tcps metrology_validate --file=path/to/artifact.json
rebar3 tcps metrology_validate --report=path/to/report.md
```

**C. Common Test hook (erlmcp_metrology_ct_hook)**
- Automatically validates artifacts after each test
- Fails test on ERROR-severity violations
- Opt-in during transition (v1.5.0), mandatory later (v1.6.0)

**D. CI gate (.github/workflows/ci.yml)**
- Runs after all tests pass
- Blocks PR merge on violations
- Generates violation summary comment

### 3. Metrology Glossary

**File:** `/Users/sac/erlmcp/docs/metrology-glossary.md`

**Contents (40 pages):**
- A-Z canonical definitions (15 core terms)
- Disambiguation rules (7 rules matching stop-line conditions)
- Quick reference table (metric → unit → scope → required fields)
- Before/after examples for each violation type

**Key Terms Defined:**
- Connection vs Session (transport vs protocol)
- Message vs Request (frames vs operations)
- Throughput (msg/s vs req/s)
- Payload Size (wire bytes, pre-TLS)
- Memory Components (heap, process, ETS, total)
- Latency (transport, protocol, application)
- Scope (per_process, per_connection, per_node, per_cluster)
- Duration (time window for rates)
- Sample Size (statistical significance)
- Workload Pattern (constant, burst, ramp, sawtooth, random)

---

## Validation Stages

```
┌─────────────────────────────────────────────────────────────┐
│ Stage 1: Build-Time Validation (make compile)              │
│ - Validate shapes/metrology.schema.json is valid           │
│ - Fail fast: Exit code 1 on schema error                   │
└─────────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────────┐
│ Stage 2: Test Execution (rebar3 ct)                        │
│ - Tests emit JSON artifacts                                │
│ - CT hook validates in teardown                            │
│ - Fail test on ERROR-severity violations                   │
└─────────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────────┐
│ Stage 3: CI Gate (.github/workflows/ci.yml)                │
│ - Run: rebar3 tcps metrology_validate                      │
│ - Validate all dist/evidence/v1.5.0/*.json                 │
│ - Block merge if violations found                          │
└─────────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────────┐
│ Stage 4: Release Validation (pre-release hook)             │
│ - Generate metrology_compliance_report.md                  │
│ - Attach to GitHub release                                 │
└─────────────────────────────────────────────────────────────┘
```

---

## Example: Valid Measurement

```json
{
  "schema_version": "1.5.0",
  "artifact_type": "evidence",
  "workload_id": "throughput_baseline_tcp",
  "metadata": {
    "timestamp": "2026-01-27T20:51:45Z",
    "environment": "ci",
    "erlang_version": "25.3",
    "description": "Baseline throughput test with 1K concurrent TCP connections"
  },
  "measurements": [
    {
      "metric_name": "throughput",
      "value": 150000,
      "unit": {"dimension": "rate", "symbol": "req/s"},
      "scope": "per_node",
      "transport": "tcp",
      "duration_seconds": 60.0,
      "sample_size": 1000,
      "workload_details": {
        "concurrent_connections": 1000,
        "message_size_bytes": 4096,
        "request_pattern": "constant",
        "json_rpc_operations": ["tools/list", "tools/call"]
      },
      "notes": "Sustained load, 4KB payload, excludes 5s warmup"
    },
    {
      "metric_name": "latency_p99",
      "value": 2.1,
      "unit": {"dimension": "time", "symbol": "ms"},
      "scope": "per_connection",
      "transport": "tcp",
      "percentile": 99.0,
      "sample_size": 60000,
      "duration_seconds": 60.0,
      "notes": "Client-side measurement, includes network RTT"
    }
  ],
  "quality_gates": {
    "throughput_min_req_s": 95000,
    "latency_p99_max_ms": 5.0,
    "memory_max_mb": 512,
    "error_rate_max_percent": 0.01
  },
  "status": "PASS",
  "violations": []
}
```

---

## Example: Violations Detected

```json
{
  "schema_version": "1.5.0",
  "artifact_type": "evidence",
  "workload_id": "bad_example",
  "measurements": [
    {
      "metric_name": "throughput",
      "value": 150000
      // ❌ MISSING: unit, scope, transport, duration_seconds
    }
  ],
  "status": "FAIL",
  "violations": [
    {
      "rule": "missing_unit",
      "severity": "ERROR",
      "message": "Metric 'throughput' has no unit field (violates stop-line condition #1)",
      "measurement_index": 0
    },
    {
      "rule": "undefined_scope",
      "severity": "ERROR",
      "message": "Metric 'throughput' has no scope field (violates stop-line condition #3)",
      "measurement_index": 0
    },
    {
      "rule": "unanchored_duration",
      "severity": "ERROR",
      "message": "Metric 'throughput' is a rate metric but has no duration_seconds field (violates stop-line condition #4)",
      "measurement_index": 0
    }
  ]
}
```

---

## Canonical Metric Registry

| Metric Name | Unit Options | Scope Options | Required Fields | Description |
|-------------|--------------|---------------|-----------------|-------------|
| throughput | msg/s, req/s, ops/s | per_node, per_cluster | duration_seconds, workload_details | Operations per second |
| latency_p50 | ms | per_connection, per_node | sample_size, percentile, duration_seconds | 50th percentile latency |
| latency_p95 | ms | per_connection, per_node | sample_size, percentile, duration_seconds | 95th percentile latency |
| latency_p99 | ms | per_connection, per_node | sample_size, percentile, duration_seconds | 99th percentile latency |
| latency_p99_9 | ms | per_connection, per_node | sample_size, percentile, duration_seconds | 99.9th percentile latency |
| memory_heap | MiB | per_process | - | Erlang process heap only |
| memory_process | MiB | per_process | - | Heap + stack + mailbox |
| memory_ets | MiB | per_node | - | ETS table memory |
| memory_total | MiB, GiB | per_node | - | OS-reported RSS |
| cpu_utilization | % | per_node | duration_seconds | CPU usage percentage |
| gc_pause_avg | ms | per_process, per_node | sample_size | Average GC pause |
| gc_pause_max | ms | per_process, per_node | sample_size | Maximum GC pause |
| gc_count | count | per_process, per_node | duration_seconds | GC execution count |
| connection_count | count | per_node | - | Active connections |
| message_queue_len | count | per_process | - | Process mailbox depth |
| error_rate | % | per_node, per_connection | sample_size, duration_seconds | Operation error rate |
| success_rate | % | per_node, per_connection | sample_size, duration_seconds | Operation success rate |
| bandwidth | Mbps, MiB/s | per_connection, per_node | duration_seconds | Network throughput |
| payload_size | B, KiB | dimensionless | - | Message body size |

---

## Backwards Compatibility

### Migration Strategy

**Challenge:** 200+ existing JSON artifacts don't conform to v1.5.0 schema.

**Solution:** Migration script + parallel validation.

**Script:** `scripts/migrate_metrology_artifacts.escript`

**Function:**
1. Parse legacy artifacts (v1.3.0, v1.4.0)
2. Transform to v1.5.0 schema:
   - Add schema_version, artifact_type
   - Infer scope from context (heuristics)
   - Wrap naked numbers in unit objects
   - Add default duration_seconds (60s)
3. Write to dist/evidence/v1.5.0/
4. Log unresolvable ambiguities

**Parallel Structure (Transition):**
```
dist/evidence/
├── v1.3.0/          # Legacy (unchanged)
├── v1.4.0/          # Legacy (unchanged)
└── v1.5.0/          # NEW: Schema-compliant
    ├── benchmarks/
    ├── chaos/
    └── metrology_compliance_report.md
```

**Timeline:**
- **v1.5.0:** Both formats coexist, CI validates v1.5.0/ only
- **v1.6.0:** Legacy archived (read-only)
- **v2.0.0:** Legacy removed

### Test Migration

**Phase 1 (v1.5.0):** Opt-in
- CT hook warns on violations (doesn't fail)
- Incremental fix by developers

**Phase 2 (v1.6.0):** Mandatory for new tests
- CT hook fails new tests on violations
- Legacy tests grandfathered

**Phase 3 (v2.0.0):** Full enforcement
- All tests must emit v1.5.0 artifacts

**Helper Functions:**
```erlang
%% In test/metrology_helpers.erl
-spec emit_measurement(MetricName, Value, Opts) -> ok.

%% Usage in test:
metrology_helpers:emit_measurement(throughput, 150000, #{
    unit => #{dimension => rate, symbol => 'req/s'},
    scope => per_node,
    transport => tcp,
    duration_seconds => 60.0,
    sample_size => 1000,
    workload_details => #{
        concurrent_connections => 1000,
        message_size_bytes => 4096,
        request_pattern => constant
    }
}).
```

---

## Quality Gates

**Defined in:** shapes/metrology.schema.json (quality_gates object)

**Default Thresholds (v1.5.0):**
```json
{
  "quality_gates": {
    "throughput_min_req_s": 95000,
    "latency_p99_max_ms": 5.0,
    "memory_max_mb": 512,
    "error_rate_max_percent": 0.01,
    "regression_tolerance_percent": 5.0
  }
}
```

**Validation Logic:**
1. Load gates from artifact or use defaults
2. Check each measurement against gate
3. Return pass | {fail, [gate_violation()]}

**Example Failure:**
```json
{
  "gate": "latency_p99_max_ms",
  "threshold": 5.0,
  "actual": 6.2,
  "severity": "ERROR",
  "message": "p99 latency (6.2ms) exceeds threshold (5.0ms) by 24%"
}
```

---

## Implementation Plan

### Phase 1: Core Validation (Week 1)
1. ✅ shapes/metrology.schema.json (DONE)
2. src/erlmcp_metrology_validator.erl (gen_server with jesse)
3. test/erlmcp_metrology_validator_tests.erl (unit tests)
4. ✅ docs/metrology-glossary.md (DONE)

### Phase 2: CI Integration (Week 2)
1. src/rebar3_tcps_metrology.erl (rebar3 provider)
2. test/erlmcp_metrology_ct_hook.erl (CT hook)
3. .github/workflows/validate_metrology.sh (CI script)
4. Update .github/workflows/ci.yml

### Phase 3: Migration (Week 3)
1. scripts/migrate_metrology_artifacts.escript
2. Create dist/evidence/v1.5.0/ structure
3. Migrate 90%+ of v1.4.0 artifacts
4. Generate metrology_compliance_report.md

### Phase 4: Test Migration (Week 4-6)
1. test/metrology_helpers.erl (helper API)
2. Migrate 10 high-value test suites
3. Update test documentation

### Phase 5: Full Enforcement (v1.6.0)
1. Switch CT hook to fail-on-violation
2. Archive legacy directories
3. Update docs

---

## Supervision Tree Impact

**No new supervisors required.**

**Integration Point:**
- erlmcp_metrology_validator as named gen_server under erlmcp_sup
- Lifetime: permanent (application-level)
- Restart: transient (crash doesn't affect tests)

**Child Spec:**
```erlang
#{
    id => erlmcp_metrology_validator,
    start => {erlmcp_metrology_validator, start_link, []},
    restart => transient,
    shutdown => 5000,
    type => worker
}
```

---

## Rationale & Tradeoffs

### 1. JSON Schema vs SHACL
**Decision:** JSON Schema (Draft-07)
**Rationale:** Better Erlang support (jesse), developer familiarity, performance
**Tradeoff:** Less semantic reasoning than SHACL (accepted)

### 2. Fail-Fast vs Collect-All-Errors
**Decision:** Fail on first ERROR
**Rationale:** Clear feedback, CI efficiency, encourages discipline
**Tradeoff:** Developers might prefer all errors (accepted)

### 3. Centralized Validator vs Embedded
**Decision:** Single gen_server
**Rationale:** Schema compilation caching, single source of truth
**Tradeoff:** Single point of failure (mitigated with transient restart)

### 4. 7 Stop-Line Conditions
**Decision:** Enumerate specific violations
**Rationale:** Traceability, education, kaizen metrics
**Tradeoff:** More complex handling (precision > simplicity)

---

## Success Metrics

**Goal:** Eliminate violations from v1.6.0 forward.

**Tracking:**
1. **Violation Rate:** Violations per 100 artifacts (target: <1)
2. **CI Pass Rate:** % of PRs passing first try (target: >95%)
3. **Migration Coverage:** % of legacy artifacts migrated (target: >90%)
4. **Developer Adoption:** % of tests using helpers (target: >80%)

**Dashboard:** TCPS (erlmcp_dashboard_http)

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|-----------|
| Schema too strict | HIGH | Opt-out via notes field |
| Migration misclassifies | MEDIUM | Manual review of 10% sample |
| Performance regression | LOW | Benchmark <1ms per artifact |
| Developer resistance | MEDIUM | Helpers + docs + staged rollout |
| Legacy never migrates | MEDIUM | Parallel structure (coexist until v2.0) |

---

## Documentation Index

### Core Design Documents
1. ✅ **shapes/metrology.schema.json** - JSON Schema definition
2. ✅ **docs/v1.5.0-metrology-validation-architecture.md** - 80-page architecture (this document's source)
3. ✅ **docs/metrology-glossary.md** - 40-page canonical definitions

### To Be Created (Implementation Phase)
4. **docs/metrology-developer-guide.md** - Quick start for developers
5. **docs/metrology-ci-integration.md** - GitHub Actions / Jenkins setup
6. **docs/metrology-compliance-checklist.md** - Release manager checklist

### Code Modules (To Be Implemented)
1. **src/erlmcp_metrology_validator.erl** - Core validator (gen_server)
2. **src/rebar3_tcps_metrology.erl** - Rebar3 provider
3. **test/erlmcp_metrology_ct_hook.erl** - Common Test hook
4. **test/metrology_helpers.erl** - Helper API for tests
5. **scripts/migrate_metrology_artifacts.escript** - Migration script

---

## Next Steps

1. **Review this design** with stakeholders:
   - plan-designer (workflow coordination)
   - erlang-otp-developer (implementation feasibility)
   - erlang-test-engineer (test migration strategy)

2. **Approve deliverables:**
   - ✅ shapes/metrology.schema.json
   - ✅ docs/v1.5.0-metrology-validation-architecture.md
   - ✅ docs/metrology-glossary.md

3. **Begin Phase 1 implementation:**
   - Assign to erlang-otp-developer
   - Timeline: 1 week
   - Acceptance criteria: All unit tests pass, validator works end-to-end

4. **Validate PoC:**
   - Migrate 1 test suite (throughput_SUITE.erl)
   - Run CI gate on migrated artifact
   - Verify all 7 stop-line conditions caught

5. **Iterate and roll out:**
   - Collect feedback from PoC
   - Adjust schema/validator as needed
   - Proceed with Phases 2-5

---

## Questions for Review

1. **Schema Coverage:** Are there metrics in existing tests NOT covered by the 18 canonical metrics?
2. **Migration Heuristics:** Are the scope/transport inference rules sufficient, or do we need manual annotation?
3. **Quality Gates:** Are the default thresholds (95K req/s, 5ms p99) appropriate for all tiers (team/enterprise/gov)?
4. **Timeline:** Is 6 weeks realistic for full implementation + migration + enforcement?
5. **Rollout Strategy:** Should we enforce validation in CI immediately (v1.5.0) or wait for v1.6.0?

---

## Appendix: 7 Stop-Line Conditions (Quick Reference)

| # | Condition | Rule | Example Violation | Fix |
|---|-----------|------|-------------------|-----|
| 1 | Naked numbers | missing_unit | `{"value": 150000}` | Add `unit: {dimension: "rate", symbol: "msg/s"}` |
| 2 | Ambiguous metrics | ambiguous_metric | `{"metric_name": "throughput"}` without clarification | Add `workload_details.json_rpc_operations` + specify `req/s` or `msg/s` |
| 3 | Undefined scope | undefined_scope | `{"metric_name": "memory_heap"}` without scope | Add `scope: "per_process"` |
| 4 | Unanchored duration | unanchored_duration | `{"metric_name": "throughput"}` without time window | Add `duration_seconds: 60.0` |
| 5 | Mixed context | mixed_context | Latency without specifying connection vs session | Add `scope: "per_connection"` + `transport: "tcp"` + clarify in notes |
| 6 | Unlabeled memory | unlabeled_memory | `{"metric_name": "memory"}` (generic) | Use `memory_heap`, `memory_process`, `memory_ets`, or `memory_total` |
| 7 | Zero sample size | zero_sample_size | `{"metric_name": "latency_p99"}` without N | Add `sample_size: 10000` + `percentile: 99.0` |

---

**Status:** Design Complete
**Approval Required From:**
- plan-designer (workflow integration)
- erlang-otp-developer (implementation feasibility)
- erlang-test-engineer (test migration)

**Once approved, proceed to Phase 1 implementation.**

---

**Version:** 1.5.0
**Agent:** erlang-architect
**Date:** 2026-01-27
