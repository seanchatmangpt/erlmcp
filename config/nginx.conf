# Nginx Configuration - erlmcp Load Balancer
#
# Distributes 100K concurrent connections across 4-node erlmcp cluster
# - 25K connections per node
# - Round-robin load balancing with sticky sessions
# - Health checks every 3 seconds
# - Automatic failover with graceful degradation
#
# Usage:
#   nginx -c $(pwd)/config/nginx.conf
#   nginx -s reload
#   nginx -s stop

user nobody;
worker_processes auto;
worker_rlimit_nofile 200000;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 100000;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging with performance details
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time" '
                    'upstream: $upstream_addr';

    access_log /var/log/nginx/access.log main buffer=32k flush=5s;

    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 300s;
    keepalive_requests 1000;
    types_hash_max_size 2048;
    client_max_body_size 16M;

    # Upstream resolver (for health checks)
    resolver 8.8.8.8 8.8.4.4 valid=10s;
    resolver_timeout 5s;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript application/json application/javascript application/xml+rss application/rss+xml font/truetype font/opentype application/vnd.ms-fontobject image/svg+xml;

    ###########################################################################
    # UPSTREAM DEFINITION - 4-node erlmcp cluster
    ###########################################################################

    # TCP/MCP protocol upstream (port 9001-9004)
    upstream erlmcp_tcp_cluster {
        # Least connections algorithm for better load distribution
        least_conn;

        # Sticky sessions using IP hash
        # Ensures same client always connects to same upstream server
        ip_hash;

        # Keep-alive connections to backends
        keepalive 256;
        keepalive_requests 100;
        keepalive_timeout 60s;

        # Node 1: Port 9001 (TCP MCP protocol)
        server localhost:9001 max_fails=2 fail_timeout=10s weight=1;

        # Node 2: Port 9002
        server localhost:9002 max_fails=2 fail_timeout=10s weight=1;

        # Node 3: Port 9003
        server localhost:9003 max_fails=2 fail_timeout=10s weight=1;

        # Node 4: Port 9004
        server localhost:9004 max_fails=2 fail_timeout=10s weight=1;
    }

    # HTTP upstream (port 8080-8083)
    upstream erlmcp_http_cluster {
        least_conn;
        ip_hash;
        keepalive 256;
        keepalive_requests 100;
        keepalive_timeout 60s;

        server localhost:8080 max_fails=2 fail_timeout=10s weight=1;
        server localhost:8081 max_fails=2 fail_timeout=10s weight=1;
        server localhost:8082 max_fails=2 fail_timeout=10s weight=1;
        server localhost:8083 max_fails=2 fail_timeout=10s weight=1;
    }

    # WebSocket upstream
    upstream erlmcp_websocket_cluster {
        least_conn;
        ip_hash;
        keepalive 256;
        keepalive_timeout 300s;

        server localhost:8080 max_fails=2 fail_timeout=10s weight=1;
        server localhost:8081 max_fails=2 fail_timeout=10s weight=1;
        server localhost:8082 max_fails=2 fail_timeout=10s weight=1;
        server localhost:8083 max_fails=2 fail_timeout=10s weight=1;
    }

    # SSE upstream
    upstream erlmcp_sse_cluster {
        least_conn;
        ip_hash;
        keepalive 256;
        keepalive_timeout 300s;

        server localhost:8081 max_fails=2 fail_timeout=10s weight=1;
        server localhost:8082 max_fails=2 fail_timeout=10s weight=1;
        server localhost:8083 max_fails=2 fail_timeout=10s weight=1;
        server localhost:8084 max_fails=2 fail_timeout=10s weight=1;
    }

    ###########################################################################
    # RATE LIMITING CONFIGURATION
    ###########################################################################

    # Per-IP rate limiting: max 100 requests/second per client
    limit_req_zone $binary_remote_addr zone=http_limit:10m rate=100r/s;
    limit_req_zone $binary_remote_addr zone=ws_limit:10m rate=100r/s;
    limit_req_zone $binary_remote_addr zone=sse_limit:10m rate=100r/s;

    # Connection limiting
    limit_conn_zone $binary_remote_addr zone=addr:10m;
    limit_conn addr 100;

    ###########################################################################
    # MAP - For sticky sessions via cookies
    ###########################################################################

    # Map to extract session ID from cookie or create new one
    map $cookie_SERVERID $route_id {
        default $cookie_SERVERID;
        "" $msec;
    }

    ###########################################################################
    # SERVER - TCP stream proxy (for non-HTTP MCP connections)
    ###########################################################################

    # Note: TCP proxying in nginx requires stream module compilation
    # For HTTP/WebSocket, use the server block below
    # This is a simplified HTTP wrapper for TCP connections

    ###########################################################################
    # SERVER - HTTP Load Balancer (Port 8000 - MCP HTTP)
    ###########################################################################

    server {
        listen 8000;
        listen [::]:8000;
        server_name _;

        # Logging for this server
        access_log /var/log/nginx/mcp_http.log main;
        error_log /var/log/nginx/mcp_http_error.log warn;

        # Connection limiting
        limit_req zone=http_limit burst=200 nodelay;

        # Proxy settings
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
        proxy_busy_buffers_size 8k;
        proxy_max_temp_file_size 2m;
        proxy_temp_file_write_size 32k;

        # Timeouts
        proxy_connect_timeout 5s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;

        # Headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Request-ID $request_id;
        proxy_set_header Connection "";

        # Sticky session cookie
        add_header Set-Cookie "SERVERID=$route_id; Path=/; Max-Age=86400" always;

        location / {
            # Route to HTTP cluster
            proxy_pass http://erlmcp_http_cluster;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }
    }

    ###########################################################################
    # SERVER - WebSocket Load Balancer (Port 8001)
    ###########################################################################

    server {
        listen 8001;
        listen [::]:8001;
        server_name _;

        access_log /var/log/nginx/mcp_websocket.log main;
        error_log /var/log/nginx/mcp_websocket_error.log warn;

        # WebSocket specific rate limiting
        limit_req zone=ws_limit burst=200 nodelay;

        location /mcp/ws {
            # WebSocket proxy
            proxy_pass http://erlmcp_websocket_cluster;
            proxy_http_version 1.1;

            # WebSocket headers
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "Upgrade";

            # Standard headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Sticky sessions for WebSocket
            proxy_set_header SERVERID $route_id;

            # Timeouts (long for WebSocket keep-alive)
            proxy_connect_timeout 5s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;

            # Buffering off for real-time WebSocket
            proxy_buffering off;
            proxy_request_buffering off;
        }
    }

    ###########################################################################
    # SERVER - SSE Load Balancer (Port 8002)
    ###########################################################################

    server {
        listen 8002;
        listen [::]:8002;
        server_name _;

        access_log /var/log/nginx/mcp_sse.log main;
        error_log /var/log/nginx/mcp_sse_error.log warn;

        limit_req zone=sse_limit burst=200 nodelay;

        location /mcp/sse {
            # SSE proxy
            proxy_pass http://erlmcp_sse_cluster;
            proxy_http_version 1.1;

            # SSE headers
            proxy_set_header Content-Type text/event-stream;
            proxy_set_header Cache-Control no-cache;
            proxy_set_header Connection keep-alive;

            # Standard headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Sticky sessions for SSE
            proxy_set_header SERVERID $route_id;

            # Timeouts (long for SSE streaming)
            proxy_connect_timeout 5s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;

            # No buffering for real-time SSE
            proxy_buffering off;
            proxy_request_buffering off;
        }
    }

    ###########################################################################
    # SERVER - Health Check Endpoint (Port 8888)
    ###########################################################################

    server {
        listen 8888;
        listen [::]:8888;
        server_name _;

        access_log off;

        # Simple health check endpoint
        location /health {
            return 200 "Nginx health check OK\n";
            add_header Content-Type text/plain;
        }

        # Status page for monitoring
        location /nginx_status {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            allow ::1;
            deny all;
        }
    }

    ###########################################################################
    # SERVER - HTTPS Load Balancer (Port 8443, optional TLS termination)
    ###########################################################################

    # Uncomment if HTTPS termination is needed
    # Requires SSL certificates at /etc/ssl/certs/nginx.crt and /etc/ssl/private/nginx.key

    # server {
    #     listen 8443 ssl http2;
    #     listen [::]:8443 ssl http2;
    #     server_name _;

    #     # SSL certificates
    #     ssl_certificate /etc/ssl/certs/nginx.crt;
    #     ssl_certificate_key /etc/ssl/private/nginx.key;

    #     # SSL protocols and ciphers
    #     ssl_protocols TLSv1.2 TLSv1.3;
    #     ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-CHACHA20-POLY1305;
    #     ssl_prefer_server_ciphers on;
    #     ssl_session_cache shared:SSL:10m;
    #     ssl_session_timeout 10m;

    #     # HSTS
    #     add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    #     location / {
    #         proxy_pass http://erlmcp_http_cluster;
    #         proxy_http_version 1.1;
    #         proxy_set_header Host $host;
    #         proxy_set_header X-Real-IP $remote_addr;
    #         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    #         proxy_set_header X-Forwarded-Proto https;
    #     }
    # }
}
