%% ErlMCP Monitoring Configuration
%% 24/7 Observability and Alerting Configuration

{monitor, #{
    %% Collection and timing settings
    check_interval_ms => 5000,              %% Health check interval (5 seconds)
    collection_interval_ms => 10000,        %% Metrics collection interval (10 seconds)
    alert_cooldown_ms => 300000,             %% Default alert cooldown (5 minutes)
    health_check_timeout_ms => 2000,         %% Health check timeout (2 seconds)
    
    %% Data retention settings
    metrics_retention_hours => 24,           %% Keep metrics for 24 hours
    max_metric_history => 8640,              %% 24h * 60min/h * 6samples/min = 8640 samples
    max_alert_history => 10000,              %% Keep last 10k alerts
    max_history_entries => 1000,             %% Dashboard history entries
    
    %% Feature toggles
    dashboard_enabled => true,               %% Enable web dashboard
    alerts_enabled => true,                  %% Enable alerting
    metrics_enabled => true,                 %% Enable metrics collection
    
    %% Dashboard settings
    dashboard_port => 8080,                  %% Dashboard HTTP port
    
    %% Alert handlers
    alert_handlers => [console, log],        %% Default alert channels
    
    %% SLA Objectives
    sla_objectives => [
        #{
            name => <<"high_availability">>,
            description => <<"99.95% availability SLA">>,
            target => 99.95,
            threshold => 99.5,
            measurement_window_ms => 3600000    %% 1 hour window
        },
        #{
            name => <<"low_latency">>,
            description => <<"P95 response time under 500ms">>,
            target => 500.0,
            threshold => 1000.0,
            measurement_window_ms => 1800000    %% 30 minute window
        },
        #{
            name => <<"reliability">>,
            description => <<"Error rate under 0.1%">>,
            target => 0.1,
            threshold => 1.0,
            measurement_window_ms => 3600000    %% 1 hour window
        }
    ],
    
    %% Notification Channels
    notification_channels => #{
        email => #{
            type => email,
            enabled => false,
            config => #{
                smtp_server => "smtp.example.com",
                smtp_port => 587,
                username => "alerts@example.com",
                password => "password",
                recipients => ["admin@example.com", "ops@example.com"]
            },
            rate_limit => #{count => 5, window_ms => 300000}  %% 5 per 5 minutes
        },
        
        slack => #{
            type => slack,
            enabled => false,
            config => #{
                webhook_url => "https://hooks.slack.com/services/YOUR/WEBHOOK/URL",
                channel => "#alerts",
                username => "ErlMCP Monitor"
            },
            rate_limit => #{count => 10, window_ms => 300000}  %% 10 per 5 minutes
        },
        
        webhook => #{
            type => webhook,
            enabled => false,
            config => #{
                url => "https://example.com/webhook/alerts",
                method => post,
                headers => #{
                    "Content-Type" => "application/json",
                    "Authorization" => "Bearer YOUR_TOKEN"
                },
                timeout_ms => 5000
            },
            rate_limit => #{count => 20, window_ms => 300000}  %% 20 per 5 minutes
        },
        
        sms => #{
            type => sms,
            enabled => false,
            config => #{
                provider => "twilio",
                account_sid => "YOUR_ACCOUNT_SID",
                auth_token => "YOUR_AUTH_TOKEN",
                phone_numbers => ["+1234567890"]
            },
            rate_limit => #{count => 3, window_ms => 900000}   %% 3 per 15 minutes (expensive!)
        }
    },
    
    %% Threshold Configuration
    thresholds => #{
        %% Response time thresholds
        latency_warning_ms => 1000,
        latency_critical_ms => 5000,
        
        %% Error rate thresholds
        error_rate_warning_percent => 1.0,
        error_rate_critical_percent => 5.0,
        
        %% Memory usage thresholds
        memory_usage_warning_percent => 75.0,
        memory_usage_critical_percent => 90.0,
        
        %% Connection failure thresholds
        connection_failure_warning_rate => 5.0,
        connection_failure_critical_rate => 15.0,
        
        %% Process count thresholds
        process_count_warning => 100000,
        process_count_critical => 200000,
        
        %% Health score thresholds
        health_score_warning => 0.7,
        health_score_critical => 0.5
    },
    
    %% Alert Rules Configuration
    alert_rules => [
        #{
            id => <<"system_high_latency">>,
            name => <<"System High Response Latency">>,
            description => <<"Average response time exceeds 1 second">>,
            metric => <<"avg_response_time_ms">>,
            condition => <<"gt">>,
            threshold => 1000,
            severity => warning,
            cooldown_ms => 300000,          %% 5 minutes
            enabled => true,
            tags => [<<"performance">>, <<"latency">>]
        },
        
        #{
            id => <<"system_critical_latency">>,
            name => <<"System Critical Response Latency">>,
            description => <<"Average response time exceeds 5 seconds">>,
            metric => <<"avg_response_time_ms">>,
            condition => <<"gt">>,
            threshold => 5000,
            severity => critical,
            cooldown_ms => 180000,          %% 3 minutes
            enabled => true,
            tags => [<<"performance">>, <<"latency">>, <<"critical">>]
        },
        
        #{
            id => <<"high_error_rate">>,
            name => <<"High Error Rate">>,
            description => <<"Error rate exceeds 1%">>,
            metric => <<"error_rate_percent">>,
            condition => <<"gt">>,
            threshold => 1.0,
            severity => warning,
            cooldown_ms => 180000,          %% 3 minutes
            enabled => true,
            tags => [<<"errors">>, <<"reliability">>]
        },
        
        #{
            id => <<"critical_error_rate">>,
            name => <<"Critical Error Rate">>,
            description => <<"Error rate exceeds 5%">>,
            metric => <<"error_rate_percent">>,
            condition => <<"gt">>,
            threshold => 5.0,
            severity => critical,
            cooldown_ms => 120000,          %% 2 minutes
            enabled => true,
            tags => [<<"errors">>, <<"reliability">>, <<"critical">>]
        },
        
        #{
            id => <<"high_memory_usage">>,
            name => <<"High Memory Usage">>,
            description => <<"Memory usage exceeds 75%">>,
            metric => <<"memory_usage_percent">>,
            condition => <<"gt">>,
            threshold => 75.0,
            severity => warning,
            cooldown_ms => 600000,          %% 10 minutes
            enabled => true,
            tags => [<<"memory">>, <<"resources">>]
        },
        
        #{
            id => <<"critical_memory_usage">>,
            name => <<"Critical Memory Usage">>,
            description => <<"Memory usage exceeds 90%">>,
            metric => <<"memory_usage_percent">>,
            condition => <<"gt">>,
            threshold => 90.0,
            severity => critical,
            cooldown_ms => 300000,          %% 5 minutes
            enabled => true,
            tags => [<<"memory">>, <<"resources">>, <<"critical">>]
        },
        
        #{
            id => <<"connection_failures">>,
            name => <<"High Connection Failure Rate">>,
            description => <<"Connection failure rate exceeds 5%">>,
            metric => <<"connection_failure_rate">>,
            condition => <<"gt">>,
            threshold => 5.0,
            severity => warning,
            cooldown_ms => 240000,          %% 4 minutes
            enabled => true,
            tags => [<<"connectivity">>, <<"reliability">>]
        },
        
        #{
            id => <<"critical_connection_failures">>,
            name => <<"Critical Connection Failures">>,
            description => <<"Connection failure rate exceeds 15%">>,
            metric => <<"connection_failure_rate">>,
            condition => <<"gt">>,
            threshold => 15.0,
            severity => critical,
            cooldown_ms => 120000,          %% 2 minutes
            enabled => true,
            tags => [<<"connectivity">>, <<"reliability">>, <<"critical">>]
        },
        
        #{
            id => <<"service_degraded">>,
            name => <<"Service Degraded">>,
            description => <<"Overall health score below 70%">>,
            metric => <<"overall_health_score">>,
            condition => <<"lt">>,
            threshold => 0.7,
            severity => warning,
            cooldown_ms => 300000,          %% 5 minutes
            enabled => true,
            tags => [<<"health">>, <<"availability">>]
        },
        
        #{
            id => <<"service_critical">>,
            name => <<"Service Critical">>,
            description => <<"Overall health score below 50%">>,
            metric => <<"overall_health_score">>,
            condition => <<"lt">>,
            threshold => 0.5,
            severity => critical,
            cooldown_ms => 60000,           %% 1 minute
            enabled => true,
            tags => [<<"health">>, <<"availability">>, <<"critical">>]
        },
        
        #{
            id => <<"process_count_high">>,
            name => <<"High Process Count">>,
            description => <<"Erlang process count exceeds 100,000">>,
            metric => <<"process_count">>,
            condition => <<"gt">>,
            threshold => 100000,
            severity => warning,
            cooldown_ms => 900000,          %% 15 minutes
            enabled => true,
            tags => [<<"processes">>, <<"resources">>]
        },
        
        #{
            id => <<"sla_violation">>,
            name => <<"SLA Violation">>,
            description => <<"One or more SLA objectives are being violated">>,
            metric => <<"sla_violations">>,
            condition => <<"gt">>,
            threshold => 0,
            severity => critical,
            cooldown_ms => 300000,          %% 5 minutes
            enabled => true,
            tags => [<<"sla">>, <<"compliance">>, <<"critical">>]
        }
    ],
    
    %% Custom Metrics Collectors
    custom_collectors => [
        %% Example custom collector
        {<<"custom_metric_1">>, fun() -> rand:uniform(100) end}
    ],
    
    %% Advanced Settings
    advanced => #{
        %% Metric aggregation settings
        aggregation_window_ms => 60000,     %% 1 minute aggregation windows
        percentiles => [50, 75, 90, 95, 99], %% Calculate these percentiles
        
        %% Health check weights (for composite health score)
        health_weights => #{
            transports => 0.25,
            registry => 0.15,
            memory => 0.20,
            connections => 0.20,
            processes => 0.10,
            dependencies => 0.10
        },
        
        %% Escalation settings
        escalation_enabled => true,
        max_escalation_level => 3,
        
        %% Rate limiting for health checks
        health_check_rate_limit => #{
            max_checks_per_second => 10,
            burst_size => 20
        },
        
        %% Anomaly detection (future feature)
        anomaly_detection => #{
            enabled => false,
            sensitivity => 0.8,
            learning_window_hours => 168  %% 1 week
        }
    }
}}.