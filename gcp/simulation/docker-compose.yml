# ============================================================================
# GCP Simulation Stack - Docker Compose
# ============================================================================
# CONSTITUTION: DOCKER-ONLY CONSTITUTION
#
# Simulates GCP services locally for development and testing without
# requiring actual GCP credentials or resources.
#
# Service Mapping:
#   Cloud SQL (PostgreSQL)  -> postgres
#   Cloud Memorystore       -> redis
#   Cloud Storage (GCS)     -> minio
#   Secret Manager          -> vault
#   Cloud KMS               -> vault
#   Artifact Registry       -> registry
#   Pub/Sub                 -> pubsub-emulator
#   Firestore               -> firestore-emulator
#   Cloud Monitoring        -> prometheus + grafana
#   Cloud Logging           -> loki
#   Cloud Load Balancer     -> traefik
#   GKE                     -> k3s (optional)
# ============================================================================

name: erlmcp-gcp-simulation

services:
  # ==========================================================================
  # Cloud SQL Simulation (PostgreSQL 16)
  # ==========================================================================
  postgres:
    image: postgres:16-alpine
    container_name: gcp-cloudsql
    hostname: cloudsql.gcp.local
    environment:
      POSTGRES_USER: erlmcp
      POSTGRES_PASSWORD: ${DB_PASSWORD:-erlmcp_secret}
      POSTGRES_DB: erlmcp_dev
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./config/postgres/init.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U erlmcp -d erlmcp_dev"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - cloudsql.gcp.local
          - postgres.gcp.local
    labels:
      gcp.service: "cloudsql"
      gcp.equivalent: "google_sql_database_instance"

  # ==========================================================================
  # Cloud Memorystore Simulation (Redis 7)
  # ==========================================================================
  redis:
    image: redis:7-alpine
    container_name: gcp-memorystore
    hostname: memorystore.gcp.local
    command: >
      redis-server
      --appendonly yes
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD:-erlmcp_redis}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-erlmcp_redis}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - memorystore.gcp.local
          - redis.gcp.local
    labels:
      gcp.service: "memorystore"
      gcp.equivalent: "google_redis_instance"

  # ==========================================================================
  # Cloud Storage Simulation (MinIO - S3/GCS compatible)
  # ==========================================================================
  minio:
    image: minio/minio:latest
    container_name: gcp-cloudstorage
    hostname: storage.gcp.local
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY:-erlmcp_storage}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY:-erlmcp_storage_secret}
      MINIO_DOMAIN: storage.gcp.local
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"   # S3/GCS API
      - "9001:9001"   # Console
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      gcp-simulation:
        aliases:
          - storage.gcp.local
          - minio.gcp.local
    labels:
      gcp.service: "cloudstorage"
      gcp.equivalent: "google_storage_bucket"

  # MinIO bucket initialization
  minio-init:
    image: minio/mc:latest
    container_name: gcp-cloudstorage-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set gcs http://minio:9000 erlmcp_storage erlmcp_storage_secret;
      mc mb gcs/erlmcp-terraform-state --ignore-existing;
      mc mb gcs/erlmcp-artifacts --ignore-existing;
      mc mb gcs/erlmcp-backups --ignore-existing;
      mc mb gcs/erlmcp-logs --ignore-existing;
      mc anonymous set download gcs/erlmcp-artifacts;
      echo 'Buckets created successfully';
      "
    networks:
      - gcp-simulation

  # ==========================================================================
  # Secret Manager + Cloud KMS Simulation (HashiCorp Vault)
  # ==========================================================================
  vault:
    image: hashicorp/vault:1.15
    container_name: gcp-secretmanager
    hostname: secrets.gcp.local
    cap_add:
      - IPC_LOCK
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_TOKEN:-erlmcp_vault_token}
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
      VAULT_ADDR: http://127.0.0.1:8200
    volumes:
      - vault_data:/vault/data
      - ./config/vault/policies:/vault/policies:ro
    ports:
      - "8200:8200"
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - secrets.gcp.local
          - kms.gcp.local
          - vault.gcp.local
    labels:
      gcp.service: "secretmanager,cloudkms"
      gcp.equivalent: "google_secret_manager_secret,google_kms_crypto_key"

  # Vault initialization with secrets
  vault-init:
    image: hashicorp/vault:1.15
    container_name: gcp-secretmanager-init
    depends_on:
      vault:
        condition: service_healthy
    environment:
      VAULT_ADDR: http://vault:8200
      VAULT_TOKEN: ${VAULT_TOKEN:-erlmcp_vault_token}
    entrypoint: >
      /bin/sh -c "
      sleep 2;
      vault secrets enable -path=erlmcp kv-v2 2>/dev/null || true;
      vault kv put erlmcp/database-url url='postgresql://erlmcp:erlmcp_secret@postgres:5432/erlmcp_dev';
      vault kv put erlmcp/api-keys primary='dev-api-key-12345' secondary='dev-api-key-67890';
      vault kv put erlmcp/jwt-secret secret='dev-jwt-secret-very-long-string-for-signing';
      vault secrets enable transit 2>/dev/null || true;
      vault write -f transit/keys/erlmcp-app-key type=aes256-gcm96;
      echo 'Vault secrets initialized';
      "
    networks:
      - gcp-simulation

  # ==========================================================================
  # Artifact Registry Simulation (Docker Registry)
  # ==========================================================================
  registry:
    image: registry:2
    container_name: gcp-artifactregistry
    hostname: registry.gcp.local
    environment:
      REGISTRY_HTTP_ADDR: 0.0.0.0:5000
      REGISTRY_STORAGE_DELETE_ENABLED: "true"
    volumes:
      - registry_data:/var/lib/registry
    ports:
      - "5000:5000"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:5000/v2/"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - registry.gcp.local
          - artifactregistry.gcp.local
    labels:
      gcp.service: "artifactregistry"
      gcp.equivalent: "google_artifact_registry_repository"

  # ==========================================================================
  # Pub/Sub Emulator
  # ==========================================================================
  pubsub-emulator:
    image: gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators
    container_name: gcp-pubsub
    hostname: pubsub.gcp.local
    command: gcloud beta emulators pubsub start --host-port=0.0.0.0:8085 --project=erlmcp-local
    ports:
      - "8085:8085"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8085"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - pubsub.gcp.local
    labels:
      gcp.service: "pubsub"
      gcp.equivalent: "google_pubsub_topic"

  # Pub/Sub topic/subscription initialization
  pubsub-init:
    image: gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators
    container_name: gcp-pubsub-init
    depends_on:
      pubsub-emulator:
        condition: service_healthy
    environment:
      PUBSUB_EMULATOR_HOST: pubsub-emulator:8085
    entrypoint: >
      /bin/sh -c "
      sleep 3;
      curl -s -X PUT http://pubsub-emulator:8085/v1/projects/erlmcp-local/topics/erlmcp-events || true;
      curl -s -X PUT http://pubsub-emulator:8085/v1/projects/erlmcp-local/topics/erlmcp-notifications || true;
      curl -s -X PUT http://pubsub-emulator:8085/v1/projects/erlmcp-local/subscriptions/erlmcp-events-sub \
        -H 'Content-Type: application/json' \
        -d '{\"topic\":\"projects/erlmcp-local/topics/erlmcp-events\"}' || true;
      echo 'Pub/Sub topics created';
      "
    networks:
      - gcp-simulation

  # ==========================================================================
  # Firestore Emulator
  # ==========================================================================
  firestore-emulator:
    image: gcr.io/google.com/cloudsdktool/google-cloud-cli:emulators
    container_name: gcp-firestore
    hostname: firestore.gcp.local
    command: gcloud emulators firestore start --host-port=0.0.0.0:8086 --project=erlmcp-local
    ports:
      - "8086:8086"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - firestore.gcp.local
    labels:
      gcp.service: "firestore"
      gcp.equivalent: "google_firestore_database"

  # ==========================================================================
  # Cloud Monitoring Simulation (Prometheus)
  # ==========================================================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: gcp-monitoring
    hostname: monitoring.gcp.local
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - prometheus_data:/prometheus
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./config/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
    ports:
      - "9090:9090"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - monitoring.gcp.local
          - prometheus.gcp.local
    labels:
      gcp.service: "monitoring"
      gcp.equivalent: "google_monitoring_uptime_check_config"

  # ==========================================================================
  # Cloud Monitoring Dashboard (Grafana)
  # ==========================================================================
  grafana:
    image: grafana/grafana:10.2.2
    container_name: gcp-monitoring-dashboard
    hostname: dashboard.gcp.local
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-erlmcp_grafana}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: http://localhost:3000
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./config/grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
      - loki
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - dashboard.gcp.local
          - grafana.gcp.local
    labels:
      gcp.service: "monitoring-dashboard"

  # ==========================================================================
  # Cloud Logging Simulation (Loki)
  # ==========================================================================
  loki:
    image: grafana/loki:2.9.2
    container_name: gcp-logging
    hostname: logging.gcp.local
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - loki_data:/loki
      - ./config/loki/loki-config.yml:/etc/loki/local-config.yaml:ro
    ports:
      - "3100:3100"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3100/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - logging.gcp.local
          - loki.gcp.local
    labels:
      gcp.service: "logging"
      gcp.equivalent: "cloud_logging"

  # ==========================================================================
  # Cloud Load Balancer Simulation (Traefik)
  # ==========================================================================
  traefik:
    image: traefik:v3.0
    container_name: gcp-loadbalancer
    hostname: lb.gcp.local
    command:
      - "--api.dashboard=true"
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.docker.network=gcp-simulation"
      - "--entrypoints.http.address=:80"
      - "--entrypoints.https.address=:443"
      - "--entrypoints.grpc.address=:50051"
      - "--metrics.prometheus=true"
      - "--accesslog=true"
      - "--log.level=INFO"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./config/traefik/dynamic:/etc/traefik/dynamic:ro
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"    # Traefik dashboard
      - "50051:50051"  # gRPC
    healthcheck:
      test: ["CMD", "traefik", "healthcheck", "--ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - lb.gcp.local
          - traefik.gcp.local
    labels:
      gcp.service: "loadbalancer"
      gcp.equivalent: "google_compute_forwarding_rule"

  # ==========================================================================
  # GKE Simulation (K3s - lightweight Kubernetes)
  # ==========================================================================
  k3s:
    image: rancher/k3s:v1.28.4-k3s1
    container_name: gcp-gke
    hostname: gke.gcp.local
    command: server --disable=traefik --tls-san=gke.gcp.local
    privileged: true
    environment:
      K3S_TOKEN: ${K3S_TOKEN:-erlmcp_k3s_token}
      K3S_KUBECONFIG_OUTPUT: /output/kubeconfig.yaml
      K3S_KUBECONFIG_MODE: "644"
    volumes:
      - k3s_data:/var/lib/rancher/k3s
      - ./config/k3s:/output:rw
    ports:
      - "6443:6443"    # Kubernetes API
      - "30000-30100:30000-30100"  # NodePort range
    healthcheck:
      test: ["CMD", "kubectl", "get", "--raw", "/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - gke.gcp.local
          - kubernetes.gcp.local
    labels:
      gcp.service: "gke"
      gcp.equivalent: "google_container_cluster"
    profiles:
      - kubernetes  # Only start with --profile kubernetes

  # ==========================================================================
  # ErlMCP Application Node
  # ==========================================================================
  erlmcp-node:
    build:
      context: ../..
      dockerfile: Dockerfile
      target: runtime
    container_name: erlmcp-gcp-app
    hostname: erlmcp.gcp.local
    environment:
      ERLMCP_ENV: simulation
      ERLMCP_NODE_NAME: erlmcp@erlmcp.gcp.local
      DATABASE_URL: postgresql://erlmcp:erlmcp_secret@postgres:5432/erlmcp_dev
      REDIS_URL: redis://:erlmcp_redis@redis:6379
      VAULT_ADDR: http://vault:8200
      VAULT_TOKEN: ${VAULT_TOKEN:-erlmcp_vault_token}
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: erlmcp_storage
      MINIO_SECRET_KEY: erlmcp_storage_secret
      PUBSUB_EMULATOR_HOST: pubsub-emulator:8085
      FIRESTORE_EMULATOR_HOST: firestore-emulator:8086
      PROMETHEUS_PUSH_GATEWAY: http://prometheus:9090
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      vault:
        condition: service_healthy
      minio:
        condition: service_healthy
    ports:
      - "8081:8080"    # HTTP API
      - "9091:9090"    # Health
      - "4370:4369"    # EPMD
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - erlmcp.gcp.local
    labels:
      gcp.service: "cloudrun"
      gcp.equivalent: "google_cloud_run_service"
      traefik.enable: "true"
      traefik.http.routers.erlmcp.rule: "Host(`erlmcp.gcp.local`)"
      traefik.http.services.erlmcp.loadbalancer.server.port: "8080"
    profiles:
      - app

  # ==========================================================================
  # OpenTelemetry Collector (Cloud Trace simulation)
  # ==========================================================================
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.90.0
    container_name: gcp-cloudtrace
    hostname: trace.gcp.local
    command: ["--config=/etc/otel-collector-config.yml"]
    volumes:
      - ./config/otel/otel-collector-config.yml:/etc/otel-collector-config.yml:ro
    ports:
      - "4317:4317"    # OTLP gRPC
      - "4318:4318"    # OTLP HTTP
      - "8888:8888"    # Prometheus metrics
      - "13133:13133"  # Health check
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:13133/"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      gcp-simulation:
        aliases:
          - trace.gcp.local
          - otel.gcp.local
    labels:
      gcp.service: "cloudtrace"
      gcp.equivalent: "cloud_trace"

# ==========================================================================
# Networks
# ==========================================================================
networks:
  gcp-simulation:
    name: gcp-simulation
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16

# ==========================================================================
# Volumes
# ==========================================================================
volumes:
  postgres_data:
    name: gcp-cloudsql-data
  redis_data:
    name: gcp-memorystore-data
  minio_data:
    name: gcp-cloudstorage-data
  vault_data:
    name: gcp-secretmanager-data
  registry_data:
    name: gcp-artifactregistry-data
  prometheus_data:
    name: gcp-monitoring-data
  grafana_data:
    name: gcp-dashboard-data
  loki_data:
    name: gcp-logging-data
  k3s_data:
    name: gcp-gke-data
