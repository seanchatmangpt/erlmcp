#!/usr/bin/env escript
%% @doc System Resilience Validation Demo Script
%% Demonstrates comprehensive resilience testing with full tracing
%%
%% Usage: ./run_resilience_validation.escript [test_type]
%% 
%% Test types:
%%   full      - Run complete resilience test suite (default)
%%   quick     - Run essential resilience tests only
%%   chaos     - Run chaos engineering experiments
%%   specific  - Run specific test (requires test name)
%%   report    - Generate resilience report from previous run

main(Args) ->
    io:format("üõ°Ô∏è  ErlMCP System Resilience Validation~n"),
    io:format("=====================================~n"),
    
    %% Initialize environment
    setup_environment(),
    
    %% Parse command line arguments
    TestType = parse_args(Args),
    
    %% Execute based on test type
    case TestType of
        full ->
            run_full_resilience_suite();
        quick ->
            run_quick_resilience_tests();
        chaos ->
            run_chaos_experiments();
        {specific, TestName} ->
            run_specific_test(TestName);
        report ->
            generate_resilience_report();
        help ->
            show_help()
    end.

%% =============================================================================
%% Main Test Execution Functions
%% =============================================================================

run_full_resilience_suite() ->
    io:format("üöÄ Starting Full System Resilience Validation~n~n"),
    
    StartTime = erlang:monotonic_time(),
    
    try
        %% Display test overview
        show_test_overview(),
        
        %% Initialize tracing
        TraceId = init_resilience_tracing(),
        io:format("üìä Tracing initialized (ID: ~s)~n", [TraceId]),
        
        %% Execute comprehensive resilience tests
        Results = execute_resilience_test_suite(),
        
        %% Display results
        EndTime = erlang:monotonic_time(),
        TotalDuration = (EndTime - StartTime) div 1000000,
        
        display_results_summary(Results, TotalDuration),
        
        %% Generate detailed report
        ReportPath = generate_test_report(Results, TraceId),
        
        %% Final status
        case maps:get(overall_success, Results, false) of
            true ->
                io:format("~n‚úÖ RESILIENCE VALIDATION PASSED~n"),
                io:format("üéØ System demonstrates strong resilience capabilities~n"),
                halt(0);
            false ->
                io:format("~n‚ùå RESILIENCE VALIDATION FAILED~n"),
                io:format("‚ö†Ô∏è  System has resilience weaknesses that need attention~n"),
                io:format("üìã See detailed report: ~s~n", [ReportPath]),
                halt(1)
        end
    catch
        Class:Reason:Stacktrace ->
            io:format("~nüí• CRITICAL ERROR: ~p:~p~n", [Class, Reason]),
            io:format("Stacktrace: ~p~n", [Stacktrace]),
            halt(2)
    end.

run_quick_resilience_tests() ->
    io:format("‚ö° Running Quick Resilience Tests~n~n"),
    
    QuickTests = [
        {connection_resilience, "Testing automatic reconnection"},
        {failover_basic, "Testing basic failover mechanisms"}, 
        {circuit_breaker_basic, "Testing circuit breaker functionality"},
        {graceful_degradation_basic, "Testing graceful degradation"}
    ],
    
    Results = lists:map(fun({TestName, Description}) ->
        io:format("üî¨ ~s... ", [Description]),
        TestResult = run_individual_test(TestName),
        case maps:get(success, TestResult, false) of
            true -> 
                io:format("‚úÖ PASSED (~pms)~n", [maps:get(duration_ms, TestResult, 0)]);
            false -> 
                io:format("‚ùå FAILED~n")
        end,
        TestResult
    end, QuickTests),
    
    PassedCount = length([R || R <- Results, maps:get(success, R, false) =:= true]),
    TotalCount = length(Results),
    
    io:format("~nüìä Quick Tests Summary: ~p/~p passed (~.1f%)~n", 
              [PassedCount, TotalCount, (PassedCount/TotalCount)*100]),
    
    case PassedCount =:= TotalCount of
        true ->
            io:format("‚úÖ Basic resilience capabilities validated~n"),
            halt(0);
        false ->
            io:format("‚ùå Some resilience issues detected~n"),
            halt(1)
    end.

run_chaos_experiments() ->
    io:format("üå™Ô∏è  Running Chaos Engineering Experiments~n~n"),
    
    ChaosExperiments = [
        {process_chaos, "Random process termination"},
        {network_chaos, "Network instability injection"},
        {resource_chaos, "Resource starvation testing"},
        {cascade_chaos, "Cascade failure simulation"}
    ],
    
    Results = lists:map(fun({ExperimentName, Description}) ->
        io:format("üí• ~s... ", [Description]),
        
        ExperimentResult = run_chaos_experiment(ExperimentName),
        
        case maps:get(success, ExperimentResult, false) of
            true -> 
                ResilienceScore = maps:get(resilience_score, ExperimentResult, 0.0),
                io:format("‚úÖ SURVIVED (Score: ~.2f)~n", [ResilienceScore]);
            false -> 
                io:format("‚ùå FAILED~n")
        end,
        
        ExperimentResult
    end, ChaosExperiments),
    
    SurvivedCount = length([R || R <- Results, maps:get(success, R, false) =:= true]),
    TotalCount = length(Results),
    
    io:format("~nüéØ Chaos Results: ~p/~p experiments survived (~.1f%)~n", 
              [SurvivedCount, TotalCount, (SurvivedCount/TotalCount)*100]),
    
    case SurvivedCount >= trunc(TotalCount * 0.8) of % 80% survival threshold
        true ->
            io:format("‚úÖ System demonstrates chaos resilience~n"),
            halt(0);
        false ->
            io:format("‚ùå System needs improved chaos resilience~n"),
            halt(1)
    end.

run_specific_test(TestName) ->
    io:format("üéØ Running Specific Test: ~s~n~n", [TestName]),
    
    TestResult = run_individual_test(list_to_atom(TestName)),
    
    io:format("üìä Test Result:~n"),
    io:format("  Success: ~p~n", [maps:get(success, TestResult, false)]),
    io:format("  Duration: ~pms~n", [maps:get(duration_ms, TestResult, 0)]),
    
    case maps:get(success, TestResult, false) of
        true ->
            io:format("‚úÖ Test passed~n"),
            halt(0);
        false ->
            io:format("‚ùå Test failed~n"),
            io:format("  Error: ~p~n", [maps:get(error, TestResult, unknown)]),
            halt(1)
    end.

generate_resilience_report() ->
    io:format("üìã Generating Resilience Report~n~n"),
    
    %% Look for previous test results
    case find_latest_test_results() of
        {ok, ResultsFile} ->
            io:format("üìÇ Found results: ~s~n", [ResultsFile]),
            Results = load_test_results(ResultsFile),
            
            ReportPath = create_comprehensive_report(Results),
            
            io:format("üìÑ Report generated: ~s~n", [ReportPath]),
            io:format("üåê Opening report in browser...~n"),
            
            open_report_in_browser(ReportPath),
            halt(0);
        {error, not_found} ->
            io:format("‚ùå No previous test results found~n"),
            io:format("üí° Run resilience tests first to generate a report~n"),
            halt(1)
    end.

%% =============================================================================
%% Test Execution Implementation
%% =============================================================================

execute_resilience_test_suite() ->
    TestPhases = [
        {phase1, "Failure Recovery Tests", fun run_failure_recovery_phase/0},
        {phase2, "Degradation Tests", fun run_degradation_phase/0},
        {phase3, "Chaos Engineering", fun run_chaos_phase/0},
        {phase4, "Advanced Scenarios", fun run_advanced_phase/0},
        {phase5, "Real-World Simulations", fun run_simulation_phase/0}
    ],
    
    PhaseResults = lists:map(fun({PhaseId, PhaseName, PhaseFun}) ->
        io:format("üìã Phase ~p: ~s~n", [PhaseId, PhaseName]),
        io:format("" ++ lists:duplicate(50, $-) ++ "~n"),
        
        PhaseStart = erlang:monotonic_time(),
        PhaseResult = PhaseFun(),
        PhaseEnd = erlang:monotonic_time(),
        PhaseDuration = (PhaseEnd - PhaseStart) div 1000000,
        
        PhaseSuccess = maps:get(success, PhaseResult, false),
        TestCount = maps:get(test_count, PhaseResult, 0),
        PassedCount = maps:get(passed_count, PhaseResult, 0),
        
        io:format("üìä Phase Result: ~p/~p tests passed (~pms)~n", 
                  [PassedCount, TestCount, PhaseDuration]),
        
        case PhaseSuccess of
            true -> io:format("‚úÖ Phase PASSED~n~n");
            false -> io:format("‚ùå Phase FAILED~n~n")
        end,
        
        PhaseResult#{
            phase_id => PhaseId,
            phase_name => PhaseName,
            duration_ms => PhaseDuration
        }
    end, TestPhases),
    
    %% Aggregate results
    TotalTests = lists:sum([maps:get(test_count, PR, 0) || PR <- PhaseResults]),
    TotalPassed = lists:sum([maps:get(passed_count, PR, 0) || PR <- PhaseResults]),
    OverallSuccess = TotalPassed =:= TotalTests,
    SuccessRate = case TotalTests of
        0 -> 0.0;
        _ -> TotalPassed / TotalTests
    end,
    
    #{
        phase_results => PhaseResults,
        total_tests => TotalTests,
        total_passed => TotalPassed,
        success_rate => SuccessRate,
        overall_success => OverallSuccess,
        resilience_score => calculate_resilience_score(PhaseResults)
    }.

%% Phase implementations (mock for demonstration)
run_failure_recovery_phase() ->
    Tests = [
        "Automatic Reconnection",
        "Failover Mechanisms", 
        "Circuit Breaker",
        "Retry Logic",
        "Byzantine Tolerance"
    ],
    
    Results = simulate_test_execution(Tests, 0.9), % 90% pass rate
    
    #{
        success => length([R || R <- Results, R =:= pass]) =:= length(Tests),
        test_count => length(Tests),
        passed_count => length([R || R <- Results, R =:= pass]),
        test_results => Results
    }.

run_degradation_phase() ->
    Tests = [
        "Graceful Degradation",
        "Partial Failure Handling",
        "Service Isolation", 
        "Backpressure Mechanisms",
        "Load Shedding"
    ],
    
    Results = simulate_test_execution(Tests, 0.85), % 85% pass rate
    
    #{
        success => length([R || R <- Results, R =:= pass]) >= trunc(length(Tests) * 0.8),
        test_count => length(Tests),
        passed_count => length([R || R <- Results, R =:= pass]),
        test_results => Results
    }.

run_chaos_phase() ->
    Experiments = [
        "Process Chaos",
        "Network Chaos",
        "Resource Chaos",
        "Cascade Failure"
    ],
    
    Results = simulate_test_execution(Experiments, 0.75), % 75% survival rate
    
    #{
        success => length([R || R <- Results, R =:= pass]) >= trunc(length(Experiments) * 0.7),
        test_count => length(Experiments),
        passed_count => length([R || R <- Results, R =:= pass]),
        test_results => Results
    }.

run_advanced_phase() ->
    Tests = [
        "Network Partition Recovery",
        "Cascade Failure Prevention", 
        "Memory Pressure Recovery",
        "Concurrent Failure Recovery"
    ],
    
    Results = simulate_test_execution(Tests, 0.8), % 80% pass rate
    
    #{
        success => length([R || R <- Results, R =:= pass]) >= trunc(length(Tests) * 0.75),
        test_count => length(Tests),
        passed_count => length([R || R <- Results, R =:= pass]),
        test_results => Results
    }.

run_simulation_phase() ->
    Simulations = [
        "Datacenter Outage",
        "Traffic Spike",
        "DDoS Attack",
        "Hardware Degradation"
    ],
    
    Results = simulate_test_execution(Simulations, 0.8), % 80% pass rate
    
    #{
        success => length([R || R <- Results, R =:= pass]) >= trunc(length(Simulations) * 0.75),
        test_count => length(Simulations),
        passed_count => length([R || R <- Results, R =:= pass]),
        test_results => Results
    }.

simulate_test_execution(TestNames, PassRate) ->
    lists:map(fun(TestName) ->
        io:format("  üî¨ ~s... ", [TestName]),
        
        %% Simulate test execution time
        ExecutionTime = 500 + rand:uniform(2000), % 0.5-2.5 seconds
        timer:sleep(ExecutionTime),
        
        %% Determine test result based on pass rate
        Result = case rand:uniform() < PassRate of
            true -> 
                io:format("‚úÖ PASSED (~pms)~n", [ExecutionTime]),
                pass;
            false -> 
                io:format("‚ùå FAILED~n"),
                fail
        end,
        
        Result
    end, TestNames).

run_individual_test(TestName) ->
    io:format("üî¨ Executing test: ~p~n", [TestName]),
    
    StartTime = erlang:monotonic_time(),
    
    %% Simulate test execution
    timer:sleep(1000 + rand:uniform(3000)), % 1-4 seconds
    
    %% Simulate test result (80% pass rate for individual tests)
    Success = rand:uniform() < 0.8,
    
    EndTime = erlang:monotonic_time(),
    Duration = (EndTime - StartTime) div 1000000,
    
    case Success of
        true ->
            #{
                success => true,
                duration_ms => Duration,
                test_name => TestName,
                metrics => generate_mock_metrics()
            };
        false ->
            #{
                success => false,
                duration_ms => Duration,
                test_name => TestName,
                error => mock_error_reason()
            }
    end.

run_chaos_experiment(ExperimentName) ->
    io:format("üí• Running chaos experiment: ~p~n", [ExperimentName]),
    
    StartTime = erlang:monotonic_time(),
    
    %% Simulate chaos experiment (longer duration)
    timer:sleep(2000 + rand:uniform(8000)), % 2-10 seconds
    
    %% Chaos experiments have lower success rate (70%)
    Success = rand:uniform() < 0.7,
    ResilienceScore = 0.5 + (rand:uniform() * 0.5), % 0.5-1.0
    
    EndTime = erlang:monotonic_time(),
    Duration = (EndTime - StartTime) div 1000000,
    
    #{
        success => Success,
        duration_ms => Duration,
        experiment_name => ExperimentName,
        resilience_score => ResilienceScore,
        chaos_metrics => generate_chaos_metrics()
    }.

%% =============================================================================
%% Helper Functions
%% =============================================================================

setup_environment() ->
    %% Initialize random seed
    rand:seed(exsss, erlang:timestamp()),
    
    %% Ensure required directories exist
    filelib:ensure_dir("reports/"),
    filelib:ensure_dir("results/"),
    
    io:format("üîß Environment initialized~n").

parse_args([]) -> full;
parse_args(["full"]) -> full;
parse_args(["quick"]) -> quick;
parse_args(["chaos"]) -> chaos;
parse_args(["specific", TestName]) -> {specific, TestName};
parse_args(["report"]) -> report;
parse_args(["help"]) -> help;
parse_args(["-h"]) -> help;
parse_args(["--help"]) -> help;
parse_args(_) -> help.

show_help() ->
    io:format("~nüõ°Ô∏è  ErlMCP System Resilience Validation~n"),
    io:format("Usage: ./run_resilience_validation.escript [COMMAND]~n~n"),
    io:format("Commands:~n"),
    io:format("  full                Run complete resilience test suite (default)~n"),
    io:format("  quick               Run essential resilience tests only~n"),
    io:format("  chaos               Run chaos engineering experiments~n"),
    io:format("  specific <test>     Run specific test~n"),
    io:format("  report              Generate resilience report~n"),
    io:format("  help                Show this help message~n~n"),
    io:format("Examples:~n"),
    io:format("  ./run_resilience_validation.escript full~n"),
    io:format("  ./run_resilience_validation.escript chaos~n"),
    io:format("  ./run_resilience_validation.escript specific circuit_breaker~n~n"),
    halt(0).

show_test_overview() ->
    io:format("üìã Resilience Test Suite Overview~n"),
    io:format("=================================~n"),
    io:format("Phase 1: Failure Recovery Tests~n"),
    io:format("  ‚Ä¢ Automatic reconnection validation~n"),
    io:format("  ‚Ä¢ Failover mechanism testing~n"),
    io:format("  ‚Ä¢ Circuit breaker functionality~n"),
    io:format("  ‚Ä¢ Retry logic with exponential backoff~n"),
    io:format("  ‚Ä¢ Byzantine fault tolerance~n~n"),
    
    io:format("Phase 2: Degradation Tests~n"),
    io:format("  ‚Ä¢ Graceful degradation under load~n"),
    io:format("  ‚Ä¢ Partial failure isolation~n"),
    io:format("  ‚Ä¢ Service boundary enforcement~n"),
    io:format("  ‚Ä¢ Backpressure mechanisms~n"),
    io:format("  ‚Ä¢ Load shedding strategies~n~n"),
    
    io:format("Phase 3: Chaos Engineering~n"),
    io:format("  ‚Ä¢ Random process termination~n"),
    io:format("  ‚Ä¢ Network instability injection~n"),
    io:format("  ‚Ä¢ Resource starvation testing~n"),
    io:format("  ‚Ä¢ Cascade failure simulation~n~n"),
    
    io:format("Phase 4: Advanced Scenarios~n"),
    io:format("  ‚Ä¢ Network partition recovery~n"),
    io:format("  ‚Ä¢ Cascade failure prevention~n"),
    io:format("  ‚Ä¢ Memory pressure handling~n"),
    io:format("  ‚Ä¢ Concurrent failure recovery~n~n"),
    
    io:format("Phase 5: Real-World Simulations~n"),
    io:format("  ‚Ä¢ Datacenter outage simulation~n"),
    io:format("  ‚Ä¢ Traffic spike handling~n"),
    io:format("  ‚Ä¢ DDoS attack response~n"),
    io:format("  ‚Ä¢ Hardware degradation testing~n~n").

init_resilience_tracing() ->
    TraceId = generate_trace_id(),
    io:format("üîç Initializing OpenTelemetry tracing...~n"),
    %% In real implementation, this would setup OpenTelemetry
    TraceId.

display_results_summary(Results, TotalDuration) ->
    io:format("~nüìä RESILIENCE VALIDATION SUMMARY~n"),
    io:format("================================~n"),
    io:format("Total Duration: ~.2f minutes~n", [TotalDuration / (60 * 1000)]),
    io:format("Total Tests: ~p~n", [maps:get(total_tests, Results, 0)]),
    io:format("Tests Passed: ~p~n", [maps:get(total_passed, Results, 0)]),
    io:format("Success Rate: ~.1f%~n", [maps:get(success_rate, Results, 0.0) * 100]),
    io:format("Resilience Score: ~.2f/1.00~n", [maps:get(resilience_score, Results, 0.0)]),
    
    PhaseResults = maps:get(phase_results, Results, []),
    io:format("~nPhase Breakdown:~n"),
    lists:foreach(fun(PhaseResult) ->
        PhaseName = maps:get(phase_name, PhaseResult, "Unknown"),
        TestCount = maps:get(test_count, PhaseResult, 0),
        PassedCount = maps:get(passed_count, PhaseResult, 0),
        PhaseDuration = maps:get(duration_ms, PhaseResult, 0),
        
        io:format("  ~s: ~p/~p passed (~pms)~n", 
                  [PhaseName, PassedCount, TestCount, PhaseDuration])
    end, PhaseResults).

generate_test_report(Results, TraceId) ->
    Timestamp = calendar:system_time_to_rfc3339(erlang:system_time(second)),
    ReportFilename = io_lib:format("resilience_report_~s.html", 
                                  [string:replace(Timestamp, ":", "-", all)]),
    ReportPath = filename:join("reports", ReportFilename),
    
    ReportContent = create_html_report(Results, TraceId),
    
    file:write_file(ReportPath, ReportContent),
    io:format("üìÑ Detailed report saved: ~s~n", [ReportPath]),
    
    %% Also save results as JSON for programmatic access
    ResultsPath = filename:join("results", "latest_results.json"),
    ResultsJson = json_encode(Results),
    file:write_file(ResultsPath, ResultsJson),
    
    ReportPath.

calculate_resilience_score(PhaseResults) ->
    %% Calculate weighted resilience score
    PhaseWeights = #{
        phase1 => 0.25,  % Failure Recovery
        phase2 => 0.20,  % Degradation
        phase3 => 0.20,  % Chaos Engineering
        phase4 => 0.20,  % Advanced Scenarios  
        phase5 => 0.15   % Real-World Simulations
    },
    
    WeightedScores = lists:map(fun(PhaseResult) ->
        PhaseId = maps:get(phase_id, PhaseResult, phase1),
        TestCount = maps:get(test_count, PhaseResult, 1),
        PassedCount = maps:get(passed_count, PhaseResult, 0),
        PhaseScore = PassedCount / TestCount,
        Weight = maps:get(PhaseId, PhaseWeights, 0.2),
        PhaseScore * Weight
    end, PhaseResults),
    
    lists:sum(WeightedScores).

create_html_report(Results, TraceId) ->
    ResilienceScore = maps:get(resilience_score, Results, 0.0),
    OverallSuccess = maps:get(overall_success, Results, false),
    
    ScoreColor = if 
        ResilienceScore >= 0.9 -> "green";
        ResilienceScore >= 0.7 -> "orange";
        true -> "red"
    end,
    
    StatusBadge = case OverallSuccess of
        true -> "<span style='color: green; font-weight: bold;'>‚úÖ RESILIENT SYSTEM</span>";
        false -> "<span style='color: red; font-weight: bold;'>‚ùå RESILIENCE ISSUES</span>"
    end,
    
    io_lib:format(
        "<!DOCTYPE html>~n"
        "<html><head><title>ErlMCP Resilience Validation Report</title>"
        "<style>"
        "body { font-family: Arial, sans-serif; margin: 40px; }"
        ".header { background: #f0f0f0; padding: 20px; border-radius: 5px; }"
        ".score { font-size: 48px; font-weight: bold; color: ~s; }"
        ".phase { margin: 20px 0; padding: 15px; border-left: 4px solid #ccc; }"
        ".metrics { display: flex; justify-content: space-around; margin: 20px 0; }"
        ".metric { text-align: center; }"
        ".metric-value { font-size: 24px; font-weight: bold; }"
        "</style></head><body>~n"
        "<div class='header'>~n"
        "<h1>üõ°Ô∏è ErlMCP System Resilience Validation Report</h1>~n"
        "<p>Generated: ~s</p>~n"
        "<p>Trace ID: ~s</p>~n"
        "<p>Status: ~s</p>~n"
        "</div>~n"
        "<div class='metrics'>~n"
        "<div class='metric'><div class='metric-value score'>~.2f</div><div>Resilience Score</div></div>~n"
        "<div class='metric'><div class='metric-value'>~p</div><div>Tests Executed</div></div>~n"
        "<div class='metric'><div class='metric-value'>~p</div><div>Tests Passed</div></div>~n"
        "<div class='metric'><div class='metric-value'>~.1f%</div><div>Success Rate</div></div>~n"
        "</div>~n"
        "~s~n" % Phase details would go here
        "</body></html>~n",
        [ScoreColor, calendar:system_time_to_rfc3339(erlang:system_time(second)), 
         TraceId, StatusBadge, ResilienceScore,
         maps:get(total_tests, Results, 0),
         maps:get(total_passed, Results, 0),
         maps:get(success_rate, Results, 0.0) * 100,
         generate_phase_html(maps:get(phase_results, Results, []))]).

generate_phase_html(PhaseResults) ->
    lists:foldl(fun(PhaseResult, Acc) ->
        PhaseName = maps:get(phase_name, PhaseResult, "Unknown Phase"),
        TestCount = maps:get(test_count, PhaseResult, 0),
        PassedCount = maps:get(passed_count, PhaseResult, 0),
        Duration = maps:get(duration_ms, PhaseResult, 0),
        
        PhaseHtml = io_lib:format(
            "<div class='phase'>~n"
            "<h3>~s</h3>~n"
            "<p>Tests: ~p/~p passed (~pms)</p>~n"
            "</div>~n",
            [PhaseName, PassedCount, TestCount, Duration]),
        
        Acc ++ PhaseHtml
    end, "", PhaseResults).

%% Mock helper functions
generate_trace_id() ->
    base64:encode(crypto:strong_rand_bytes(16)).

generate_mock_metrics() ->
    #{
        recovery_time_ms => rand:uniform(5000),
        error_rate => rand:uniform() * 0.1,
        throughput_rps => 500 + rand:uniform(1500)
    }.

mock_error_reason() ->
    Reasons = [timeout, connection_refused, circuit_open, resource_exhaustion],
    lists:nth(rand:uniform(length(Reasons)), Reasons).

generate_chaos_metrics() ->
    #{
        survival_rate => 0.7 + (rand:uniform() * 0.3),
        blast_radius => rand:uniform() * 0.3,
        recovery_time_ms => 1000 + rand:uniform(9000)
    }.

find_latest_test_results() ->
    case file:list_dir("results") of
        {ok, Files} ->
            JsonFiles = [F || F <- Files, filename:extension(F) =:= ".json"],
            case JsonFiles of
                [] -> {error, not_found};
                _ -> 
                    LatestFile = lists:last(lists:sort(JsonFiles)),
                    {ok, filename:join("results", LatestFile)}
            end;
        {error, _} ->
            {error, not_found}
    end.

load_test_results(FilePath) ->
    {ok, Content} = file:read_file(FilePath),
    json_decode(Content).

create_comprehensive_report(Results) ->
    ReportPath = "reports/comprehensive_resilience_report.html",
    ReportContent = create_html_report(Results, "previous-run"),
    file:write_file(ReportPath, ReportContent),
    ReportPath.

open_report_in_browser(ReportPath) ->
    %% Platform-specific browser opening
    case os:type() of
        {unix, darwin} -> % macOS
            os:cmd("open " ++ ReportPath);
        {unix, linux} ->  % Linux
            os:cmd("xdg-open " ++ ReportPath);
        {win32, _} ->     % Windows
            os:cmd("start " ++ ReportPath);
        _ ->
            io:format("üìÅ Report available at: ~s~n", [ReportPath])
    end.

%% Simple JSON encode/decode (minimal implementation)
json_encode(Term) ->
    %% In real implementation, would use proper JSON library
    io_lib:format("~p", [Term]).

json_decode(Json) ->
    %% In real implementation, would use proper JSON library
    {ok, Tokens, _} = erl_scan:string(binary_to_list(Json)),
    {ok, Term} = erl_parse:parse_term(Tokens),
    Term.