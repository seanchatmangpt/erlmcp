name: Performance Regression Detection

on:
  pull_request:
    branches: [main]
    paths:
      - 'apps/**'
      - 'rebar.config'
      - 'rebar.lock'
      - '.github/workflows/performance-regression.yml'
  push:
    branches: [main]
    paths:
      - 'apps/**'
      - 'bench/**'

permissions:
  contents: read
  pull-requests: write
  checks: write

concurrency:
  group: performance-regression-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  #=============================================================================
  # JOB 1: Run Performance Regression Tests
  #=============================================================================
  performance-regression-tests:
    name: Performance Regression Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for baseline comparison

      - name: Setup Erlang/OTP
        uses: erlef/setup-beam@v1
        with:
          otp-version: '27'
          rebar3-version: '3.23'

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            _build
            ~/.cache/rebar3
          key: ${{ runner.os }}-rebar3-${{ hashFiles('rebar.lock', '**/rebar.config') }}
          restore-keys: |
            ${{ runner.os }}-rebar3-

      - name: Compile project
        run: |
          echo "::group::Compiling project"
          TERM=dumb rebar3 compile
          TERM=dumb rebar3 as test compile
          echo "::endgroup::"

      - name: Load performance thresholds
        id: thresholds
        run: |
          if [ -f .github/performance-thresholds.json ]; then
            echo "thresholds_file=.github/performance-thresholds.json" >> $GITHUB_OUTPUT
            echo "Loaded thresholds from .github/performance-thresholds.json"
          else
            echo "thresholds_file=" >> $GITHUB_OUTPUT
            echo "Using default thresholds"
          fi

      - name: Run performance regression SUITE
        id: perf_tests
        run: |
          echo "::group::Running performance regression tests"
          echo "This may take 10-15 minutes..."
          echo ""

          # Run the performance validator SUITE
          rebar3 ct --suite=apps/erlmcp_validation/test/erlmcp_performance_validator_SUITE \
            --cover \
            2>&1 | tee performance_test.log

          TEST_EXIT=${PIPESTATUS[0]}

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Performance Regression Tests" >> $GITHUB_STEP_SUMMARY
          if [ $TEST_EXIT -eq 0 ]; then
            echo "### âœ… PASSED" >> $GITHUB_STEP_SUMMARY
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "### âŒ FAILED" >> $GITHUB_STEP_SUMMARY
            echo "status=failed" >> $GITHUB_OUTPUT
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "::endgroup::"

          if [ $TEST_EXIT -ne 0 ]; then
            echo "::error::Performance regression tests FAILED"
            exit 1
          fi

      - name: Capture performance test failure
        if: failure() && steps.perf_tests.outcome == 'failure'
        uses: ./.github/actions/capture-failure
        with:
          failure-type: benchmark
          otp-version: '27'


      - name: Parse test results
        id: results
        run: |
          # Extract key metrics from test output
          echo "Parsing test results..."

          # Look for regression indicators in the log
          if grep -q "REGRESSION DETECTED" performance_test.log; then
            echo "regressions=true" >> $GITHUB_OUTPUT
            REGRESSION_COUNT=$(grep -c "REGRESSION DETECTED" performance_test.log || echo "0")
            echo "regression_count=$REGRESSION_COUNT" >> $GITHUB_OUTPUT
          else
            echo "regressions=false" >> $GITHUB_OUTPUT
            echo "regression_count=0" >> $GITHUB_OUTPUT
          fi

          # Extract coverage
          if grep -q "covered" performance_test.log; then
            COVERAGE=$(grep "covered" performance_test.log | tail -1 | awk '{print $1}' || echo "0")
            echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
          else
            echo "coverage=0" >> $GITHUB_OUTPUT
          fi

      - name: Generate performance report
        if: always()
        run: |
          cat > performance_report.md << 'EOF'
          # Performance Regression Test Report

          **Date:** $(date -u +%Y-%m-%dT%H:%M:%SZ)
          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}
          **Actor:** ${{ github.actor }}

          ## Test Status

          **Result:** ${{ steps.perf_tests.outputs.status }}
          **Regressions:** ${{ steps.results.outputs.regressions }}
          **Regression Count:** ${{ steps.results.outputs.regression_count }}
          **Coverage:** ${{ steps.results.outputs.coverage }}%

          ## Thresholds

          Thresholds loaded from: ${{ steps.thresholds.outputs.thresholds_file }}

          ## Performance Metrics

          See detailed test logs in workflow artifacts.

          EOF

          cat performance_report.md

      - name: Upload performance test logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-regression-logs
          path: |
            performance_test.log
            performance_report.md
            _build/test/logs/
          retention-days: 30

      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-regression-coverage
          path: _build/test/cover/
          retention-days: 30

  #=============================================================================
  # JOB 2: Compare with Baseline
  #=============================================================================
  baseline-comparison:
    name: Baseline Comparison
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: performance-regression-tests

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Erlang/OTP
        uses: erlef/setup-beam@v1
        with:
          otp-version: '27'
          rebar3-version: '3.23'

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            _build
            ~/.cache/rebar3
          key: ${{ runner.os }}-rebar3-${{ hashFiles('rebar.lock') }}
          restore-keys: |
            ${{ runner.os }}-rebar3-

      - name: Compile project
        run: |
          TERM=dumb rebar3 compile

      - name: Fetch baseline from main
        run: |
          git fetch origin main:main || true

          # Check for baseline files
          if [ -d "bench/baselines" ]; then
            echo "Found baseline directory:"
            ls -lh bench/baselines/ || echo "No baselines yet"
          else
            echo "No baseline directory found - this is the first run"
            mkdir -p bench/baselines
          fi

      - name: Run baseline comparison
        id: compare
        run: |
          chmod +x tools/baseline-compare.sh

          # Run comparison (continue on error to capture results)
          ./tools/baseline-compare.sh --threshold 10 || true

          # Check if comparison report was generated
          if ls bench/baselines/comparison_*.html 1> /dev/null 2>&1; then
            echo "comparison_generated=true" >> $GITHUB_OUTPUT
            COMPARISON_FILE=$(ls -t bench/baselines/comparison_*.html | head -1)
            echo "comparison_file=$COMPARISON_FILE" >> $GITHUB_OUTPUT
          else
            echo "comparison_generated=false" >> $GITHUB_OUTPUT
          fi

      - name: Analyze comparison results
        id: analysis
        run: |
          # Count regressions from comparison
          if [ -f "${{ steps.compare.outputs.comparison_file }}" ]; then
            REGRESSIONS=$(grep -c "REGRESSION" "${{ steps.compare.outputs.comparison_file }}" || echo "0")
            echo "regression_count=$REGRESSIONS" >> $GITHUB_OUTPUT

            if [ "$REGRESSIONS" -gt 0 ]; then
              echo "has_regression=true" >> $GITHUB_OUTPUT
              echo "::warning::Found $REGRESSIONS performance regression(s)"
            else
              echo "has_regression=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "regression_count=0" >> $GITHUB_OUTPUT
            echo "has_regression=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload comparison report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: baseline-comparison-report
          path: |
            bench/baselines/comparison_*.html
            bench/baselines/*.json
          retention-days: 30
      - name: Capture baseline comparison failure
        if: failure() && steps.analysis.outcome == 'failure'
        uses: ./.github/actions/capture-failure
        with:
          failure-type: benchmark
          otp-version: '27'


      - name: Fail on regression
        if: steps.analysis.outputs.has_regression == 'true'
        run: |
          echo "::error::Performance regression detected - blocking merge"
          echo "Regression count: ${{ steps.analysis.outputs.regression_count }}"
          echo "See comparison report in artifacts for details"
          exit 1

  #=============================================================================
  # JOB 3: PR Comment with Results
  #=============================================================================
  pr-comment:
    name: PR Comment
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: [performance-regression-tests, baseline-comparison]
    permissions:
      pull-requests: write

    steps:
      - name: Download test logs
        uses: actions/download-artifact@v4
        with:
          name: performance-regression-logs
          path: ./logs

      - name: Download comparison report
        uses: actions/download-artifact@v4
        with:
          name: baseline-comparison-report
          path: ./comparison

      - name: Generate PR comment
        id: comment
        run: |
          # Read test results
          TEST_STATUS="${{ needs.performance-regression-tests.result }}"
          BASELINE_STATUS="${{ needs.baseline-comparison.result }}"

          # Build comment body
          cat > pr_comment.md << 'EOF'
          ## ðŸš€ Performance Regression Check

          ### Test Results

          **Performance Tests:** ${{ needs.performance-regression-tests.result == 'success' && 'âœ… PASSED' || 'âŒ FAILED' }}
          **Baseline Comparison:** ${{ needs.baseline-comparison.result == 'success' && 'âœ… PASSED' || 'âŒ FAILED' }}

          ### Summary

          EOF

          # Add regression details if available
          if [ -f "logs/performance_report.md" ]; then
            cat logs/performance_report.md >> pr_comment.md
            echo "" >> pr_comment.md
          fi

          # Add comparison details
          if ls comparison/comparison_*.html 1> /dev/null 2>&1; then
            echo "### ðŸ“Š Baseline Comparison" >> pr_comment.md
            echo "" >> pr_comment.md
            echo "A detailed comparison report is available in the [workflow artifacts](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})." >> pr_comment.md
            echo "" >> pr_comment.md
          fi

          # Add recommendations if tests failed
          if [ "$TEST_STATUS" != "success" ] || [ "$BASELINE_STATUS" != "success" ]; then
            cat >> pr_comment.md << 'REC'
            ### âš ï¸ Action Required

            Performance regressions were detected. Please review:

            1. **Test Logs**: Download `performance-regression-logs` artifact
            2. **Comparison Report**: Download `baseline-comparison-report` artifact
            3. **Fix**: Address the performance issues before merging

            ### To Accept Intentional Regressions

            If the performance change is intentional and justified:

            ```bash
            # Update baseline locally
            ./tools/baseline-update.sh --reason "Justification for change"

            # Commit and push
            git add bench/baselines/
            git commit -m "chore: update performance baseline"
            git push
            ```

            **Note:** Baseline updates require explicit justification and will be reviewed.
            REC
          else
            cat >> pr_comment.md << 'EOF'
            ### âœ… All Performance Checks Passed

            No regressions detected. This PR meets all performance requirements.
            EOF
          fi

          # Add thresholds info
          cat >> pr_comment.md << 'EOF'
          ---
          **Thresholds:** 10% performance, 20% memory
          **Workflow:** performance-regression.yml
          EOF

          # Output for next step
          echo "comment_body<<EOF" >> $GITHUB_OUTPUT
          cat pr_comment.md >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Post comment to PR
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let body = fs.readFileSync('pr_comment.md', 'utf8');

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Performance Regression Check')
            );

            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

  #=============================================================================
  # JOB 4: Update Baseline (main branch only)
  #=============================================================================
  update-baseline:
    name: Update Baseline
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    needs: performance-regression-tests

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Erlang/OTP
        uses: erlef/setup-beam@v1
        with:
          otp-version: '27'
          rebar3-version: '3.23'

      - name: Compile project
        run: |
          TERM=dumb rebar3 compile

      - name: Capture new baseline
        run: |
          chmod +x tools/baseline-capture.sh
          ./tools/baseline-capture.sh --no-commit

      - name: Commit baseline
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"

          # Add any new baseline files
          git add bench/baselines/*.json || true

          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No baseline changes to commit"
          else
            git commit -m "chore: update performance baseline [skip ci]

            Automatic baseline update from CI/CD pipeline
            Version: $(grep -o '{vsn, "[^"]*"}' src/erlmcp.app.src | sed 's/{vsn, "\(.*\)"}/\1/')

            Co-Authored-By: GitHub Actions <actions@github.com>"
            git push origin main
          fi

  #=============================================================================
  # JOB 5: Performance Trend Analysis
  #=============================================================================
  trend-analysis:
    name: Performance Trend Analysis
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: performance-regression-tests
    permissions:
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Analyze performance trends
        run: |
          echo "# Performance Trend Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Get recent performance history
          git log --oneline --grep="baseline\|performance" -20 >> $GITHUB_STEP_SUMMARY || true

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Recent Baselines" >> $GITHUB_STEP_SUMMARY
          ls -lh bench/baselines/*.json 2>/dev/null | tail -5 >> $GITHUB_STEP_SUMMARY || echo "No baselines found" >> $GITHUB_STEP_SUMMARY

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Performance History" >> $GITHUB_STEP_SUMMARY
          echo "Analyzing trends across recent commits..." >> $GITHUB_STEP_SUMMARY

      - name: Generate trend visualization
        if: hashFiles('scripts/generate_trend_chart.sh') != ''
        run: |
          chmod +x scripts/generate_trend_chart.sh
          ./scripts/generate_trend_chart.sh || true

      - name: Upload trend analysis
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-trend-analysis
          path: |
            bench/trends/
            *.png
          retention-days: 90
          if-no-files-found: ignore
