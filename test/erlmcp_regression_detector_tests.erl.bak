-module(erlmcp_regression_detector_tests).

-include_lib("eunit/include/eunit.hrl").
-include_lib("kernel/include/logger.hrl").

%% Test setup/teardown
setup() ->
    erlmcp_regression_detector:start().

teardown(_) ->
    erlmcp_regression_detector:stop().

%% Test suite
regression_detector_test_() ->
    {setup,
     fun setup/0,
     fun teardown/1,
     [
         {"Basic regression detection", fun test_basic_regression_detection/0},
         {"Baseline establishment", fun test_baseline_establishment/0},
         {"Statistical significance", fun test_statistical_significance/0},
         {"Latency regression detection", fun test_latency_regression/0},
         {"Throughput regression detection", fun test_throughput_regression/0},
         {"Error rate regression detection", fun test_error_rate_regression/0},
         {"Resource usage regression detection", fun test_resource_regression/0},
         {"Alert system", fun test_alert_system/0},
         {"Confidence calculation", fun test_confidence_calculation/0},
         {"Severity assessment", fun test_severity_assessment/0},
         {"Configuration management", fun test_configuration/0},
         {"Continuous monitoring", fun test_continuous_monitoring/0},
         {"Dashboard integration", fun test_dashboard_integration/0},
         {"Performance under load", fun test_performance_load/0},
         {"Edge cases", fun test_edge_cases/0}
     ]}.

%% @doc Test basic regression detection functionality
test_basic_regression_detection() ->
    % Setup baseline data
    BaselineMetrics = [
        {latency, generate_normal_data(50.0, 5.0, 100)},
        {throughput, generate_normal_data(1000.0, 50.0, 100)},
        {error_rate, generate_normal_data(0.01, 0.005, 100)}
    ],
    
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(BaselineMetrics)),
    
    % Test with normal metrics (no regression expected)
    NormalMetrics = #{
        latency => 52.0,
        throughput => 995.0,
        error_rate => 0.012
    },
    
    {ok, Results} = erlmcp_regression_detector:detect_regression(NormalMetrics, latency),
    ?assert(not has_regression(Results)),
    
    % Test with regressed metrics
    RegressedMetrics = #{
        latency => 75.0,    % 50% increase
        throughput => 750.0, % 25% decrease  
        error_rate => 0.05   % 5x increase
    },
    
    {regression_detected, RegressedResults} = erlmcp_regression_detector:detect_regression(RegressedMetrics, latency),
    ?assert(has_regression(RegressedResults)),
    
    ?debugMsg("Basic regression detection test passed").

%% @doc Test baseline establishment with statistical analysis
test_baseline_establishment() ->
    % Test with sufficient samples
    LargeDataset = generate_normal_data(100.0, 10.0, 50),
    Metrics = [{test_metric, LargeDataset}],
    
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(Metrics)),
    
    % Test with insufficient samples
    SmallDataset = generate_normal_data(100.0, 10.0, 5),
    SmallMetrics = [{small_metric, SmallDataset}],
    
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(SmallMetrics)),
    
    ?debugMsg("Baseline establishment test passed").

%% @doc Test statistical significance calculations
test_statistical_significance() ->
    % Create baseline with known parameters
    BaselineData = generate_normal_data(100.0, 15.0, 50),
    Baseline = create_test_baseline(BaselineData),
    
    % Test significant change
    SignificantValue = 130.0, % 2 standard deviations away
    {significant, _PValue} = erlmcp_regression_detector:calculate_statistical_significance(SignificantValue, Baseline),
    
    % Test non-significant change
    NonSignificantValue = 105.0, % Within normal range
    {not_significant, _} = erlmcp_regression_detector:calculate_statistical_significance(NonSignificantValue, Baseline),
    
    ?debugMsg("Statistical significance test passed").

%% @doc Test latency regression detection
test_latency_regression() ->
    BaselineMetrics = [{latency, generate_normal_data(50.0, 5.0, 50)}],
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(BaselineMetrics)),
    
    % Test normal latency
    NormalLatency = #{latency => 52.0},
    {ok, _} = erlmcp_regression_detector:detect_regression(NormalLatency, latency),
    
    % Test regressed latency
    HighLatency = #{latency => 100.0}, % 100% increase
    {regression_detected, Results} = erlmcp_regression_detector:detect_regression(HighLatency, latency),
    
    LatencyResult = find_metric_result(latency, Results),
    ?assert(LatencyResult =/= undefined),
    ?assert(element(6, LatencyResult)), % is_regression field
    
    ?debugMsg("Latency regression detection test passed").

%% @doc Test throughput regression detection  
test_throughput_regression() ->
    BaselineMetrics = [{throughput, generate_normal_data(1000.0, 50.0, 50)}],
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(BaselineMetrics)),
    
    % Test normal throughput
    NormalThroughput = #{throughput => 980.0},
    {ok, _} = erlmcp_regression_detector:detect_regression(NormalThroughput, throughput),
    
    % Test regressed throughput (decrease is regression for throughput)
    LowThroughput = #{throughput => 700.0}, % 30% decrease
    {regression_detected, Results} = erlmcp_regression_detector:detect_regression(LowThroughput, throughput),
    
    ThroughputResult = find_metric_result(throughput, Results),
    ?assert(ThroughputResult =/= undefined),
    ?assert(element(6, ThroughputResult)), % is_regression field
    
    ?debugMsg("Throughput regression detection test passed").

%% @doc Test error rate regression detection
test_error_rate_regression() ->
    BaselineMetrics = [{error_rate, generate_normal_data(0.01, 0.002, 50)}],
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(BaselineMetrics)),
    
    % Test normal error rate
    NormalErrorRate = #{error_rate => 0.012},
    {ok, _} = erlmcp_regression_detector:detect_regression(NormalErrorRate, error_rate),
    
    % Test regressed error rate
    HighErrorRate = #{error_rate => 0.05}, % 5x increase
    {regression_detected, Results} = erlmcp_regression_detector:detect_regression(HighErrorRate, error_rate),
    
    ErrorResult = find_metric_result(error_rate, Results),
    ?assert(ErrorResult =/= undefined),
    ?assert(element(6, ErrorResult)), % is_regression field
    
    ?debugMsg("Error rate regression detection test passed").

%% @doc Test resource usage regression detection
test_resource_regression() ->
    BaselineMetrics = [{resource_usage, generate_normal_data(60.0, 8.0, 50)}],
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(BaselineMetrics)),
    
    % Test normal resource usage
    NormalResource = #{resource_usage => 65.0},
    {ok, _} = erlmcp_regression_detector:detect_regression(NormalResource, resource_usage),
    
    % Test regressed resource usage
    HighResource = #{resource_usage => 95.0}, % ~60% increase
    {regression_detected, Results} = erlmcp_regression_detector:detect_regression(HighResource, resource_usage),
    
    ResourceResult = find_metric_result(resource_usage, Results),
    ?assert(ResourceResult =/= undefined),
    ?assert(element(6, ResourceResult)), % is_regression field
    
    ?debugMsg("Resource usage regression detection test passed").

%% @doc Test alert system
test_alert_system() ->
    % Setup baseline
    BaselineMetrics = [{latency, generate_normal_data(50.0, 5.0, 50)}],
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(BaselineMetrics)),
    
    % Configure alert channels
    Config = #{
        latency => 0.20, % 20% threshold
        alert_channels => [log, console]
    },
    ?assertEqual(ok, erlmcp_regression_detector:configure_thresholds(Config)),
    
    % Trigger regression that should cause alert
    CriticalLatency = #{latency => 100.0}, % 100% increase
    {regression_detected, Results} = erlmcp_regression_detector:detect_regression(CriticalLatency, latency),
    
    % Verify alert was triggered (check logs or mock alert system)
    ?assert(has_critical_regression(Results)),
    
    ?debugMsg("Alert system test passed").

%% @doc Test confidence calculation
test_confidence_calculation() ->
    BaselineData = generate_normal_data(100.0, 10.0, 50),
    Baseline = create_test_baseline(BaselineData),
    
    % Value within confidence interval
    ValueInRange = 105.0,
    HighConfidence = erlmcp_regression_detector:calculate_confidence(ValueInRange, Baseline),
    ?assert(HighConfidence > 0.9),
    
    % Value outside confidence interval
    ValueOutOfRange = 150.0,
    LowConfidence = erlmcp_regression_detector:calculate_confidence(ValueOutOfRange, Baseline),
    ?assert(LowConfidence < 0.5),
    
    ?debugMsg("Confidence calculation test passed").

%% @doc Test severity assessment
test_severity_assessment() ->
    % Test different severity levels for latency
    LowSeverity = erlmcp_regression_detector:calculate_severity(latency, 15.0),
    ?assertEqual(low, LowSeverity),
    
    MediumSeverity = erlmcp_regression_detector:calculate_severity(latency, 35.0),
    ?assertEqual(medium, MediumSeverity),
    
    HighSeverity = erlmcp_regression_detector:calculate_severity(latency, 75.0),
    ?assertEqual(high, HighSeverity),
    
    CriticalSeverity = erlmcp_regression_detector:calculate_severity(latency, 150.0),
    ?assertEqual(critical, CriticalSeverity),
    
    % Test error rate severities
    CriticalErrorSeverity = erlmcp_regression_detector:calculate_severity(error_rate, 60.0),
    ?assertEqual(critical, CriticalErrorSeverity),
    
    ?debugMsg("Severity assessment test passed").

%% @doc Test configuration management
test_configuration() ->
    % Test threshold configuration
    NewThresholds = #{
        latency => 0.15,
        throughput => 0.20,
        error_rate => 0.05
    },
    ?assertEqual(ok, erlmcp_regression_detector:configure_thresholds(NewThresholds)),
    
    % Test continuous monitoring toggle
    ?assertEqual(ok, erlmcp_regression_detector:enable_continuous_monitoring(true)),
    ?assertEqual(ok, erlmcp_regression_detector:enable_continuous_monitoring(false)),
    
    ?debugMsg("Configuration management test passed").

%% @doc Test continuous monitoring
test_continuous_monitoring() ->
    ?assertEqual(ok, erlmcp_regression_detector:enable_continuous_monitoring(true)),
    
    % Simulate continuous monitoring by checking multiple times
    BaselineMetrics = [{latency, generate_normal_data(50.0, 5.0, 50)}],
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(BaselineMetrics)),
    
    % Multiple checks with varying metrics
    TestMetrics = [
        #{latency => 52.0}, % Normal
        #{latency => 48.0}, % Normal
        #{latency => 85.0}, % Regression
        #{latency => 55.0}  % Back to normal
    ],
    
    Results = lists:map(fun(Metrics) ->
        erlmcp_regression_detector:detect_regression(Metrics, latency)
    end, TestMetrics),
    
    % Should have one regression detection
    Regressions = [R || {regression_detected, _} = R <- Results],
    ?assertEqual(1, length(Regressions)),
    
    ?debugMsg("Continuous monitoring test passed").

%% @doc Test dashboard integration
test_dashboard_integration() ->
    % Start dashboard
    ?assertEqual({ok, _}, erlmcp_regression_dashboard:start_dashboard(8081)),
    
    % Get dashboard data
    {ok, DashboardData} = erlmcp_regression_dashboard:get_dashboard_data(),
    ?assert(is_map(DashboardData)),
    ?assert(maps:is_key(timestamp, DashboardData)),
    ?assert(maps:is_key(metrics, DashboardData)),
    
    % Test dashboard update
    UpdateData = #{
        metrics => #{latency => 75.0, throughput => 900.0},
        regressions => []
    },
    ?assertEqual(ok, erlmcp_regression_dashboard:update_dashboard(UpdateData)),
    
    % Test dashboard rendering
    {ok, HTML} = erlmcp_regression_dashboard:render_dashboard(),
    ?assert(is_list(HTML)),
    ?assert(length(HTML) > 0),
    
    % Stop dashboard
    ?assertEqual(ok, erlmcp_regression_dashboard:stop_dashboard()),
    
    ?debugMsg("Dashboard integration test passed").

%% @doc Test performance under load
test_performance_load() ->
    % Setup baseline
    LargeBaseline = generate_normal_data(100.0, 15.0, 1000),
    BaselineMetrics = [{performance_test, LargeBaseline}],
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(BaselineMetrics)),
    
    % Measure performance of many regression checks
    NumTests = 100,
    TestMetrics = [#{performance_test => 95.0 + rand:uniform(20)} || _ <- lists:seq(1, NumTests)],
    
    StartTime = erlang:system_time(microsecond),
    
    Results = lists:map(fun(Metrics) ->
        erlmcp_regression_detector:detect_regression(Metrics, performance_test)
    end, TestMetrics),
    
    EndTime = erlang:system_time(microsecond),
    Duration = EndTime - StartTime,
    
    % Should complete within reasonable time (< 100ms for 100 checks)
    ?assert(Duration < 100000), % 100ms in microseconds
    
    % All should return valid results
    ?assertEqual(NumTests, length(Results)),
    
    ?debugMsg(io_lib:format("Performance test completed ~p checks in ~p microseconds", [NumTests, Duration])).

%% @doc Test edge cases and error handling
test_edge_cases() ->
    % Test with no baseline
    NoBaseline = #{latency => 50.0},
    ?assertEqual({error, no_baseline}, erlmcp_regression_detector:detect_regression(NoBaseline, nonexistent)),
    
    % Test with empty metrics
    EmptyMetrics = #{},
    BaselineMetrics = [{empty_test, generate_normal_data(50.0, 5.0, 30)}],
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(BaselineMetrics)),
    {ok, EmptyResults} = erlmcp_regression_detector:detect_regression(EmptyMetrics, empty_test),
    ?assertEqual([], EmptyResults),
    
    % Test with extreme values
    ExtremeMetrics = #{latency => 999999.0},
    ExtremeBaseline = [{latency, generate_normal_data(50.0, 5.0, 30)}],
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(ExtremeBaseline)),
    {regression_detected, ExtremeResults} = erlmcp_regression_detector:detect_regression(ExtremeMetrics, latency),
    ?assert(has_critical_regression(ExtremeResults)),
    
    % Test with zero/negative values
    ZeroMetrics = #{error_rate => 0.0},
    ZeroBaseline = [{error_rate, [0.01, 0.02, 0.015, 0.008, 0.012]}],
    ?assertEqual(ok, erlmcp_regression_detector:update_baseline(ZeroBaseline)),
    {ok, _ZeroResults} = erlmcp_regression_detector:detect_regression(ZeroMetrics, error_rate),
    
    ?debugMsg("Edge cases test passed").

%% Helper functions

%% @doc Generate normal distribution data
generate_normal_data(Mean, StdDev, Count) ->
    [Mean + StdDev * rand_normal() || _ <- lists:seq(1, Count)].

%% @doc Generate random normal distribution value (Box-Muller transform)
rand_normal() ->
    case get(normal_cache) of
        undefined ->
            U1 = rand:uniform(),
            U2 = rand:uniform(),
            Z0 = math:sqrt(-2 * math:log(U1)) * math:cos(2 * math:pi() * U2),
            Z1 = math:sqrt(-2 * math:log(U1)) * math:sin(2 * math:pi() * U2),
            put(normal_cache, Z1),
            Z0;
        Z1 ->
            erase(normal_cache),
            Z1
    end.

%% @doc Create test baseline record
create_test_baseline(Data) ->
    Mean = lists:sum(Data) / length(Data),
    Variance = lists:sum([math:pow(X - Mean, 2) || X <- Data]) / (length(Data) - 1),
    StdDev = math:sqrt(Variance),
    StandardError = StdDev / math:sqrt(length(Data)),
    Margin = 1.96 * StandardError,
    
    #{
        mean => Mean,
        std_dev => StdDev,
        samples => Data,
        timestamp => erlang:system_time(millisecond),
        confidence_interval => {Mean - Margin, Mean + Margin}
    }.

%% @doc Check if results contain regression
has_regression(Results) ->
    lists:any(fun(R) -> 
        element(6, R) % is_regression field
    end, Results).

%% @doc Check if results contain critical regression
has_critical_regression(Results) ->
    lists:any(fun(R) -> 
        element(6, R) andalso element(7, R) =:= critical % is_regression and severity
    end, Results).

%% @doc Find metric result in results list
find_metric_result(MetricName, Results) ->
    lists:keyfind(MetricName, 2, Results). % metric_name is field 2

%% @doc Run all tests
run_tests() ->
    ?debugMsg("Starting regression detector tests..."),
    eunit:test(?MODULE, [verbose]),
    ?debugMsg("All regression detector tests completed!").