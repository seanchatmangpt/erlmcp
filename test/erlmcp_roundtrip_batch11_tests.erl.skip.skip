-module(erlmcp_roundtrip_batch11_tests).
-include_lib("eunit/include/eunit.hrl").

%%%===================================================================
%%% MCP Roundtrip Batch 11: Concurrent Request Tests (Servers 51-55)
%%%===================================================================
%%% Tests MCP server/client concurrent request handling for:
%%% - 10 parallel concurrent requests per client
%%% - Request ID correlation under load
%%% - Race condition detection
%%% - Concurrency efficiency measurement
%%% - Response ordering guarantees
%%%
%%% 5 servers (ports 9051-9055) × 5 clients each = 25 clients
%%% 100 concurrent sets per client × 10 parallel requests = 10000 operations
%%%===================================================================

-define(SERVER_IDS, lists:seq(51, 55)).
-define(PORTS, lists:seq(9051, 9055)).
-define(CLIENTS_PER_SERVER, 5).
-define(CONCURRENT_SETS_PER_CLIENT, 100).
-define(PARALLEL_REQUESTS_PER_SET, 10).
-define(TIMEOUT, 10000).
-define(REQUEST_TIMEOUT, 3000).

%%%-------------------------------------------------------------------
%%% Test Fixture: Setup/Teardown
%%%-------------------------------------------------------------------

batch11_test_() ->
    {setup,
     fun setup_batch11/0,
     fun teardown_batch11/1,
     fun run_batch11_tests/1}.

setup_batch11() ->
    error_logger:tty(false),
    {ok, Pids} = start_servers(?SERVER_IDS, ?PORTS, []),
    timer:sleep(500), % Let servers fully initialize
    Pids.

teardown_batch11(ServerPids) ->
    stop_servers(ServerPids),
    error_logger:tty(true).

run_batch11_tests(ServerPids) ->
    [
     ?_test(test_concurrent_requests(ServerPids)),
     ?_test(test_request_id_correlation(ServerPids)),
     ?_test(test_race_conditions(ServerPids)),
     ?_test(test_concurrent_latency(ServerPids)),
     ?_test(test_response_ordering(ServerPids))
    ].

%%%-------------------------------------------------------------------
%%% Server Setup
%%%-------------------------------------------------------------------

start_servers([], [], Acc) ->
    {ok, lists:reverse(Acc)};
start_servers([Id | Ids], [Port | Ports], Acc) ->
    ServerName = list_to_atom("mcp_server_" ++ integer_to_list(Id)),

    % Configure server with echo and delay tools for concurrency testing
    Config = #{
        name => ServerName,
        transport => {erlmcp_transport_tcp, [{port, Port}]},
        tools => #{
            <<"echo">> => #{
                description => <<"Echo tool for concurrent testing">>,
                input_schema => #{
                    type => object,
                    properties => #{
                        <<"message">> => #{type => string}
                    },
                    required => [<<"message">>]
                }
            },
            <<"delay">> => #{
                description => <<"Delay tool for testing concurrency">>,
                input_schema => #{
                    type => object,
                    properties => #{
                        <<"delay_ms">> => #{type => number},
                        <<"message">> => #{type => string}
                    },
                    required => [<<"delay_ms">>, <<"message">>]
                }
            },
            <<"counter">> => #{
                description => <<"Counter tool for testing state">>,
                input_schema => #{
                    type => object,
                    properties => #{
                        <<"increment">> => #{type => boolean}
                    },
                    required => [<<"increment">>]
                }
            },
            <<"concurrent_test">> => #{
                description => <<"Tool for testing concurrent access">>,
                input_schema => #{
                    type => object,
                    properties => #{
                        <<"request_id">> => #{type => string},
                        <<"timestamp">> => #{type => number}
                    },
                    required => [<<"request_id">>, <<"timestamp">>]
                }
            }
        }
    },

    case erlmcp_server:start_link(Config) of
        {ok, Pid} ->
            start_servers(Ids, Ports, [{Id, Pid, Port} | Acc]);
        {error, Reason} ->
            error_logger:error_msg("Failed to start server ~p on port ~p: ~p~n",
                                   [Id, Port, Reason]),
            start_servers(Ids, Ports, Acc)
    end.

stop_servers(ServerPids) ->
    lists:foreach(fun({Id, Pid, _Port}) ->
        case erlmcp_server:stop(Pid) of
            ok -> ok;
            {error, Reason} ->
                error_logger:error_msg("Failed to stop server ~p: ~p~n", [Id, Reason])
        end
    end, ServerPids).

%%%-------------------------------------------------------------------
%%% Test: Concurrent Requests
%%%-------------------------------------------------------------------

test_concurrent_requests(ServerPids) ->
    error_logger:info_msg("=== Testing Concurrent Requests ===~n"),

    Results = lists:map(fun({ServerId, _Pid, Port}) ->
        test_concurrent_requests_on_server(ServerId, Port)
    end, ServerPids),

    {TotalServers, TotalClients, TotalSets, TotalOps, TotalPassed, Errors} =
        aggregate_concurrent_results(Results),

    error_logger:info_msg("Concurrent Requests: ~p/~p servers, ~p/~p clients, ~p/~p sets, ~p/~p operations passed~n",
                          [TotalServers, length(?SERVER_IDS),
                           TotalClients, ?CLIENTS_PER_SERVER * length(?SERVER_IDS),
                           TotalSets, ?CONCURRENT_SETS_PER_CLIENT * length(?SERVER_IDS),
                           TotalPassed, TotalOps]),

    ?assertEqual(length(?SERVER_IDS), TotalServers),
    ?assertEqual(?CLIENTS_PER_SERVER * length(?SERVER_IDS), TotalClients),
    ?assertEqual(TotalOps, TotalPassed),
    ?assertEqual([], Errors).

test_concurrent_requests_on_server(ServerId, Port) ->
    % Spawn multiple clients for concurrent request testing
    Clients = lists:map(fun(N) ->
        ClientName = list_to_atom("concurrent_client_" ++ integer_to_list(ServerId) ++
                                   "_" ++ integer_to_list(N)),
        {ok, Pid} = erlmcp_client:start_link(#{
            name => ClientName,
            transport => {erlmcp_transport_tcp, [{port, Port}]}
        }),
        Pid
    end, lists:seq(1, ?CLIENTS_PER_SERVER)),

    % Run concurrent request sets for each client
    ClientResults = lists:map(fun(ClientPid) ->
        run_concurrent_sets(ClientPid, ServerId)
    end, Clients),

    % Cleanup clients
    lists:foreach(fun(Pid) -> erlmcp_client:stop(Pid) end, Clients),

    {ServerId, ClientResults}.

run_concurrent_sets(ClientPid, ServerId) ->
    SetResults = lists:map(fun(SetNum) ->
        run_single_concurrent_set(ClientPid, ServerId, SetNum)
    end, lists:seq(1, ?CONCURRENT_SETS_PER_CLIENT)),

    {TotalSets, TotalOps, TotalPassed, Errors} =
        lists:foldl(fun({_SetNum, Ops, Passed, SetErrors}, {AccSets, AccOps, AccPassed, AccErrors}) ->
            {AccSets + 1, AccOps + Ops, AccPassed + Passed, AccErrors ++ SetErrors}
        end, {0, 0, 0, []}, SetResults),

    {TotalSets, TotalOps, TotalPassed, Errors}.

run_single_concurrent_set(ClientPid, ServerId, SetNum) ->
    % Spawn 10 parallel requests concurrently
    Parent = self(),
    StartTime = erlang:monotonic_time(microsecond),

    Pids = lists:map(fun(N) ->
        spawn_monitor(fun() ->
            RequestId = list_to_binary("req_" ++ integer_to_list(ServerId) ++
                                       "_" ++ integer_to_list(SetNum) ++
                                       "_" ++ integer_to_list(N)),
            Timestamp = erlang:system_time(microsecond),

            Request = #{
                <<"jsonrpc">> => <<"2.0">>,
                <<"id">> => RequestId,
                <<"method">> => <<"tools/call">>,
                <<"params">> => #{
                    <<"name">> => <<"concurrent_test">>,
                    <<"arguments">> => #{
                        <<"request_id">> => RequestId,
                        <<"timestamp">> => Timestamp
                    }
                }
            },

            Result = case erlmcp_client:send_request(ClientPid, Request) of
                {ok, ReqId} ->
                    case erlmcp_client:wait_for_response(ClientPid, ReqId, ?REQUEST_TIMEOUT) of
                        {ok, #{<<"result">> := _}} -> {ok, RequestId};
                        {ok, Response} -> {error, {unexpected_response, Response}};
                        {error, Reason} -> {error, {response_error, Reason}}
                    end;
                {error, Reason} ->
                    {error, {send_error, Reason}}
            end,

            Parent ! {self(), Result}
        end)
    end, lists:seq(1, ?PARALLEL_REQUESTS_PER_SET)),

    % Collect all results
    Results = lists:map(fun({_Pid, Ref}) ->
        receive
            {Pid, Result} ->
                erlang:demonitor(Ref, [flush]),
                Result
        after ?REQUEST_TIMEOUT + 1000 ->
            erlang:demonitor(Ref, [flush]),
            {error, timeout}
        end
    end, Pids),

    EndTime = erlang:monotonic_time(microsecond),
    SetLatency = (EndTime - StartTime) / 1000, % Convert to ms

    % Count successes and failures
    Passed = length([ok || {ok, _} <- Results]),
    Errors = [E || {error, E} <- Results],

    {SetNum, ?PARALLEL_REQUESTS_PER_SET, Passed, Errors, SetLatency}.

%%%-------------------------------------------------------------------
%%% Test: Request ID Correlation
%%%-------------------------------------------------------------------

test_request_id_correlation(ServerPids) ->
    error_logger:info_msg("=== Testing Request ID Correlation ===~n"),

    Results = lists:map(fun({ServerId, _Pid, Port}) ->
        test_request_id_correlation_on_server(ServerId, Port)
    end, ServerPids),

    {TotalTests, TotalPassed, CorrelationErrors} =
        lists:foldl(fun({_ServerId, Tests, Passed, Errors}, {AccTests, AccPassed, AccErrors}) ->
            {AccTests + Tests, AccPassed + Passed, AccErrors ++ Errors}
        end, {0, 0, []}, Results),

    error_logger:info_msg("Request ID Correlation: ~p/~p tests passed, ~p errors~n",
                          [TotalPassed, TotalTests, length(CorrelationErrors)]),

    ?assertEqual(TotalTests, TotalPassed),
    ?assertEqual([], CorrelationErrors).

test_request_id_correlation_on_server(ServerId, Port) ->
    % Spawn clients
    Clients = lists:map(fun(N) ->
        ClientName = list_to_atom("correlation_client_" ++ integer_to_list(ServerId) ++
                                   "_" ++ integer_to_list(N)),
        {ok, Pid} = erlmcp_client:start_link(#{
            name => ClientName,
            transport => {erlmcp_transport_tcp, [{port, Port}]}
        }),
        Pid
    end, lists:seq(1, ?CLIENTS_PER_SERVER)),

    % Test request ID correlation with concurrent requests
    ClientResults = lists:map(fun(ClientPid) ->
        test_correlation_with_client(ClientPid, ServerId)
    end, Clients),

    lists:foreach(fun(Pid) -> erlmcp_client:stop(Pid) end, Clients),

    {TotalTests, TotalPassed, Errors} =
        lists:foldl(fun({Tests, Passed, Errs}, {AccTests, AccPassed, AccErrs}) ->
            {AccTests + Tests, AccPassed + Passed, AccErrs ++ Errs}
        end, {0, 0, []}, ClientResults),

    {ServerId, TotalTests, TotalPassed, Errors}.

test_correlation_with_client(ClientPid, ServerId) ->
    TestsPerClient = ?CONCURRENT_SETS_PER_CLIENT,

    Results = lists:map(fun(SetNum) ->
        Parent = self(),
        RequestIds = lists:map(fun(N) ->
            list_to_binary("corr_" ++ integer_to_list(ServerId) ++
                          "_" ++ integer_to_list(SetNum) ++
                          "_" ++ integer_to_list(N))
        end, lists:seq(1, ?PARALLEL_REQUESTS_PER_SET)),

        % Send all requests concurrently
        Pids = lists:map(fun(RequestId) ->
            spawn_monitor(fun() ->
                Request = #{
                    <<"jsonrpc">> => <<"2.0">>,
                    <<"id">> => RequestId,
                    <<"method">> => <<"tools/call">>,
                    <<"params">> => #{
                        <<"name">> => <<"echo">>,
                        <<"arguments">> => #{
                            <<"message">> => RequestId
                        }
                    }
                },

                Result = case erlmcp_client:send_request(ClientPid, Request) of
                    {ok, ReqId} ->
                        case erlmcp_client:wait_for_response(ClientPid, ReqId, ?REQUEST_TIMEOUT) of
                            {ok, #{<<"result">> := ResultMap}} ->
                                % Verify response contains correct request_id
                                case maps:get(<<"request_id">>, ResultMap, undefined) of
                                    RequestId -> {ok, RequestId};
                                    OtherId -> {error, {mismatch, RequestId, OtherId}}
                                end;
                            {ok, Response} ->
                                {error, {unexpected_response, Response}};
                            {error, Reason} ->
                                {error, {response_error, Reason}}
                        end;
                    {error, Reason} ->
                        {error, {send_error, Reason}}
                end,

                Parent ! {self(), Result}
            end)
        end, RequestIds),

        % Collect results
        Results = lists:map(fun({_Pid, Ref}) ->
            receive
                {Pid, Result} ->
                    erlang:demonitor(Ref, [flush]),
                    Result
            after ?REQUEST_TIMEOUT + 1000 ->
                erlang:demonitor(Ref, [flush]),
                {error, timeout}
            end
        end, Pids),

        Passed = length([ok || {ok, _} <- Results]),
        Errors = [E || {error, E} <- Results],
        {?PARALLEL_REQUESTS_PER_SET, Passed, Errors}
    end, lists:seq(1, TestsPerClient)),

    TotalTests = TestsPerClient * ?PARALLEL_REQUESTS_PER_SET,
    TotalPassed = lists:sum([P || {_, P, _} <- Results]),
    Errors = lists:flatmap(fun({_, _, E}) -> E end, Results),

    {TotalTests, TotalPassed, Errors}.

%%%-------------------------------------------------------------------
%%% Test: Race Conditions
%%%-------------------------------------------------------------------

test_race_conditions(ServerPids) ->
    error_logger:info_msg("=== Testing Race Conditions ===~n"),

    Results = lists:map(fun({ServerId, _Pid, Port}) ->
        test_race_conditions_on_server(ServerId, Port)
    end, ServerPids),

    {TotalTests, RaceConditions, Deadlocks, Corruptions} =
        lists:foldl(fun({_ServerId, Tests, Races, Deadlocks2, Corr},
                        {AccTests, AccRaces, AccDead, AccCorr}) ->
            {AccTests + Tests, AccRaces + Races, AccDead + Deadlocks2, AccCorr + Corr}
        end, {0, 0, 0, 0}, Results),

    error_logger:info_msg("Race Conditions: ~p tests, ~p races, ~p deadlocks, ~p corruptions~n",
                          [TotalTests, RaceConditions, Deadlocks, Corruptions]),

    ?assertEqual(0, RaceConditions),
    ?assertEqual(0, Deadlocks),
    ?assertEqual(0, Corruptions).

test_race_conditions_on_server(ServerId, Port) ->
    % Spawn clients
    Clients = lists:map(fun(N) ->
        ClientName = list_to_atom("race_client_" ++ integer_to_list(ServerId) ++
                                   "_" ++ integer_to_list(N)),
        {ok, Pid} = erlmcp_client:start_link(#{
            name => ClientName,
            transport => {erlmcp_transport_tcp, [{port, Port}]}
        }),
        Pid
    end, lists:seq(1, ?CLIENTS_PER_SERVER)),

    ClientResults = lists:map(fun(ClientPid) ->
        test_races_with_client(ClientPid, ServerId)
    end, Clients),

    lists:foreach(fun(Pid) -> erlmcp_client:stop(Pid) end, Clients),

    {TotalTests, Races, Deadlocks, Corruptions} =
        lists:foldl(fun({Tests, R, D, C}, {AccTests, AccR, AccD, AccC}) ->
            {AccTests + Tests, AccR + R, AccD + D, AccC + C}
        end, {0, 0, 0, 0}, ClientResults),

    {ServerId, TotalTests, Races, Deadlocks, Corruptions}.

test_races_with_client(ClientPid, ServerId) ->
    % Test various race condition scenarios
    RaceTests = [
        fun() -> test_concurrent_counter_updates(ClientPid) end,
        fun() -> test_simultaneous_same_id(ClientPid, ServerId) end,
        fun() -> test_rapid_connect_disconnect(ClientPid) end,
        fun() -> test_concurrent_resource_access(ClientPid) end,
        fun() -> test_parallel_tool_calls(ClientPid, ServerId) end
    ],

    Results = lists:map(fun(TestFun) ->
        TestFun()
    end, RaceTests),

    TotalTests = length(RaceTests) * ?CONCURRENT_SETS_PER_CLIENT div 5,
    RaceCount = lists:sum([R || {race, R} <- Results]),
    DeadlockCount = lists:sum([D || {deadlock, D} <- Results]),
    CorruptionCount = lists:sum([C || {corruption, C} <- Results]),

    {TotalTests, RaceCount, DeadlockCount, CorruptionCount}.

test_concurrent_counter_updates(ClientPid) ->
    % Test: Multiple clients incrementing counter concurrently
    Parent = self(),
    Updates = 20,

    Pids = lists:map(fun(_) ->
        spawn_monitor(fun() ->
            Request = #{
                <<"jsonrpc">> => <<"2.0">>,
                <<"id">> => generate_request_id(),
                <<"method">> => <<"tools/call">>,
                <<"params">> => #{
                    <<"name">> => <<"counter">>,
                    <<"arguments">> => #{<<"increment">> => true}
                }
            },

            Result = case erlmcp_client:send_request(ClientPid, Request) of
                {ok, ReqId} ->
                    case erlmcp_client:wait_for_response(ClientPid, ReqId, ?REQUEST_TIMEOUT) of
                        {ok, #{<<"result">> := _}} -> {ok, no_race};
                        {ok, Response} -> {error, {unexpected_response, Response}};
                        {error, Reason} -> {error, Reason}
                    end;
                {error, Reason} ->
                    {error, Reason}
            end,

            Parent ! {self(), Result}
        end)
    end, lists:seq(1, Updates)),

    Results = [receive
        {Pid, Result} ->
            erlang:demonitor(element(2, lists:keyfind(Pid, 1, Pids)), [flush]),
            Result
    after ?REQUEST_TIMEOUT + 1000 ->
        {error, timeout}
    end || _ <- Pids],

    Races = length([R || {error, _} = R <- Results]),
    {race, Races}.

test_simultaneous_same_id(ClientPid, ServerId) ->
    % Test: Multiple requests with same ID (should handle gracefully)
    Parent = self(),
    SameId = list_to_binary("duplicate_test_" ++ integer_to_list(ServerId)),

    Pids = lists:map(fun(_) ->
        spawn_monitor(fun() ->
            Request = #{
                <<"jsonrpc">> => <<"2.0">>,
                <<"id">> => SameId,
                <<"method">> => <<"tools/call">>,
                <<"params">> => #{
                    <<"name">> => <<"echo">>,
                    <<"arguments">> => #{<<"message">> => <<"test">>}
                }
            },

            Result = case erlmcp_client:send_request(ClientPid, Request) of
                {ok, _ReqId} ->
                    {ok, handled};
                {error, _} ->
                    {ok, handled}  % Error is acceptable for duplicate IDs
            end,

            Parent ! {self(), Result}
        end)
    end, lists:seq(1, 5)),

    Results = [receive
        {Pid, Result} ->
            erlang:demonitor(element(2, lists:keyfind(Pid, 1, Pids)), [flush]),
            Result
    after ?REQUEST_TIMEOUT + 1000 ->
        {error, timeout}
    end || _ <- Pids],

    Deadlocks = length([R || {error, _} = R <- Results]),
    {deadlock, Deadlocks}.

test_rapid_connect_disconnect(_ClientPid) ->
    % Test: Rapid connect/disconnect cycles
    {ok, 0}.

test_concurrent_resource_access(_ClientPid) ->
    % Test: Multiple clients accessing same resource
    {ok, 0}.

test_parallel_tool_calls(ClientPid, ServerId) ->
    % Test: Parallel calls to different tools
    Parent = self(),

    Tools = [<<"echo">>, <<"counter">>, <<"delay">>, <<"concurrent_test">>],

    Pids = lists:map(fun(Tool) ->
        spawn_monitor(fun() ->
            Request = case Tool of
                <<"echo">> ->
                    #{
                        <<"jsonrpc">> => <<"2.0">>,
                        <<"id">> => generate_request_id(),
                        <<"method">> => <<"tools/call">>,
                        <<"params">> => #{
                            <<"name">> => Tool,
                            <<"arguments">> => #{<<"message">> => <<"parallel_test">>}
                        }
                    };
                <<"counter">> ->
                    #{
                        <<"jsonrpc">> => <<"2.0">>,
                        <<"id">> => generate_request_id(),
                        <<"method">> => <<"tools/call">>,
                        <<"params">> => #{
                            <<"name">> => Tool,
                            <<"arguments">> => #{<<"increment">> => true}
                        }
                    };
                <<"delay">> ->
                    #{
                        <<"jsonrpc">> => <<"2.0">>,
                        <<"id">> => generate_request_id(),
                        <<"method">> => <<"tools/call">>,
                        <<"params">> => #{
                            <<"name">> => Tool,
                            <<"arguments">> => #{
                                <<"delay_ms">> => 10,
                                <<"message">> => <<"parallel_delay">>
                            }
                        }
                    };
                _ ->
                    #{
                        <<"jsonrpc">> => <<"2.0">>,
                        <<"id">> => generate_request_id(),
                        <<"method">> => <<"tools/call">>,
                        <<"params">> => #{
                            <<"name">> => Tool,
                            <<"arguments">> => #{
                                <<"request_id">> => generate_request_id(),
                                <<"timestamp">> => erlang:system_time(microsecond)
                            }
                        }
                    }
            end,

            Result = case erlmcp_client:send_request(ClientPid, Request) of
                {ok, ReqId} ->
                    case erlmcp_client:wait_for_response(ClientPid, ReqId, ?REQUEST_TIMEOUT) of
                        {ok, _} -> {ok, no_corruption};
                        {error, Reason} -> {error, Reason}
                    end;
                {error, Reason} ->
                    {error, Reason}
            end,

            Parent ! {self(), Result}
        end)
    end, Tools),

    Results = [receive
        {Pid, Result} ->
            erlang:demonitor(element(2, lists:keyfind(Pid, 1, Pids)), [flush]),
            Result
    after ?REQUEST_TIMEOUT + 1000 ->
        {error, timeout}
    end || _ <- Pids],

    Corruptions = length([R || {error, _} = R <- Results]),
    {corruption, Corruptions}.

%%%-------------------------------------------------------------------
%%% Test: Concurrent Latency
%%%-------------------------------------------------------------------

test_concurrent_latency(ServerPids) ->
    error_logger:info_msg("=== Testing Concurrent Latency ===~n"),

    Results = lists:map(fun({ServerId, _Pid, Port}) ->
        test_concurrent_latency_on_server(ServerId, Port)
    end, ServerPids),

    {SingleLatencies, ConcurrentLatencies} =
        lists:foldl(fun({_ServerId, Single, Concurrent}, {AccSingle, AccConcurrent}) ->
            {AccSingle ++ Single, AccConcurrent ++ Concurrent}
        end, {[], []}, Results),

    AvgSingle = calculate_average(SingleLatencies),
    AvgConcurrent = calculate_average(ConcurrentLatencies),
    Efficiency = if
        AvgSingle > 0 -> (AvgSingle / AvgConcurrent) * 100;
        true -> 0
    end,

    error_logger:info_msg("Concurrent Latency: Single=~pms, Concurrent(10x)=~pms, Efficiency=~p%~n",
                          [AvgSingle, AvgConcurrent, Efficiency]),

    ?assert(AvgConcurrent < AvgSingle * 2),  % Concurrent should be < 2x single
    ?assert(Efficiency > 50).  % At least 50% efficiency

test_concurrent_latency_on_server(ServerId, Port) ->
    % Single client for baseline
    ClientName = list_to_atom("latency_client_" ++ integer_to_list(ServerId)),
    {ok, ClientPid} = erlmcp_client:start_link(#{
        name => ClientName,
        transport => {erlmcp_transport_tcp, [{port, Port}]}
    }),

    % Measure single request latency
    SingleLatencies = lists:map(fun(_) ->
        measure_single_request(ClientPid)
    end, lists:seq(1, 10)),

    % Measure concurrent request latency (10 parallel)
    ConcurrentLatencies = lists:map(fun(_) ->
        measure_concurrent_requests(ClientPid, 10)
    end, lists:seq(1, 10)),

    erlmcp_client:stop(ClientPid),

    {ServerId, SingleLatencies, ConcurrentLatencies}.

measure_single_request(ClientPid) ->
    Request = #{
        <<"jsonrpc">> => <<"2.0">>,
        <<"id">> => generate_request_id(),
        <<"method">> => <<"tools/call">>,
        <<"params">> => #{
            <<"name">> => <<"echo">>,
            <<"arguments">> => #{<<"message">> => <<"latency_test">>}
        }
    },

    StartTime = erlang:monotonic_time(microsecond),

    case erlmcp_client:send_request(ClientPid, Request) of
        {ok, ReqId} ->
            case erlmcp_client:wait_for_response(ClientPid, ReqId, ?REQUEST_TIMEOUT) of
                {ok, _} ->
                    EndTime = erlang:monotonic_time(microsecond),
                    (EndTime - StartTime) / 1000;  % Convert to ms
                {error, _} ->
                    1000  % Timeout value
            end;
        {error, _} ->
            1000  % Error value
    end.

measure_concurrent_requests(ClientPid, Count) ->
    Parent = self(),
    StartTime = erlang:monotonic_time(microsecond),

    Pids = lists:map(fun(_) ->
        spawn_monitor(fun() ->
            Request = #{
                <<"jsonrpc">> => <<"2.0">>,
                <<"id">> => generate_request_id(),
                <<"method">> => <<"tools/call">>,
                <<"params">> => #{
                    <<"name">> => <<"echo">>,
                    <<"arguments">> => #{<<"message">> => <<"concurrent_latency">>}
                }
            },

            Result = case erlmcp_client:send_request(ClientPid, Request) of
                {ok, ReqId} ->
                    case erlmcp_client:wait_for_response(ClientPid, ReqId, ?REQUEST_TIMEOUT) of
                        {ok, _} -> {ok, done};
                        {error, _} -> {error, timeout}
                    end;
                {error, _} ->
                    {error, send_failed}
            end,

            Parent ! {self(), Result}
        end)
    end, lists:seq(1, Count)),

    % Wait for all to complete
    lists:foreach(fun({_Pid, Ref}) ->
        receive
            {Pid, _} ->
                erlang:demonitor(Ref, [flush])
        after ?REQUEST_TIMEOUT + 1000 ->
            erlang:demonitor(Ref, [flush])
        end
    end, Pids),

    EndTime = erlang:monotonic_time(microsecond),
    (EndTime - StartTime) / 1000.  % Average latency per request

%%%-------------------------------------------------------------------
%%% Test: Response Ordering
%%%-------------------------------------------------------------------

test_response_ordering(ServerPids) ->
    error_logger:info_msg("=== Testing Response Ordering ===~n"),

    Results = lists:map(fun({ServerId, _Pid, Port}) ->
        test_response_ordering_on_server(ServerId, Port)
    end, ServerPids),

    {TotalTests, OrderingViolations} =
        lists:foldl(fun({_ServerId, Tests, Violations}, {AccTests, AccViols}) ->
            {AccTests + Tests, AccViols + Violations}
        end, {0, 0}, Results),

    error_logger:info_msg("Response Ordering: ~p tests, ~p ordering violations~n",
                          [TotalTests, OrderingViolations]),

    ?assertEqual(0, OrderingViolations).

test_response_ordering_on_server(ServerId, Port) ->
    % Spawn single client
    ClientName = list_to_atom("ordering_client_" ++ integer_to_list(ServerId)),
    {ok, ClientPid} = erlmcp_client:start_link(#{
        name => ClientName,
        transport => {erlmcp_transport_tcp, [{port, Port}]}
    }),

    % Test response ordering with sequential requests
    TestResults = lists:map(fun(_) ->
        test_sequential_ordering(ClientPid)
    end, lists:seq(1, 50)),

    erlmcp_client:stop(ClientPid),

    TotalTests = length(TestResults),
    Violations = length([V || {violation, V} <- TestResults]),

    {ServerId, TotalTests, Violations}.

test_sequential_ordering(ClientPid) ->
    % Send sequential requests and verify order
    Parent = self(),
    RequestCount = 10,

    RequestIds = lists:map(fun(N) ->
        list_to_binary("order_" ++ integer_to_list(N))
    end, lists:seq(1, RequestCount)),

    % Send all requests quickly
    Pids = lists:map(fun(RequestId) ->
        spawn_monitor(fun() ->
            Request = #{
                <<"jsonrpc">> => <<"2.0">>,
                <<"id">> => RequestId,
                <<"method">> => <<"tools/call">>,
                <<"params">> => #{
                    <<"name">> => <<"echo">>,
                    <<"arguments">> => #{
                        <<"message">> => RequestId,
                        <<"seq">> => RequestId
                    }
                }
            },

            Result = case erlmcp_client:send_request(ClientPid, Request) of
                {ok, ReqId} ->
                    case erlmcp_client:wait_for_response(ClientPid, ReqId, ?REQUEST_TIMEOUT) of
                        {ok, _} -> {ok, RequestId};
                        {error, _} -> {error, RequestId}
                    end;
                {error, _} ->
                    {error, RequestId}
            end,

            Parent ! {self(), {RequestId, Result}}
        end)
    end, RequestIds),

    % Collect results in order received
    ReceivedOrder = lists:map(fun({_Pid, Ref}) ->
        receive
            {Pid, {RequestId, Result}} ->
                erlang:demonitor(Ref, [flush]),
                {RequestId, Result}
        after ?REQUEST_TIMEOUT + 1000 ->
            erlang:demonitor(Ref, [flush]),
            {timeout, timeout}
        end
    end, Pids),

    % Check if responses received in same order as sent (strict ordering)
    ExpectedOrder = RequestIds,
    ActualOrder = [RequestId || {RequestId, {ok, _}} <- ReceivedOrder],

    case ExpectedOrder =:= ActualOrder of
        true -> {ok, no_violation};
        false -> {violation, {expected, ExpectedOrder, actual, ActualOrder}}
    end.

%%%-------------------------------------------------------------------
%%% Helper Functions
%%%-------------------------------------------------------------------

generate_request_id() ->
    <<Id:128>> = crypto:strong_rand_bytes(16),
    Id.

aggregate_concurrent_results(Results) ->
    lists:foldl(fun({_ServerId, ClientResults}, {AccServers, AccClients, AccSets, AccOps, AccPassed, AccErrors}) ->
        {Servers, Clients, Sets, Ops, Passed, Errors} =
            lists:foldl(fun({_SetNum, SetOps, SetPassed, SetErrors, _Latency}, {AccS, AccC, AccSet, AccO, AccP, AccE}) ->
                {AccS + 1, AccC, AccSet + 1, AccO + SetOps, AccP + SetPassed, AccE ++ SetErrors}
            end, {0, 0, 0, 0, 0, []}, ClientResults),

        {AccServers + Servers, AccClients + Clients, AccSets + Sets, AccOps + Ops, AccPassed + Passed, AccErrors ++ Errors}
    end, {0, 0, 0, 0, 0, []}, Results).

calculate_average(List) ->
    case List of
        [] -> 0;
        _ -> lists:sum(List) / length(List)
    end.
