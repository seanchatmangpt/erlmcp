-module(erlmcp_load_scenarios).

%% API exports
-export([
    run_scenario/1,
    run_scenario/2,
    get_predefined_scenarios/0,
    validate_system_limits/0,
    benchmark_protocol_comparison/0,
    stress_test_mcp_server/1,
    capacity_planning_test/1
]).

-include_lib("kernel/include/logger.hrl").

-define(DEFAULT_HOST, "localhost").
-define(DEFAULT_PORT, 8080).
-define(MCP_PORT, 3000).

%%%===================================================================
%%% API Functions
%%%===================================================================

%% Run a predefined scenario by name
run_scenario(ScenarioName) ->
    run_scenario(ScenarioName, #{}).

run_scenario(ScenarioName, Overrides) ->
    case get_scenario_config(ScenarioName) of
        {ok, BaseConfig} ->
            Config = maps:merge(BaseConfig, Overrides),
            execute_scenario(ScenarioName, Config);
        {error, Reason} ->
            {error, Reason}
    end.

%% Get list of all predefined scenarios
get_predefined_scenarios() ->
    [
        {api_baseline, "Baseline API performance test"},
        {burst_traffic, "Simulate traffic bursts"},
        {gradual_ramp, "Gradual traffic ramp-up"},
        {peak_hours, "Peak usage simulation"},
        {mobile_patterns, "Mobile app usage patterns"},
        {batch_processing, "Batch operation testing"},
        {websocket_streaming, "WebSocket streaming test"},
        {mcp_protocol_test, "MCP protocol validation"},
        {mixed_workload, "Mixed read/write workload"},
        {connection_pooling, "Connection pooling efficiency"},
        {large_payload, "Large message handling"},
        {high_frequency, "High frequency trading simulation"},
        {iot_telemetry, "IoT device telemetry"},
        {gaming_session, "Gaming session patterns"},
        {cdn_traffic, "CDN traffic simulation"},
        {database_stress, "Database connection stress"},
        {microservice_mesh, "Microservice mesh testing"},
        {chaos_engineering, "Chaos engineering patterns"}
    ].

%% Validate system performance limits
validate_system_limits() ->
    ?LOG_INFO("Starting system limits validation"),
    
    % Test increasing loads to find breaking points
    TestCases = [
        {low_load, 50},
        {medium_load, 200},
        {high_load, 500},
        {stress_load, 1000},
        {extreme_load, 2000}
    ],
    
    Results = lists:map(fun({TestName, Rate}) ->
        ?LOG_INFO("Testing ~p at ~p req/sec", [TestName, Rate]),
        
        Config = #{
            pattern => constant,
            rate => Rate,
            duration => 10000, % 10 seconds
            message_size => medium,
            protocol => http,
            trace_every_request => false % Reduce overhead at high loads
        },
        
        {ok, GeneratorId} = erlmcp_load_generator:generate_traffic(Config),
        
        % Monitor during execution
        timer:sleep(3000),
        {ok, MidMetrics} = erlmcp_load_generator:get_metrics(GeneratorId),
        
        timer:sleep(8000),
        {ok, FinalMetrics} = erlmcp_load_generator:get_metrics(GeneratorId),
        
        % Analyze results
        ActualThroughput = maps:get(throughput_rps, FinalMetrics),
        SuccessRate = maps:get(success_rate, FinalMetrics),
        AvgLatency = maps:get(avg_latency_us, FinalMetrics),
        P99Latency = maps:get(p99_latency_us, FinalMetrics),
        
        SystemStable = SuccessRate > 0.95 andalso P99Latency < AvgLatency * 5,
        
        Result = #{
            test_name => TestName,
            target_rate => Rate,
            actual_throughput => ActualThroughput,
            success_rate => SuccessRate,
            avg_latency_us => AvgLatency,
            p99_latency_us => P99Latency,
            system_stable => SystemStable,
            efficiency => ActualThroughput / Rate
        },
        
        ?LOG_INFO("~p results: throughput=~.1f, success=~.3f, stable=~p", 
                  [TestName, ActualThroughput, SuccessRate, SystemStable]),
        
        Result
    end, TestCases),
    
    % Find performance limits
    MaxStableRate = find_max_stable_rate(Results),
    RecommendedRate = round(MaxStableRate * 0.8), % 80% of max for safety margin
    
    Summary = #{
        test_results => Results,
        max_stable_rate => MaxStableRate,
        recommended_rate => RecommendedRate,
        system_capacity => analyze_system_capacity(Results)
    },
    
    ?LOG_INFO("System validation complete. Max stable: ~p, Recommended: ~p", 
              [MaxStableRate, RecommendedRate]),
    
    {ok, Summary}.

%% Compare different protocols under same load
benchmark_protocol_comparison() ->
    ?LOG_INFO("Starting protocol comparison benchmark"),
    
    Protocols = [http, websocket, tcp, mcp],
    TestConfig = #{
        pattern => constant,
        rate => 100,
        duration => 8000,
        message_size => small,
        trace_every_request => true
    },
    
    Results = lists:map(fun(Protocol) ->
        ?LOG_INFO("Benchmarking protocol: ~p", [Protocol]),
        
        Config = TestConfig#{
            protocol => Protocol,
            target_port => case Protocol of
                mcp -> ?MCP_PORT;
                _ -> ?DEFAULT_PORT
            end
        },
        
        {ok, GeneratorId} = erlmcp_load_generator:generate_traffic(Config),
        timer:sleep(9000),
        
        {ok, Metrics} = erlmcp_load_generator:get_metrics(GeneratorId),
        
        #{
            protocol => Protocol,
            throughput => maps:get(throughput_rps, Metrics),
            success_rate => maps:get(success_rate, Metrics),
            avg_latency => maps:get(avg_latency_us, Metrics),
            p95_latency => maps:get(p95_latency_us, Metrics),
            p99_latency => maps:get(p99_latency_us, Metrics)
        }
    end, Protocols),
    
    % Analyze and rank protocols
    RankedResults = lists:sort(fun(A, B) ->
        ScoreA = calculate_protocol_score(A),
        ScoreB = calculate_protocol_score(B),
        ScoreA > ScoreB
    end, Results),
    
    ?LOG_INFO("Protocol comparison complete"),
    lists:foreach(fun(#{protocol := Proto, throughput := Tput, success_rate := SR}) ->
        ?LOG_INFO("  ~p: throughput=~.1f, success=~.3f", [Proto, Tput, SR])
    end, RankedResults),
    
    {ok, #{
        detailed_results => Results,
        ranked_results => RankedResults,
        recommendations => generate_protocol_recommendations(RankedResults)
    }}.

%% Stress test MCP server specifically
stress_test_mcp_server(ServerConfig) ->
    ?LOG_INFO("Starting MCP server stress test"),
    
    Host = maps:get(host, ServerConfig, ?DEFAULT_HOST),
    Port = maps:get(port, ServerConfig, ?MCP_PORT),
    
    % Progressive stress test
    StressPhases = [
        #{name => warmup, rate => 10, duration => 5000},
        #{name => baseline, rate => 50, duration => 10000},
        #{name => moderate, rate => 100, duration => 15000},
        #{name => high, rate => 200, duration => 10000},
        #{name => stress, rate => 500, duration => 10000},
        #{name => recovery, rate => 50, duration => 5000}
    ],
    
    Results = lists:map(fun(Phase) ->
        PhaseName = maps:get(name, Phase),
        ?LOG_INFO("MCP stress phase: ~p", [PhaseName]),
        
        Config = #{
            pattern => constant,
            rate => maps:get(rate, Phase),
            duration => maps:get(duration, Phase),
            message_size => mixed,
            protocol => mcp,
            target_host => Host,
            target_port => Port,
            workload => mixed,
            trace_every_request => PhaseName =:= baseline % Only trace baseline for detailed analysis
        },
        
        StartTime = erlang:system_time(millisecond),
        {ok, GeneratorId} = erlmcp_load_generator:generate_traffic(Config),
        
        % Wait for phase completion
        timer:sleep(maps:get(duration, Phase) + 1000),
        
        {ok, Metrics} = erlmcp_load_generator:get_metrics(GeneratorId),
        EndTime = erlang:system_time(millisecond),
        
        PhaseResult = Metrics#{
            phase_name => PhaseName,
            target_rate => maps:get(rate, Phase),
            actual_duration => EndTime - StartTime
        },
        
        ?LOG_INFO("Phase ~p: throughput=~.1f, success=~.3f", 
                  [PhaseName, 
                   maps:get(throughput_rps, Metrics),
                   maps:get(success_rate, Metrics)]),
        
        PhaseResult
    end, StressPhases),
    
    % Analyze MCP server behavior
    Analysis = analyze_mcp_performance(Results),
    
    {ok, #{
        phase_results => Results,
        performance_analysis => Analysis,
        server_health => assess_mcp_server_health(Results)
    }}.

%% Capacity planning test for deployment sizing
capacity_planning_test(Requirements) ->
    ?LOG_INFO("Starting capacity planning test"),
    
    ExpectedUsers = maps:get(expected_users, Requirements, 1000),
    PeakMultiplier = maps:get(peak_multiplier, Requirements, 3),
    AvgRequestsPerUser = maps:get(avg_requests_per_user, Requirements, 10),
    
    % Calculate load scenarios
    BaselineRate = ExpectedUsers * AvgRequestsPerUser / 60, % Requests per second
    PeakRate = BaselineRate * PeakMultiplier,
    
    TestScenarios = [
        #{name => baseline, rate => round(BaselineRate), duration => 30000},
        #{name => growth_20, rate => round(BaselineRate * 1.2), duration => 30000},
        #{name => growth_50, rate => round(BaselineRate * 1.5), duration => 30000},
        #{name => peak_traffic, rate => round(PeakRate), duration => 30000},
        #{name => sustained_peak, rate => round(PeakRate * 0.8), duration => 60000}
    ],
    
    Results = lists:map(fun(Scenario) ->
        ScenarioName = maps:get(name, Scenario),
        ?LOG_INFO("Testing capacity scenario: ~p", [ScenarioName]),
        
        Config = #{
            pattern => constant,
            rate => maps:get(rate, Scenario),
            duration => maps:get(duration, Scenario),
            message_size => mixed,
            protocol => http,
            workload => balanced,
            connection_type => pooled,
            max_connections => 50,
            trace_every_request => ScenarioName =:= baseline
        },
        
        {ok, GeneratorId} = erlmcp_load_generator:generate_traffic(Config),
        timer:sleep(maps:get(duration, Scenario) + 2000),
        
        {ok, Metrics} = erlmcp_load_generator:get_metrics(GeneratorId),
        
        ScenarioResult = Metrics#{
            scenario_name => ScenarioName,
            target_users => round(maps:get(rate, Scenario) / AvgRequestsPerUser * 60),
            meets_sla => maps:get(success_rate, Metrics) >= 0.99 andalso 
                        maps:get(p95_latency_us, Metrics) =< 500000 % 500ms SLA
        },
        
        ?LOG_INFO("Scenario ~p: users=~p, success=~.3f, meets_sla=~p", 
                  [ScenarioName,
                   maps:get(target_users, ScenarioResult),
                   maps:get(success_rate, Metrics),
                   maps:get(meets_sla, ScenarioResult)]),
        
        ScenarioResult
    end, TestScenarios),
    
    % Generate capacity recommendations
    Recommendations = generate_capacity_recommendations(Results, Requirements),
    
    {ok, #{
        scenario_results => Results,
        capacity_recommendations => Recommendations,
        deployment_sizing => calculate_deployment_sizing(Results)
    }}.

%%%===================================================================
%%% Internal Functions
%%%===================================================================

get_scenario_config(ScenarioName) ->
    Scenarios = #{
        api_baseline => #{
            pattern => constant,
            rate => 20,
            duration => 30000,
            message_size => small,
            protocol => http,
            workload => balanced,
            connection_type => long_lived,
            trace_every_request => true
        },
        
        burst_traffic => #{
            pattern => burst,
            rate => 30, % Base rate, bursts to 300
            duration => 60000,
            message_size => medium,
            protocol => http,
            workload => read_heavy,
            connection_type => pooled,
            trace_every_request => false
        },
        
        gradual_ramp => #{
            pattern => ramp_up,
            rate => 100, % Max rate
            duration => 120000,
            message_size => small,
            protocol => websocket,
            workload => stream,
            connection_type => long_lived,
            trace_every_request => true
        },
        
        peak_hours => #{
            pattern => sine_wave,
            rate => 80, % Base rate with sine wave variation
            duration => 180000, % 3 minutes
            message_size => mixed,
            protocol => http,
            workload => balanced,
            connection_type => pooled,
            max_connections => 20,
            trace_every_request => false
        },
        
        mobile_patterns => #{
            pattern => random_walk,
            rate => 40,
            duration => 90000,
            message_size => small,
            protocol => http,
            workload => read_heavy,
            connection_type => short_lived,
            trace_every_request => true
        },
        
        batch_processing => #{
            pattern => constant,
            rate => 5,
            duration => 60000,
            message_size => large,
            protocol => tcp,
            workload => batch,
            connection_type => long_lived,
            batch_size => 10,
            trace_every_request => false
        },
        
        websocket_streaming => #{
            pattern => constant,
            rate => 50,
            duration => 60000,
            message_size => medium,
            protocol => websocket,
            workload => stream,
            connection_type => long_lived,
            trace_every_request => true
        },
        
        mcp_protocol_test => #{
            pattern => ramp_up,
            rate => 50,
            duration => 45000,
            message_size => medium,
            protocol => mcp,
            workload => balanced,
            connection_type => pooled,
            target_port => ?MCP_PORT,
            trace_every_request => true
        },
        
        mixed_workload => #{
            pattern => sine_wave,
            rate => 60,
            duration => 120000,
            message_size => mixed,
            protocol => http,
            workload => balanced,
            connection_type => pooled,
            max_connections => 15,
            trace_every_request => false
        },
        
        connection_pooling => #{
            pattern => burst,
            rate => 100,
            duration => 45000,
            message_size => small,
            protocol => http,
            workload => read_heavy,
            connection_type => pooled,
            max_connections => 10,
            trace_every_request => true
        },
        
        large_payload => #{
            pattern => constant,
            rate => 10,
            duration => 30000,
            message_size => large,
            protocol => http,
            workload => write_heavy,
            connection_type => long_lived,
            trace_every_request => false
        },
        
        high_frequency => #{
            pattern => poisson,
            rate => 200, % Lambda
            duration => 60000,
            message_size => small,
            protocol => tcp,
            workload => balanced,
            connection_type => pooled,
            max_connections => 50,
            trace_every_request => false
        },
        
        iot_telemetry => #{
            pattern => poisson,
            rate => 150,
            duration => 90000,
            message_size => small,
            protocol => http,
            workload => write_heavy,
            connection_type => short_lived,
            trace_every_request => false
        },
        
        gaming_session => #{
            pattern => random_walk,
            rate => 80,
            duration => 120000,
            message_size => medium,
            protocol => websocket,
            workload => balanced,
            connection_type => long_lived,
            trace_every_request => true
        },
        
        cdn_traffic => #{
            pattern => burst,
            rate => 200,
            duration => 60000,
            message_size => large,
            protocol => http,
            workload => read_heavy,
            connection_type => pooled,
            max_connections => 30,
            trace_every_request => false
        },
        
        database_stress => #{
            pattern => ramp_up,
            rate => 300,
            duration => 90000,
            message_size => medium,
            protocol => tcp,
            workload => write_heavy,
            connection_type => pooled,
            max_connections => 20,
            trace_every_request => false
        },
        
        microservice_mesh => #{
            pattern => sine_wave,
            rate => 120,
            duration => 150000,
            message_size => mixed,
            protocol => http,
            workload => balanced,
            connection_type => pooled,
            max_connections => 25,
            trace_every_request => true
        },
        
        chaos_engineering => #{
            pattern => random_walk,
            rate => 100,
            duration => 120000,
            message_size => mixed,
            protocol => http,
            workload => mixed,
            connection_type => mixed,
            trace_every_request => false
        }
    },
    
    case maps:get(ScenarioName, Scenarios, undefined) of
        undefined ->
            {error, {unknown_scenario, ScenarioName}};
        Config ->
            {ok, Config#{
                target_host => ?DEFAULT_HOST,
                target_port => ?DEFAULT_PORT
            }}
    end.

execute_scenario(ScenarioName, Config) ->
    ?LOG_INFO("Executing scenario: ~p", [ScenarioName]),
    ?LOG_INFO("Configuration: ~p", [Config]),
    
    StartTime = erlang:system_time(millisecond),
    {ok, GeneratorId} = erlmcp_load_generator:generate_traffic(Config),
    
    % Wait for completion
    Duration = maps:get(duration, Config),
    timer:sleep(Duration + 2000),
    
    {ok, Metrics} = erlmcp_load_generator:get_metrics(GeneratorId),
    EndTime = erlang:system_time(millisecond),
    
    Result = Metrics#{
        scenario_name => ScenarioName,
        config => Config,
        actual_duration => EndTime - StartTime,
        timestamp => StartTime
    },
    
    ?LOG_INFO("Scenario ~p completed: throughput=~.1f req/sec, success=~.3f",
              [ScenarioName, 
               maps:get(throughput_rps, Result),
               maps:get(success_rate, Result)]),
    
    {ok, Result}.

find_max_stable_rate(Results) ->
    StableResults = lists:filter(fun(#{system_stable := Stable}) -> Stable end, Results),
    case StableResults of
        [] -> 0;
        _ ->
            MaxResult = lists:max(lists:map(fun(#{target_rate := Rate}) -> Rate end, StableResults)),
            MaxResult
    end.

analyze_system_capacity(Results) ->
    TotalTests = length(Results),
    StableTests = length([R || R = #{system_stable := true} <- Results]),
    
    AvgEfficiency = lists:sum([maps:get(efficiency, R) || R <- Results]) / TotalTests,
    
    #{
        total_tests => TotalTests,
        stable_tests => StableTests,
        stability_ratio => StableTests / TotalTests,
        avg_efficiency => AvgEfficiency,
        performance_degradation => analyze_degradation_pattern(Results)
    }.

analyze_degradation_pattern(Results) ->
    SortedResults = lists:sort(fun(#{target_rate := A}, #{target_rate := B}) -> A =< B end, Results),
    
    Patterns = lists:map(fun(#{target_rate := Rate, efficiency := Eff, success_rate := SR}) ->
        #{rate => Rate, efficiency => Eff, success_rate => SR}
    end, SortedResults),
    
    #{
        pattern_data => Patterns,
        degradation_point => find_degradation_point(Patterns),
        failure_point => find_failure_point(Patterns)
    }.

find_degradation_point(Patterns) ->
    % Find where efficiency drops below 90%
    case lists:search(fun(#{efficiency := Eff}) -> Eff < 0.9 end, Patterns) of
        {value, #{rate := Rate}} -> Rate;
        false -> undefined
    end.

find_failure_point(Patterns) ->
    % Find where success rate drops below 80%
    case lists:search(fun(#{success_rate := SR}) -> SR < 0.8 end, Patterns) of
        {value, #{rate := Rate}} -> Rate;
        false -> undefined
    end.

calculate_protocol_score(#{throughput := Tput, success_rate := SR, avg_latency := Latency}) ->
    % Weighted score: throughput (40%) + success rate (40%) + latency penalty (20%)
    TputScore = min(Tput / 1000, 1.0), % Normalize to 0-1
    LatencyPenalty = min(Latency / 1000000, 1.0), % Normalize microseconds to penalty
    0.4 * TputScore + 0.4 * SR - 0.2 * LatencyPenalty.

generate_protocol_recommendations(RankedResults) ->
    [Best | _] = RankedResults,
    BestProtocol = maps:get(protocol, Best),
    
    Recommendations = [
        #{
            category => best_overall,
            protocol => BestProtocol,
            reason => "Highest combined performance score"
        }
    ],
    
    % Add specific use case recommendations
    SpecificRecs = lists:foldl(fun(#{protocol := Proto, avg_latency := Lat, success_rate := SR}, Acc) ->
        NewRecs = case Proto of
            tcp when Lat < 50000 -> % < 50ms
                [#{category => low_latency, protocol => Proto, reason => "Lowest latency"} | Acc];
            http when SR > 0.95 ->
                [#{category => reliability, protocol => Proto, reason => "Most reliable"} | Acc];
            websocket ->
                [#{category => streaming, protocol => Proto, reason => "Best for real-time streams"} | Acc];
            mcp ->
                [#{category => rpc, protocol => Proto, reason => "Structured RPC communication"} | Acc];
            _ ->
                Acc
        end,
        NewRecs
    end, Recommendations, RankedResults),
    
    SpecificRecs.

analyze_mcp_performance(Results) ->
    % Analyze specific MCP server behavior patterns
    BaselinePhase = lists:keyfind(baseline, 2, [R || R = #{phase_name := baseline} <- Results]),
    StressPhase = lists:keyfind(stress, 2, [R || R = #{phase_name := stress} <- Results]),
    
    Analysis = #{
        baseline_performance => case BaselinePhase of
            false -> undefined;
            #{throughput_rps := Tput, success_rate := SR, avg_latency_us := Lat} ->
                #{throughput => Tput, success_rate => SR, avg_latency_us => Lat}
        end,
        
        stress_performance => case StressPhase of
            false -> undefined;
            #{throughput_rps := STput, success_rate := SSR, avg_latency_us := SLat} ->
                #{throughput => STput, success_rate => SSR, avg_latency_us => SLat}
        end,
        
        performance_degradation => case {BaselinePhase, StressPhase} of
            {#{throughput_rps := BTput, success_rate := BSR}, 
             #{throughput_rps := STput, success_rate := SSR}} ->
                #{
                    throughput_loss => (BTput - STput) / BTput,
                    success_rate_drop => BSR - SSR,
                    handles_stress => SSR > 0.8 andalso STput > BTput * 0.5
                };
            _ -> undefined
        end
    },
    
    Analysis.

assess_mcp_server_health(Results) ->
    % Assess overall MCP server health based on test phases
    PhaseHealth = lists:map(fun(#{phase_name := Phase, success_rate := SR, 
                                 p99_latency_us := P99, throughput_rps := Tput}) ->
        Healthy = SR > 0.9 andalso P99 < 2000000 andalso Tput > 0, % 2s P99 threshold
        #{phase => Phase, healthy => Healthy, success_rate => SR, p99_latency => P99}
    end, Results),
    
    HealthyPhases = length([P || #{healthy := true} <- PhaseHealth]),
    TotalPhases = length(PhaseHealth),
    
    OverallHealth = case HealthyPhases / TotalPhases of
        Ratio when Ratio >= 0.8 -> excellent;
        Ratio when Ratio >= 0.6 -> good;
        Ratio when Ratio >= 0.4 -> fair;
        _ -> poor
    end,
    
    #{
        overall_health => OverallHealth,
        phase_health => PhaseHealth,
        healthy_phases => HealthyPhases,
        total_phases => TotalPhases,
        health_ratio => HealthyPhases / TotalPhases
    }.

generate_capacity_recommendations(Results, Requirements) ->
    ExpectedUsers = maps:get(expected_users, Requirements),
    
    % Find scenarios that meet SLA
    MeetsSLA = [R || R = #{meets_sla := true} <- Results],
    
    MaxCapacity = case MeetsSLA of
        [] ->
            ?LOG_WARNING("No scenarios met SLA requirements"),
            #{max_users => 0, confidence => low};
        _ ->
            MaxUsers = lists:max([maps:get(target_users, R) || R <- MeetsSLA]),
            #{max_users => MaxUsers, confidence => high}
    end,
    
    % Calculate recommended deployment size
    SafetyMargin = 0.7, % 70% of max capacity
    RecommendedUsers = round(maps:get(max_users, MaxCapacity) * SafetyMargin),
    
    Recommendations = #{
        current_requirements => #{
            expected_users => ExpectedUsers,
            meets_requirements => RecommendedUsers >= ExpectedUsers
        },
        
        capacity_analysis => MaxCapacity,
        
        deployment_recommendation => #{
            recommended_max_users => RecommendedUsers,
            safety_margin => SafetyMargin,
            scaling_factor => case ExpectedUsers > 0 of
                true -> RecommendedUsers / ExpectedUsers;
                false -> 1.0
            end
        },
        
        infrastructure_sizing => calculate_infrastructure_needs(RecommendedUsers, Results)
    },
    
    Recommendations.

calculate_deployment_sizing(Results) ->
    % Calculate infrastructure requirements based on test results
    PeakThroughput = lists:max([maps:get(throughput_rps, R) || R <- Results]),
    AvgLatency = lists:sum([maps:get(avg_latency_us, R) || R <- Results]) / length(Results),
    
    % Rough estimates for deployment sizing
    #{
        peak_throughput_rps => PeakThroughput,
        avg_latency_us => AvgLatency,
        estimated_cpu_cores => max(2, round(PeakThroughput / 100)), % 100 req/sec per core
        estimated_memory_gb => max(1, round(PeakThroughput / 200)), % 200 req/sec per GB
        connection_pool_size => max(10, round(PeakThroughput / 10)), % 10 req/sec per connection
        load_balancer_needed => PeakThroughput > 500
    }.

calculate_infrastructure_needs(RecommendedUsers, Results) ->
    % Estimate infrastructure based on user load
    #{
        application_servers => max(1, round(RecommendedUsers / 1000)), % 1000 users per server
        database_connections => max(10, round(RecommendedUsers / 50)), % 50 users per connection
        cache_memory_gb => max(1, round(RecommendedUsers / 100)), % 100 users per GB cache
        cdn_required => RecommendedUsers > 5000,
        monitoring_critical => RecommendedUsers > 1000
    }.