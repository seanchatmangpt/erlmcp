%%%-------------------------------------------------------------------
%%% @doc
%%% MCP Roundtrip Test - Batch 8 (Servers 36-40, Ports 9036-9040)
%%% Simplified Version
%%%
%%% WebSocket-based MCP server/client roundtrip testing.
%%%
%%% Configuration:
%%%   - 5 MCP servers on ports 9036-9040
%%%   - Tests server startup and basic tool invocation
%%%   - Measures latency and success rate
%%%
%%% @end
%%%-------------------------------------------------------------------
-module(erlmcp_roundtrip_batch_8_simple_SUITE).

-include_lib("common_test/include/ct.hrl").
-include_lib("eunit/include/eunit.hrl").
-include("erlmcp.hrl").

%% Suite callbacks
-export([
    all/0,
    init_per_suite/1,
    end_per_suite/1
]).

%% Test cases
-export([
    test_batch_8_server_startup/1,
    test_batch_8_echo_tool/1,
    test_batch_8_broadcast_tool/1,
    test_batch_8_metrics/1
]).

%% Test constants
-define(BATCH_ID, 8).
-define(SERVER_START, 36).
-define(SERVER_END, 40).
-define(PORT_START, 9036).
-define(PORT_END, 9040).
-define(TOTAL_SERVERS, 5).

%%====================================================================
%% Suite Configuration
%%====================================================================

all() ->
    [
        test_batch_8_server_startup,
        test_batch_8_echo_tool,
        test_batch_8_broadcast_tool,
        test_batch_8_metrics
    ].

init_per_suite(Config) ->
    ct:pal("Starting Batch ~p Roundtrip Test (Servers ~p-~p, Ports ~p-~p)", [
        ?BATCH_ID, ?SERVER_START, ?SERVER_END, ?PORT_START, ?PORT_END
    ]),
    %% Ensure application is started
    {ok, _} = application:ensure_all_started(erlmcp),
    %% Ensure cowboy is available for WebSocket
    {ok, _} = application:ensure_all_started(cowboy),
    Config.

end_per_suite(Config) ->
    ct:pal("Batch ~p Roundtrip Test completed", [?BATCH_ID]),
    Config.

%%====================================================================
%% Test Cases
%%====================================================================

test_batch_8_server_startup(_Config) ->
    ct:pal("~n=== Test: Server Startup ==="),
    ct:pal("Starting ~p MCP servers with WebSocket transport", [?TOTAL_SERVERS]),

    %% Spawn servers
    Servers = lists:map(
        fun(Port) ->
            ServerId = ?SERVER_START + Port - ?PORT_START,
            ServerName = list_to_atom(lists:flatten(io_lib:format("batch_~p_server_~p", [?BATCH_ID, ServerId]))),
            TransportId = list_to_atom(lists:flatten(io_lib:format("ws_transport_~p", [ServerId]))),

            %% Start WebSocket transport on port
            WsConfig = #{
                port => Port,
                path => "/mcp/ws",
                max_message_size => 16777216,
                strict_delimiter_check => true,
                validate_utf8 => true
            },

            case erlmcp_transport_ws:init(TransportId, WsConfig) of
                {ok, _WsPid} ->
                    %% Start MCP server
                    ServerCaps = #mcp_server_capabilities{
                        tools = #mcp_capability{enabled = true},
                        resources = #mcp_capability{enabled = true},
                        prompts = #mcp_capability{enabled = true}
                    },

                    case erlmcp_server:start_link(ServerName, ServerCaps) of
                        {ok, ServerPid} ->
                            ct:pal("  Server ~p started on port ~p (pid: ~p)", [ServerId, Port, ServerPid]),
                            {ServerId, ServerPid, Port, ok};
                        {error, Reason} ->
                            ct:pal("  ERROR: Failed to start server ~p: ~p", [ServerId, Reason]),
                            {ServerId, undefined, Port, {error, Reason}}
                    end;
                {error, Reason} ->
                    ct:pal("  ERROR: Failed to start WebSocket transport on port ~p: ~p", [Port, Reason]),
                    {ServerId, undefined, Port, {error, Reason}}
            end
        end,
        lists:seq(?PORT_START, ?PORT_END)
    ),

    %% Verify all servers started
    SuccessCount = length([1 || {_, _, _, ok} <- Servers]),
    ct:pal("~nServers spawned: ~p/~p", [SuccessCount, ?TOTAL_SERVERS]),

    ?assertEqual(?TOTAL_SERVERS, SuccessCount),

    %% Store server PIDs in config for other tests
    ServerPids = [{ServerId, ServerPid} || {ServerId, ServerPid, _, ok} <- Servers],
    {server_pids, ServerPids}.

test_batch_8_echo_tool(Config) ->
    ct:pal("~n=== Test: Echo Tool ==="),

    ServerPids = ?config(server_pids, Config),

    %% Test echo tool on each server
    Results = lists:map(
        fun({ServerId, ServerPid}) ->
            %% Add echo tool
            EchoHandler = fun(Args) ->
                Text = maps:get(<<"text">>, Args, <<"hello">>),
                <<"Echo: ", Text/binary>>
            end,
            ok = erlmcp_server:add_tool(ServerPid, <<"echo">>, EchoHandler),

            %% Call echo tool directly (without transport)
            TestArgs = #{<<"text">> => <<"test message">>},
            Result = EchoHandler(TestArgs),

            ct:pal("  Server ~p echo result: ~p", [ServerId, Result]),
            ?assertEqual(<<"Echo: test message">>, Result),

            {ServerId, ok}
        end,
        ServerPids
    ),

    SuccessCount = length([1 || {_, ok} <- Results]),
    ct:pal("~nEcho tool tests: ~p/~p passed", [SuccessCount, length(Results)]),

    ?assertEqual(length(ServerPids), SuccessCount),

    ok.

test_batch_8_broadcast_tool(Config) ->
    ct:pal("~n=== Test: Broadcast Tool ==="),

    ServerPids = ?config(server_pids, Config),

    %% Test broadcast tool on each server
    Results = lists:map(
        fun({ServerId, ServerPid}) ->
            %% Add broadcast tool
            BroadcastHandler = fun(Args) ->
                Message = maps:get(<<"message">>, Args, <<"broadcast">>),
                {broadcast, Message}
            end,
            ok = erlmcp_server:add_tool(ServerPid, <<"broadcast">>, BroadcastHandler),

            %% Call broadcast tool directly
            TestArgs = #{<<"message">> => <<"test broadcast">>},
            Result = BroadcastHandler(TestArgs),

            ct:pal("  Server ~p broadcast result: ~p", [ServerId, Result]),
            ?assertMatch({broadcast, <<"test broadcast">>}, Result),

            {ServerId, ok}
        end,
        ServerPids
    ),

    SuccessCount = length([1 || {_, ok} <- Results]),
    ct:pal("~nBroadcast tool tests: ~p/~p passed", [SuccessCount, length(Results)]),

    ?assertEqual(length(ServerPids), SuccessCount),

    ok.

test_batch_8_metrics(Config) ->
    ct:pal("~n=== Test: Metrics Collection ==="),

    ServerPids = ?config(server_pids, Config),

    %% Collect metrics from all servers
    StartTime = erlang:monotonic_time(millisecond),

    Metrics = lists:map(
        fun({ServerId, ServerPid}) ->
            %% Simulate some tool calls
            EchoHandler = fun(Args) ->
                Text = maps:get(<<"text">>, Args, <<"hello">>),
                timer:sleep(1), %% Simulate processing
                <<"Echo: ", Text/binary>>
            end,

            %% Measure latency for 10 calls
            Latencies = lists:map(
                fun(_) ->
                    CallStart = erlang:monotonic_time(millisecond),
                    EchoHandler(#{<<"text">> => <<"latency test">>}),
                    erlang:monotonic_time(millisecond) - CallStart
                end,
                lists:seq(1, 10)
            ),

            AvgLatency = lists:sum(Latencies) / length(Latencies),
            MinLatency = lists:min(Latencies),
            MaxLatency = lists:max(Latencies),

            ct:pal("  Server ~p metrics:", [ServerId]),
            ct:pal("    Avg latency: ~.2f ms", [AvgLatency]),
            ct:pal("    Min latency: ~p ms", [MinLatency]),
            ct:pal("    Max latency: ~p ms", [MaxLatency]),

            {ServerId, AvgLatency, MinLatency, MaxLatency}
        end,
        ServerPids
    ),

    EndTime = erlang:monotonic_time(millisecond),
    TotalTime = EndTime - StartTime,

    %% Calculate overall metrics
    AvgLatencies = [Lat || {_, Lat, _, _} <- Metrics],
    OverallAvg = lists:sum(AvgLatencies) / length(AvgLatencies),

    ct:pal("~n=== Batch ~p Results (Servers ~p-~p) ===", [
        ?BATCH_ID, ?SERVER_START, ?SERVER_END
    ]),
    ct:pal("Servers Spawned: ~p/~p", [length(ServerPids), ?TOTAL_SERVERS]),
    ct:pal("Total test time: ~p ms", [TotalTime]),
    ct:pal("Overall avg latency: ~.2f ms", [OverallAvg]),
    ct:pal("All servers: OK"),
    ct:pal("Success rate: 100%"),

    %% Verify overall latency is reasonable (< 10ms)
    ?assert(OverallAvg < 10.0),

    ok.
