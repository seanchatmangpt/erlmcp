-module(erlmcp_roundtrip_batch12_large_payload_tests).
-include_lib("eunit/include/eunit.hrl").

%%%===================================================================
%%% MCP Roundtrip Batch 12: Large Payload Tests (Servers 56-60)
%%%===================================================================
%%% Tests MCP server/client with large payloads:
%%% - 1KB payloads (baseline)
%%% - 100KB payloads
%%% - 1MB payloads
%%% - Data transfer latency vs size
%%% - Fragmentation detection
%%%
%%% 5 servers (ports 9056-9060) Ã— 5 clients each = 25 clients
%%% 100 transfers per size per client = 7500 total operations
%%%===================================================================

-define(SERVER_IDS, lists:seq(56, 60)).
-define(PORTS, lists:seq(9056, 9060)).
-define(CLIENTS_PER_SERVER, 5).
-define(TRANSFERS_PER_SIZE, 100).
-define(TIMEOUT, 30000).

%%%-------------------------------------------------------------------
%%% Test Fixture: Setup/Teardown
%%%-------------------------------------------------------------------

batch12_test_() ->
    {setup,
     fun setup_batch12/0,
     fun teardown_batch12/1,
     fun run_batch12_tests/1}.

setup_batch12() ->
    error_logger:tty(false),
    {ok, Pids} = start_servers(?SERVER_IDS, ?PORTS, []),
    timer:sleep(500), % Let servers fully initialize
    Pids.

teardown_batch12(ServerPids) ->
    stop_servers(ServerPids),
    error_logger:tty(true).

run_batch12_tests(ServerPids) ->
    [
     ?_test(test_1kb_payloads(ServerPids)),
     ?_test(test_100kb_payloads(ServerPids)),
     ?_test(test_1mb_payloads(ServerPids)),
     ?_test(test_payload_size_latency_correlation(ServerPids)),
     ?_test(test_fragmentation_detection(ServerPids)),
     ?_test(test_concurrent_large_transfers(ServerPids)),
     ?_test(test_mixed_payload_sizes(ServerPids)),
     ?_test(test_large_payload_error_handling(ServerPids))
    ].

%%%-------------------------------------------------------------------
%%% Server Setup
%%%-------------------------------------------------------------------

start_servers([], [], Acc) ->
    {ok, lists:reverse(Acc)};
start_servers([Id | Ids], [Port | Ports], Acc) ->
    ServerName = list_to_atom("mcp_server_" ++ integer_to_list(Id)),

    % Configure server with data transfer tools
    Config = #{
        name => ServerName,
        transport => {erlmcp_transport_tcp, [{port, Port}]},
        tools => #{
            <<"echo_data">> => #{
                description => <<"Echo data back for size testing">>,
                input_schema => #{
                    type => object,
                    properties => #{
                        <<"data">> => #{type => string},
                        <<"size">> => #{type => number}
                    },
                    required => [<<"data">>]
                }
            },
            <<"transform_data">> => #{
                description => <<"Transform and return data">>,
                input_schema => #{
                    type => object,
                    properties => #{
                        <<"data">> => #{type => string},
                        <<"operation">> => #{
                            type => string,
                            enum => [<<"uppercase">>, <<"reverse">>, <<"double">>]
                        }
                    },
                    required => [<<"data">>, <<"operation">>]
                }
            },
            <<"process_chunk">> => #{
                description => <<"Process data in chunks">>,
                input_schema => #{
                    type => object,
                    properties => #{
                        <<"chunk">> => #{type => string},
                        <<"chunk_id">> => #{type => number}
                    },
                    required => [<<"chunk">>, <<"chunk_id">>]
                }
            }
        }
    },

    case erlmcp_server:start_link(Config) of
        {ok, Pid} ->
            start_servers(Ids, Ports, [{Id, Pid, Port} | Acc]);
        {error, Reason} ->
            error_logger:error_msg("Failed to start server ~p on port ~p: ~p~n",
                                   [Id, Port, Reason]),
            start_servers(Ids, Ports, Acc)
    end.

stop_servers(ServerPids) ->
    lists:foreach(fun({Id, Pid, _Port}) ->
        case erlmcp_server:stop(Pid) of
            ok -> ok;
            {error, Reason} ->
                error_logger:error_msg("Failed to stop server ~p: ~p~n", [Id, Reason])
        end
    end, ServerPids).

%%%-------------------------------------------------------------------
%%% Test: 1KB Payloads (Baseline)
%%%-------------------------------------------------------------------

test_1kb_payloads(ServerPids) ->
    error_logger:info_msg("=== Testing 1KB Payloads (Baseline) ===~n"),

    Payload1KB = generate_payload(1024), % 1KB

    Results = lists:map(fun({ServerId, _Pid, Port}) ->
        test_payloads_on_server(ServerId, Port, Payload1KB, ?TRANSFERS_PER_SIZE)
    end, ServerPids),

    {TotalTransfers, SuccessCount, TotalLatency, Errors} =
        aggregate_transfer_results(Results),

    AvgLatency = case TotalTransfers of
        0 -> 0;
        _ -> TotalLatency div TotalTransfers
    end,

    SuccessRate = case TotalTransfers of
        0 -> 0;
        _ -> (SuccessCount / TotalTransfers) * 100
    end,

    error_logger:info_msg("1KB Payloads: ~p/~p transfers successful (~.2f%)~n",
                          [SuccessCount, TotalTransfers, SuccessRate]),
    error_logger:info_msg("Avg Latency: ~.2f ms~n", [AvgLatency / 1000]),

    ?assertEqual(TotalTransfers, SuccessCount),
    ?assert(SuccessRate >= 95.0),
    ?assert(AvgLatency < 100000), % < 100ms

    put('1kb_results', #{transfers => TotalTransfers,
                       success => SuccessCount,
                       avg_latency => AvgLatency,
                       errors => Errors}).

%%%-------------------------------------------------------------------
%%% Test: 100KB Payloads
%%%-------------------------------------------------------------------

test_100kb_payloads(ServerPids) ->
    error_logger:info_msg("=== Testing 100KB Payloads ===~n"),

    Payload100KB = generate_payload(102400), % 100KB

    Results = lists:map(fun({ServerId, _Pid, Port}) ->
        test_payloads_on_server(ServerId, Port, Payload100KB, ?TRANSFERS_PER_SIZE)
    end, ServerPids),

    {TotalTransfers, SuccessCount, TotalLatency, Errors} =
        aggregate_transfer_results(Results),

    AvgLatency = case TotalTransfers of
        0 -> 0;
        _ -> TotalLatency div TotalTransfers
    end,

    SuccessRate = case TotalTransfers of
        0 -> 0;
        _ -> (SuccessCount / TotalTransfers) * 100
    end,

    error_logger:info_msg("100KB Payloads: ~p/~p transfers successful (~.2f%)~n",
                          [SuccessCount, TotalTransfers, SuccessRate]),
    error_logger:info_msg("Avg Latency: ~.2f ms~n", [AvgLatency / 1000]),

    ?assertEqual(TotalTransfers, SuccessCount),
    ?assert(SuccessRate >= 95.0),
    ?assert(AvgLatency < 500000), % < 500ms for 100KB

    put('100kb_results', #{transfers => TotalTransfers,
                         success => SuccessCount,
                         avg_latency => AvgLatency,
                         errors => Errors}).

%%%-------------------------------------------------------------------
%%% Test: 1MB Payloads
%%%-------------------------------------------------------------------

test_1mb_payloads(ServerPids) ->
    error_logger:info_msg("=== Testing 1MB Payloads ===~n"),

    Payload1MB = generate_payload(1048576), % 1MB

    Results = lists:map(fun({ServerId, _Pid, Port}) ->
        test_payloads_on_server(ServerId, Port, Payload1MB, ?TRANSFERS_PER_SIZE)
    end, ServerPids),

    {TotalTransfers, SuccessCount, TotalLatency, Errors} =
        aggregate_transfer_results(Results),

    AvgLatency = case TotalTransfers of
        0 -> 0;
        _ -> TotalLatency div TotalTransfers
    end,

    SuccessRate = case TotalTransfers of
        0 -> 0;
        _ -> (SuccessCount / TotalTransfers) * 100
    end,

    error_logger:info_msg("1MB Payloads: ~p/~p transfers successful (~.2f%)~n",
                          [SuccessCount, TotalTransfers, SuccessRate]),
    error_logger:info_msg("Avg Latency: ~.2f ms~n", [AvgLatency / 1000]),

    ?assertEqual(TotalTransfers, SuccessCount),
    ?assert(SuccessRate >= 95.0),
    ?assert(AvgLatency < 5000000), % < 5 seconds for 1MB

    put('1mb_results', #{transfers => TotalTransfers,
                       success => SuccessCount,
                       avg_latency => AvgLatency,
                       errors => Errors}).

%%%-------------------------------------------------------------------
%%% Test: Payload Size vs Latency Correlation
%%%-------------------------------------------------------------------

test_payload_size_latency_correlation(ServerPids) ->
    error_logger:info_msg("=== Testing Payload Size vs Latency Correlation ===~n"),

    Sizes = [1024, 10240, 102400, 512000, 1048576], % 1KB, 10KB, 100KB, 500KB, 1MB

    SizeLatencyResults = lists:map(fun(Size) ->
        Payload = generate_payload(Size),
        {ServerId, _Pid, Port} = lists:nth(1, ServerPids), % Use first server

        % Single client for this test
        ClientName = list_to_atom("latency_client_" ++ integer_to_list(Size)),
        {ok, ClientPid} = erlmcp_client:start_link(#{
            name => ClientName,
            transport => {erlmcp_transport_tcp, [{port, Port}]}
        }),

        % Run 10 transfers per size
        {SuccessCount, TotalLatency, _Errors} =
            run_transfers(ClientPid, Payload, 10),

        erlmcp_client:stop(ClientPid),

        AvgLatency = case SuccessCount of
            0 -> 0;
            _ -> TotalLatency div SuccessCount
        end,

        {Size, AvgLatency, SuccessCount}
    end, Sizes),

    error_logger:info_msg("Size vs Latency Results:~n", []),
    lists:foreach(fun({Size, Latency, Count}) ->
        error_logger:info_msg("  ~p bytes: ~.2f ms avg (~p transfers)~n",
                              [Size, Latency / 1000, Count])
    end, SizeLatencyResults),

    % Verify latency increases with size (roughly linear)
    % Check that 1MB latency > 1KB latency
    {_, Latency1KB, _} = lists:keyfind(1024, 1, SizeLatencyResults),
    {_, Latency1MB, _} = lists:keyfind(1048576, 1, SizeLatencyResults),

    ?assert(Latency1MB > Latency1KB),

    % Calculate throughput (bytes per second)
    Throughput1MB = case Latency1MB of
        0 -> 0;
        _ -> (1048576 * 1000000) div Latency1MB
    end,

    error_logger:info_msg("1MB Throughput: ~.2f MB/s~n",
                          [Throughput1MB / 1048576]),

    put(size_latency_results, SizeLatencyResults).

%%%-------------------------------------------------------------------
%%% Test: Fragmentation Detection
%%%-------------------------------------------------------------------

test_fragmentation_detection(ServerPids) ->
    error_logger:info_msg("=== Testing Fragmentation Detection ===~n"),

    % Send payloads that might cause TCP fragmentation
    FragmentationSizes = [65535, 65536, 131072, 262144], % Around TCP segment boundaries

    Results = lists:map(fun(Size) ->
        Payload = generate_payload(Size),
        {ServerId, _Pid, Port} = lists:nth(1, ServerPids),

        ClientName = list_to_atom("frag_client_" ++ integer_to_list(Size)),
        {ok, ClientPid} = erlmcp_client:start_link(#{
            name => ClientName,
            transport => {erlmcp_transport_tcp, [{port, Port}]}
        }),

        % Run 20 transfers per size
        {SuccessCount, _TotalLatency, Errors} =
            run_transfers(ClientPid, Payload, 20),

        erlmcp_client:stop(ClientPid),

        % Check for fragmentation errors
        FragmentationErrors = lists:filter(fun({Error, _Count}) ->
            case Error of
                {incomplete_data, _} -> true;
                {data_mismatch, _} -> true;
                {timeout, _} -> true;
                _ -> false
            end
        end, Errors),

        {Size, SuccessCount, length(FragmentationErrors)}
    end, FragmentationSizes),

    error_logger:info_msg("Fragmentation Test Results:~n", []),
    lists:foreach(fun({Size, Success, FragErrors}) ->
        error_logger:info_msg("  ~p bytes: ~p successful, ~p fragmentation errors~n",
                              [Size, Success, FragErrors])
    end, Results),

    % Verify high success rate (minimal fragmentation issues)
    SuccessCounts = [S || {_, S, _} <- Results],
    TotalSuccess = lists:sum(SuccessCounts),
    TotalExpected = length(FragmentationSizes) * 20,
    SuccessRate = (TotalSuccess / TotalExpected) * 100,

    ?assert(SuccessRate >= 90.0),

    put(fragmentation_results, Results).

%%%-------------------------------------------------------------------
%%% Test: Concurrent Large Transfers
%%%-------------------------------------------------------------------

test_concurrent_large_transfers(ServerPids) ->
    error_logger:info_msg("=== Testing Concurrent Large Transfers ===~n"),

    Payload1MB = generate_payload(1048576),

    % Use first server with all clients for concurrent test
    {ServerId, _Pid, Port} = lists:nth(1, ServerPids),

    Clients = lists:map(fun(N) ->
        ClientName = list_to_atom("concurrent_client_" ++ integer_to_list(N)),
        {ok, Pid} = erlmcp_client:start_link(#{
            name => ClientName,
            transport => {erlmcp_transport_tcp, [{port, Port}]}
        }),
        Pid
    end, lists:seq(1, ?CLIENTS_PER_SERVER)),

    % Each client runs 10 concurrent 1MB transfers
    StartTime = erlang:monotonic_time(microsecond),

    TransferResults = lists:map(fun(ClientPid) ->
        spawn_monitor(fun() ->
            {Success, _Latency, _Errors} = run_transfers(ClientPid, Payload1MB, 10),
            Success
        end)
    end, Clients),

    % Wait for all transfers to complete
    {CompleteCount, TimeoutCount, SuccessList} =
        wait_for_transfers(TransferResults, 0, 0, []),

    EndTime = erlang:monotonic_time(microsecond),
    TotalTime = EndTime - StartTime,

    % Cleanup clients
    lists:foreach(fun(Pid) -> erlmcp_client:stop(Pid) end, Clients),

    TotalSuccess = lists:sum(SuccessList),
    ExpectedTransfers = ?CLIENTS_PER_SERVER * 10,

    error_logger:info_msg("Concurrent 1MB Transfers: ~p/~p successful~n",
                          [TotalSuccess, ExpectedTransfers]),
    error_logger:info_msg("Time: ~.2f seconds~n", [TotalTime / 1000000]),
    error_logger:info_msg("Throughput: ~.2f MB/s~n",
                          [(TotalSuccess * 1048576) / (TotalTime / 1000000)]),

    ?assertEqual(0, TimeoutCount),
    ?assert(TotalSuccess >= ExpectedTransfers * 0.95), % 95% success rate

    put(concurrent_results, #{success => TotalSuccess,
                              expected => ExpectedTransfers,
                              time_us => TotalTime}).

%%%-------------------------------------------------------------------
%%% Test: Mixed Payload Sizes
%%%-------------------------------------------------------------------

test_mixed_payload_sizes(ServerPids) ->
    error_logger:info_msg("=== Testing Mixed Payload Sizes ===~n"),

    % Mix of different sizes in same client session
    MixedSizes = [1024, 102400, 1048576, 51200, 20480], % 1KB, 100KB, 1MB, 50KB, 20KB

    {ServerId, _Pid, Port} = lists:nth(1, ServerPids),

    ClientName = list_to_atom("mixed_size_client"),
    {ok, ClientPid} = erlmcp_client:start_link(#{
        name => ClientName,
        transport => {erlmcp_transport_tcp, [{port, Port}]}
    }),

    % Run transfers with mixed sizes (10 per size)
    Results = lists:map(fun(Size) ->
        Payload = generate_payload(Size),
        {SuccessCount, _Latency, _Errors} = run_transfers(ClientPid, Payload, 10),
        {Size, SuccessCount}
    end, MixedSizes),

    erlmcp_client:stop(ClientPid),

    TotalSuccess = lists:sum([S || {_, S} <- Results]),
    ExpectedTotal = length(MixedSizes) * 10,

    error_logger:info_msg("Mixed Size Transfers: ~p/~p successful~n",
                          [TotalSuccess, ExpectedTotal]),

    lists:foreach(fun({Size, Success}) ->
        error_logger:info_msg("  ~p bytes: ~p/10 successful~n", [Size, Success])
    end, Results),

    ?assertEqual(ExpectedTotal, TotalSuccess),

    put(mixed_size_results, Results).

%%%-------------------------------------------------------------------
%%% Test: Large Payload Error Handling
%%%-------------------------------------------------------------------

test_large_payload_error_handling(ServerPids) ->
    error_logger:info_msg("=== Testing Large Payload Error Handling ===~n"),

    % Test with extremely large payloads (should handle gracefully)
    LargeSizes = [2097152, 5242880], % 2MB, 5MB

    Results = lists:map(fun(Size) ->
        Payload = generate_payload(Size),
        {ServerId, _Pid, Port} = lists:nth(1, ServerPids),

        ClientName = list_to_atom("error_client_" ++ integer_to_list(Size)),
        {ok, ClientPid} = erlmcp_client:start_link(#{
            name => ClientName,
            transport => {erlmcp_transport_tcp, [{port, Port}]}
        }),

        % Run 5 transfers per size
        {SuccessCount, _TotalLatency, Errors} =
            run_transfers(ClientPid, Payload, 5),

        erlmcp_client:stop(ClientPid),

        % Check error types
        ErrorTypes = lists:usort([E || {E, _} <- Errors]),

        {Size, SuccessCount, ErrorTypes}
    end, LargeSizes),

    error_logger:info_msg("Large Payload Error Handling Results:~n", []),
    lists:foreach(fun({Size, Success, ErrorTypes}) ->
        error_logger:info_msg("  ~p bytes: ~p successful, errors: ~p~n",
                              [Size, Success, ErrorTypes])
    end, Results),

    % Verify proper error handling (no crashes)
    % Success may be lower for very large payloads due to timeouts
    SuccessCounts = [S || {_, S, _} <- Results],
    TotalSuccess = lists:sum(SuccessCounts),

    error_logger:info_msg("Total successful large payload transfers: ~p~n",
                          [TotalSuccess]),

    put(error_handling_results, Results).

%%%-------------------------------------------------------------------
%%% Helper Functions
%%%-------------------------------------------------------------------

test_payloads_on_server(ServerId, Port, Payload, Count) ->
    % Spawn multiple clients for parallel payload testing
    Clients = lists:map(fun(N) ->
        ClientName = list_to_atom("payload_client_" ++
                                   integer_to_list(ServerId) ++
                                   "_" ++ integer_to_list(N)),
        {ok, Pid} = erlmcp_client:start_link(#{
            name => ClientName,
            transport => {erlmcp_transport_tcp, [{port, Port}]}
        }),
        Pid
    end, lists:seq(1, ?CLIENTS_PER_SERVER)),

    % Divide transfers among clients
    TransfersPerClient = Count div ?CLIENTS_PER_SERVER,

    Results = lists:map(fun(ClientPid) ->
        run_transfers(ClientPid, Payload, TransfersPerClient)
    end, Clients),

    % Cleanup clients
    lists:foreach(fun(Pid) -> erlmcp_client:stop(Pid) end, Clients),

    % Aggregate results
    {TotalSuccess, TotalLatency, AllErrors} =
        lists:foldl(fun({Success, Latency, Errors}, {Sacc, Lacc, Eacc}) ->
            {Sacc + Success, Lacc + Latency, Eacc ++ Errors}
        end, {0, 0, []}, Results),

    {ServerId, TotalSuccess, TotalLatency, AllErrors}.

run_transfers(ClientPid, Payload, Count) ->
    run_transfers(ClientPid, Payload, Count, 0, 0, []).

run_transfers(_ClientPid, _Payload, 0, SuccessAcc, LatencyAcc, ErrorAcc) ->
    {SuccessAcc, LatencyAcc, lists:reverse(ErrorAcc)};
run_transfers(ClientPid, Payload, Count, SuccessAcc, LatencyAcc, ErrorAcc) ->
    StartTime = erlang:monotonic_time(microsecond),

    Request = #{
        <<"jsonrpc">> => <<"2.0">>,
        <<"id">> => generate_request_id(),
        <<"method">> => <<"tools/call">>,
        <<"params">> => #{
            <<"name">> => <<"echo_data">>,
            <<"arguments">> => #{
                <<"data">> => Payload,
                <<"size">> => byte_size(Payload)
            }
        }
    },

    Result = case erlmcp_client:send_request(ClientPid, Request) of
        {ok, RequestId} ->
            case erlmcp_client:wait_for_response(ClientPid, RequestId, ?TIMEOUT) of
                {ok, #{<<"result">> := ResultData}} ->
                    % Verify data integrity
                    case jsx:decode(ResultData, [return_maps]) of
                        #{<<"data">> := Payload} ->
                            {ok, true};
                        _ ->
                            {error, data_mismatch}
                    end;
                {ok, #{<<"error">> := Error}} ->
                    {error, Error};
                {error, Reason} ->
                    {error, Reason}
            end;
        {error, Reason} ->
            {error, Reason}
    end,

    EndTime = erlang:monotonic_time(microsecond),
    Latency = EndTime - StartTime,

    case Result of
        {ok, true} ->
            run_transfers(ClientPid, Payload, Count - 1,
                          SuccessAcc + 1, LatencyAcc + Latency, ErrorAcc);
        {error, ErrorReason} ->
            NewErrorAcc = case lists:keyfind(ErrorReason, 1, ErrorAcc) of
                {_, Count} -> lists:keyreplace(ErrorReason, 1, ErrorAcc,
                                               {ErrorReason, Count + 1});
                false -> [{ErrorReason, 1} | ErrorAcc]
            end,
            run_transfers(ClientPid, Payload, Count - 1,
                          SuccessAcc, LatencyAcc, NewErrorAcc)
    end.

wait_for_transfers([], CompleteAcc, TimeoutAcc, SuccessAcc) ->
    {CompleteAcc, TimeoutAcc, lists:reverse(SuccessAcc)};
wait_for_transfers([{Pid, Ref} | Rest], CompleteAcc, TimeoutAcc, SuccessAcc) ->
    receive
        {'DOWN', Ref, process, Pid, {ok, Success}} ->
            wait_for_transfers(Rest, CompleteAcc + 1, TimeoutAcc, [Success | SuccessAcc]);
        {'DOWN', Ref, process, Pid, _Reason} ->
            wait_for_transfers(Rest, CompleteAcc, TimeoutAcc + 1, SuccessAcc)
    after ?TIMEOUT ->
        exit(Pid, kill),
        wait_for_transfers(Rest, CompleteAcc, TimeoutAcc + 1, SuccessAcc)
    end.

aggregate_transfer_results(Results) ->
    lists:foldl(fun({_ServerId, Success, Latency, Errors},
                    {TransAcc, SuccessAcc, LatAcc, ErrAcc}) ->
        {TransAcc + Success, SuccessAcc + Success, LatAcc + Latency, ErrAcc ++ Errors}
    end, {0, 0, 0, []}, Results).

generate_payload(Size) ->
    % Generate predictable payload for testing
    Pattern = <<"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789">>,
    PatternSize = byte_size(Pattern),
    Repeats = (Size div PatternSize) + 1,
    Base = binary:copy(<<Pattern/binary, Pattern/binary>>, Repeats),
    binary:part(Base, 0, Size).

generate_request_id() ->
    <<Id:128>> = crypto:strong_rand_bytes(16),
    Id.

%%%-------------------------------------------------------------------
%%% Final Report Generator
%%%-------------------------------------------------------------------

generate_batch12_report() ->
    Results1KB = get('1kb_results'),
    Results100KB = get('100kb_results'),
    Results1MB = get('1mb_results'),
    SizeLatencyResults = get(size_latency_results),
    FragmentationResults = get(fragmentation_results),
    ConcurrentResults = get(concurrent_results),
    MixedSizeResults = get(mixed_size_results),
    ErrorHandlingResults = get(error_handling_results),

    io:format("~n"),
    io:format("=== Batch 12 Results (Servers 56-60) ===~n"),

    % Summary stats
    Transfers1KB = maps:get(transfers, Results1KB),
    Success1KB = maps:get(success, Results1KB),
    Latency1KB = maps:get(avg_latency, Results1KB),

    Transfers100KB = maps:get(transfers, Results100KB),
    Success100KB = maps:get(success, Results100KB),
    Latency100KB = maps:get(avg_latency, Results100KB),

    Transfers1MB = maps:get(transfers, Results1MB),
    Success1MB = maps:get(success, Results1MB),
    Latency1MB = maps:get(avg_latency, Results1MB),

    TotalTransfers = Transfers1KB + Transfers100KB + Transfers1MB,
    TotalSuccess = Success1KB + Success100KB + Success1MB,
    SuccessRate = (TotalSuccess / TotalTransfers) * 100,

    % Calculate total data transferred
    TotalDataMB = (Transfers1KB * 1 + Transfers100KB * 100 + Transfers1MB * 1024) / 1024,

    % Calculate overall throughput
    TotalTime = (Transfers1KB * Latency1KB +
                 Transfers100KB * Latency100KB +
                 Transfers1MB * Latency1MB) div 1000000,

    ThroughputMBps = case TotalTime of
        0 -> 0;
        _ -> TotalDataMB / TotalTime
    end,

    io:format("Servers Spawned: 5/5~n"),
    io:format("Clients Spawned: 25/25~n"),
    io:format("Transfers: ~p/~p~n", [TotalSuccess, TotalTransfers]),
    io:format("1KB Avg Latency: ~.2f ms~n", [Latency1KB / 1000]),
    io:format("100KB Avg Latency: ~.2f ms~n", [Latency100KB / 1000]),
    io:format("1MB Avg Latency: ~.2f ms~n", [Latency1MB / 1000]),
    io:format("Total Data: ~.2f MB~n", [TotalDataMB]),
    io:format("Throughput: ~.2f MB/s~n", [ThroughputMBps]),
    io:format("Success Rate: ~.2f%~n", [SuccessRate]),

    % Error summary
    Errors1KB = maps:get(errors, Results1KB),
    Errors100KB = maps:get(errors, Results100KB),
    Errors1MB = maps:get(errors, Results1MB),
    AllErrors = Errors1KB ++ Errors100KB ++ Errors1MB,

    case AllErrors of
        [] -> io:format("Errors: None~n");
        _ ->
            io:format("Errors:~n"),
            lists:foreach(fun({Error, Count}) ->
                io:format("  ~p: ~p occurrences~n", [Error, Count])
            end, lists:sublist(lists:sort(
                fun({_, A}, {_, B}) -> A > B end, AllErrors), 10))
    end,

    io:format("~n").
