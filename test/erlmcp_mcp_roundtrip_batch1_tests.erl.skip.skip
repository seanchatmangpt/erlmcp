-module(erlmcp_mcp_roundtrip_batch1_tests).
-include_lib("eunit/include/eunit.hrl").
-include_lib("erlmcp_core/include/erlmcp.hrl").

%%====================================================================
%% Chicago School TDD - MCP Roundtrip Integration Tests (Batch 1)
%% Real servers, real clients, real TCP connections, state-based verification
%% Tests: 5 servers (ports 9001-9005), 5 clients per server, 100 ops per client
%% Total: 25 clients, 2500 operations
%%====================================================================

%%====================================================================
%% Test Configuration
%%====================================================================

-define(BATCH_ID, 1).
-define(SERVER_COUNT, 5).
-define(CLIENTS_PER_SERVER, 5).
-define(OPERATIONS_PER_CLIENT, 100).
-define(TOTAL_CLIENTS, ?SERVER_COUNT * ?CLIENTS_PER_SERVER).
-define(TOTAL_OPERATIONS, ?TOTAL_CLIENTS * ?OPERATIONS_PER_CLIENT).
-define(BASE_PORT, 9001).
-define(TIMEOUT, 10000).

%%====================================================================
%% Main Test Suite - Batch 1 Roundtrip
%%====================================================================

mcp_roundtrip_batch1_test_() ->
    {setup,
     fun setup_batch1/0,
     fun cleanup_batch1/1,
     fun(_Ctx) ->
         [
          ?_test(test_spawn_servers()),
          ?_test(test_spawn_clients()),
          ?_test(test_tool_operations()),
          ?_test(test_resource_operations()),
          ?_test(test_prompt_operations()),
          ?_test(test_roundtrip_latency()),
          ?_test(test_concurrent_operations()),
          ?_test(test_server_cleanup())
         ]
     end}.

%%====================================================================
%% Setup and Cleanup - Chicago School: Real Application Startup
%%====================================================================

setup_batch1() ->
    %% Start real application with all dependencies
    application:ensure_all_started(gproc),
    application:ensure_all_started(erlmcp_core),
    application:ensure_all_started(erlmcp_transports),

    %% Create server configuration context
    #{
        batch_id => ?BATCH_ID,
        base_port => ?BASE_PORT,
        servers => [],
        clients => [],
        results => #{latencies => [], errors => [], operations => 0}
    }.

cleanup_batch1(#{servers := Servers, clients := Clients}) ->
    %% Cleanup all clients first (reverse dependency order)
    lists:foreach(
        fun(#{pid := Pid}) ->
            case is_process_alive(Pid) of
                true -> erlmcp_client:stop(Pid);
                false -> ok
            end
        end,
        Clients
    ),

    %% Cleanup all servers
    lists:foreach(
        fun(#{pid := Pid}) ->
            case is_process_alive(Pid) of
                true -> erlmcp_server:stop(Pid);
                false -> ok
            end
        end,
        Servers
    ),

    %% Allow graceful shutdown
    timer:sleep(200),

    %% Stop applications
    application:stop(erlmcp_transports),
    application:stop(erlmcp_core),
    application:stop(gproc),

    ok.

%%====================================================================
%% Test Case 1: Spawn 5 Servers (Chicago School: Real gen_servers)
%%====================================================================

test_spawn_servers() ->
    ServersSpawned = spawn_servers(?BASE_PORT, ?SERVER_COUNT, []),

    %% Verify: All servers spawned successfully (state-based)
    ?assertEqual(?SERVER_COUNT, length(ServersSpawned)),

    %% Verify: All server PIDs are alive (observable behavior)
    AliveServers = lists:filter(
        fun(#{pid := Pid}) -> is_process_alive(Pid) end,
        ServersSpawned
    ),
    ?assertEqual(?SERVER_COUNT, length(AliveServers)),

    %% Verify: Each server has unique port (no conflicts)
    Ports = [Port || #{port := Port} <- ServersSpawned],
    UniquePorts = lists:usort(Ports),
    ?assertEqual(?SERVER_COUNT, length(UniquePorts)),

    %% Store servers in process dictionary for subsequent tests
    put(servers, ServersSpawned),

    io:format("~n=== Batch ~p: Servers Spawned ===~n", [?BATCH_ID]),
    lists:foreach(
        fun(#{server_id := Id, port := Port}) ->
            io:format("  Server ~p on port ~p~n", [Id, Port])
        end,
        ServersSpawned
    ).

spawn_servers(_Port, 0, Acc) ->
    lists:reverse(Acc);
spawn_servers(Port, Count, Acc) ->
    ServerId = list_to_atom("mcp_server_" ++ integer_to_list(Port)),

    %% Create server capabilities
    Capabilities = #mcp_server_capabilities{
        resources = #mcp_capability{enabled = true},
        tools = #mcp_capability{enabled = true},
        prompts = #mcp_capability{enabled = true}
    },

    %% Spawn real server (Chicago School: no mocks)
    case erlmcp_server:start_link(ServerId, Capabilities) of
        {ok, ServerPid} ->
            %% Add calculator tools
            add_calculator_tools(ServerPid),

            %% Add file resources
            add_file_resources(ServerPid),

            %% Add hello prompt
            add_hello_prompt(ServerPid),

            ServerInfo = #{
                server_id => ServerId,
                pid => ServerPid,
                port => Port,
                transport => tcp
            },
            spawn_servers(Port + 1, Count - 1, [ServerInfo | Acc]);
        {error, Reason} ->
            io:format("  Failed to spawn server on port ~p: ~p~n", [Port, Reason]),
            spawn_servers(Port + 1, Count - 1, Acc)
    end.

%%====================================================================
%% Test Case 2: Spawn 25 Clients (5 per server)
%%====================================================================

test_spawn_clients() ->
    Servers = get(servers),
    AllClients = spawn_clients_for_servers(Servers, ?CLIENTS_PER_SERVER, []),

    %% Verify: All clients spawned successfully
    ExpectedClients = ?TOTAL_CLIENTS,
    ?assertEqual(ExpectedClients, length(AllClients)),

    %% Verify: All client PIDs are alive
    AliveClients = lists:filter(
        fun(#{pid := Pid}) -> is_process_alive(Pid) end,
        AllClients
    ),
    ?assertEqual(ExpectedClients, length(AliveClients)),

    %% Store clients for subsequent tests
    put(clients, AllClients),

    io:format("~n=== Batch ~p: Clients Spawned ===~n", [?BATCH_ID]),
    io:format("  Total clients: ~p~n", [length(AllClients)]),
    lists:foreach(
        fun(#{server_id := ServerId, client_id := ClientId}) ->
            io:format("  Client ~p connected to ~p~n", [ClientId, ServerId])
        end,
        lists:sublist(AllClients, 5)  %% Show first 5 as sample
    ),
    io:format("  ... (~p more clients)~n", [length(AllClients) - 5]).

spawn_clients_for_servers([], _Count, Acc) ->
    lists:reverse(Acc);
spawn_clients_for_servers([#{server_id := ServerId, port := Port} = Server | Rest], Count, Acc) ->
    ServerClients = spawn_clients_for_server(Server, Count, []),
    spawn_clients_for_servers(Rest, Count, ServerClients ++ Acc).

spawn_clients_for_server(_Server, 0, Acc) ->
    lists:reverse(Acc);
spawn_clients_for_server(#{server_id := ServerId, port := Port} = Server, Count, Acc) ->
    ClientId = list_to_atom(
        "mcp_client_" ++ integer_to_list(Port) ++ "_" ++ integer_to_list(Count)
    ),

    %% Create client with TCP transport (real connection)
    TransportOpts = {tcp, #{
        host => "localhost",
        port => Port,
        timeout => 5000
    }},

    case erlmcp_client:start_link(TransportOpts) of
        {ok, ClientPid} ->
            %% Initialize client
            ClientCapabilities = #mcp_client_capabilities{
                roots = #mcp_capability{enabled = false},
                sampling = #mcp_capability{enabled = false}
            },
            case erlmcp_client:initialize(ClientPid, ClientCapabilities) of
                {ok, _ServerInfo} ->
                    ClientInfo = #{
                        client_id => ClientId,
                        pid => ClientPid,
                        server_id => ServerId,
                        port => Port,
                        transport => tcp
                    },
                    spawn_clients_for_server(Server, Count - 1, [ClientInfo | Acc]);
                {error, InitReason} ->
                    %% Client spawned but initialization failed
                    erlmcp_client:stop(ClientPid),
                    spawn_clients_for_server(Server, Count - 1, Acc)
            end;
        {error, Reason} ->
            io:format("  Failed to spawn client ~p: ~p~n", [ClientId, Reason]),
            spawn_clients_for_server(Server, Count - 1, Acc)
    end.

%%====================================================================
%% Test Case 3: Tool Operations (add, subtract, multiply)
%%====================================================================

test_tool_operations() ->
    Clients = get(clients),
    {SuccessCount, FailCount, Latencies} = run_tool_operations(Clients, ?OPERATIONS_PER_CLIENT),

    %% Verify: All operations attempted
    TotalOps = SuccessCount + FailCount,
    ExpectedOps = ?TOTAL_CLIENTS * ?OPERATIONS_PER_CLIENT,
    ?assertEqual(ExpectedOps, TotalOps),

    %% Verify: High success rate (allow 5% failure for network issues)
    SuccessRate = (SuccessCount / TotalOps) * 100,
    ?assert(SuccessRate >= 95.0),

    %% Verify: Reasonable latency (99th percentile < 1 second)
    SortedLatencies = lists:sort(Latencies),
    P99Index = min(length(SortedLatencies), max(1, trunc(length(SortedLatencies) * 0.99))),
    P99Latency = lists:nth(P99Index, SortedLatencies),
    ?assert(P99Latency < 1000000),  %% < 1 second in microseconds

    put(tool_latencies, Latencies),
    put(tool_success_count, SuccessCount),

    io:format("~n=== Batch ~p: Tool Operations ===~n", [?BATCH_ID]),
    io:format("  Total operations: ~p~n", [TotalOps]),
    io:format("  Successful: ~p (~.2f%)~n", [SuccessCount, SuccessRate]),
    io:format("  Failed: ~p~n", [FailCount]),
    print_latency_stats(Latencies).

run_tool_operations(Clients, OpsPerClient) ->
    run_tool_operations(Clients, OpsPerClient, 0, 0, []).

run_tool_operations([], _OpsPerClient, SuccessAcc, FailAcc, LatencyAcc) ->
    {SuccessAcc, FailAcc, lists:reverse(LatencyAcc)};
run_tool_operations([#{pid := ClientPid} = Client | Rest], OpsPerClient, SuccessAcc, FailAcc, LatencyAcc) ->
    {Success, Fail, Latencies} = run_client_tool_ops(ClientPid, OpsPerClient, [], []),
    run_tool_operations(
        Rest,
        OpsPerClient,
        SuccessAcc + Success,
        FailAcc + Fail,
        Latencies ++ LatencyAcc
    ).

run_client_tool_ops(_ClientPid, 0, SuccessAcc, FailAcc) ->
    {SuccessAcc, FailAcc, lists:reverse(SuccessAcc ++ FailAcc)};
run_client_tool_ops(ClientPid, Count, SuccessAcc, FailAcc) ->
    %% Test different operations
    Operations = [
        {<<"calculator_add">>, #{a => rand:uniform(100), b => rand:uniform(100)}},
        {<<"calculator_subtract">>, #{a => rand:uniform(100), b => rand:uniform(100)}},
        {<<"calculator_multiply">>, #{a => rand:uniform(10), b => rand:uniform(10)}}
    ],

    {ToolName, Args} = lists:nth(rand:uniform(length(Operations)), Operations),

    %% Measure latency
    StartTime = erlang:monotonic_time(microsecond),
    Result = erlmcp_client:call_tool(ClientPid, ToolName, Args),
    EndTime = erlang:monotonic_time(microsecond),
    Latency = EndTime - StartTime,

    case Result of
        {ok, _ToolResult} ->
            run_client_tool_ops(ClientPid, Count - 1, [Latency | SuccessAcc], FailAcc);
        {error, Reason} ->
            run_client_tool_ops(ClientPid, Count - 1, SuccessAcc, [Reason | FailAcc])
    end.

%%====================================================================
%% Test Case 4: Resource Operations
%%====================================================================

test_resource_operations() ->
    Clients = get(clients),
    {SuccessCount, FailCount} = run_resource_operations(Clients, 20),  %% 20 ops per client

    %% Verify: All resource operations attempted
    TotalOps = SuccessCount + FailCount,
    ExpectedOps = ?TOTAL_CLIENTS * 20,
    ?assertEqual(ExpectedOps, TotalOps),

    %% Verify: High success rate
    SuccessRate = (SuccessCount / TotalOps) * 100,
    ?assert(SuccessRate >= 95.0),

    put(resource_success_count, SuccessCount),

    io:format("~n=== Batch ~p: Resource Operations ===~n", [?BATCH_ID]),
    io:format("  Total operations: ~p~n", [TotalOps]),
    io:format("  Successful: ~p (~.2f%)~n", [SuccessCount, SuccessRate]),
    io:format("  Failed: ~p~n", [FailCount]).

run_resource_operations(Clients, OpsPerClient) ->
    run_resource_operations(Clients, OpsPerClient, 0, 0).

run_resource_operations([], _OpsPerClient, SuccessAcc, FailAcc) ->
    {SuccessAcc, FailAcc};
run_resource_operations([#{pid := ClientPid} | Rest], OpsPerClient, SuccessAcc, FailAcc) ->
    {Success, Fail} = run_client_resource_ops(ClientPid, OpsPerClient, 0, 0),
    run_resource_operations(Rest, OpsPerClient, SuccessAcc + Success, FailAcc + Fail).

run_client_resource_ops(_ClientPid, 0, SuccessAcc, FailAcc) ->
    {SuccessAcc, FailAcc};
run_client_resource_ops(ClientPid, Count, SuccessAcc, FailAcc) ->
    %% Test list and read resources
    StartTime = erlang:monotonic_time(microsecond),

    Result = case rand:uniform(2) of
        1 -> erlmcp_client:list_resources(ClientPid);
        2 -> erlmcp_client:read_resource(ClientPid, <<"file://test.txt">>)
    end,

    case Result of
        {ok, _} ->
            run_client_resource_ops(ClientPid, Count - 1, SuccessAcc + 1, FailAcc);
        {error, _} ->
            run_client_resource_ops(ClientPid, Count - 1, SuccessAcc, FailAcc + 1)
    end.

%%====================================================================
%% Test Case 5: Prompt Operations
%%====================================================================

test_prompt_operations() ->
    Clients = get(clients),
    {SuccessCount, FailCount} = run_prompt_operations(Clients, 10),  %% 10 ops per client

    %% Verify: All prompt operations attempted
    TotalOps = SuccessCount + FailCount,
    ExpectedOps = ?TOTAL_CLIENTS * 10,
    ?assertEqual(ExpectedOps, TotalOps),

    %% Verify: High success rate
    SuccessRate = (SuccessCount / TotalOps) * 100,
    ?assert(SuccessRate >= 95.0),

    put(prompt_success_count, SuccessCount),

    io:format("~n=== Batch ~p: Prompt Operations ===~n", [?BATCH_ID]),
    io:format("  Total operations: ~p~n", [TotalOps]),
    io:format("  Successful: ~p (~.2f%)~n", [SuccessCount, SuccessRate]),
    io:format("  Failed: ~p~n", [FailCount]).

run_prompt_operations(Clients, OpsPerClient) ->
    run_prompt_operations(Clients, OpsPerClient, 0, 0).

run_prompt_operations([], _OpsPerClient, SuccessAcc, FailAcc) ->
    {SuccessAcc, FailAcc};
run_prompt_operations([#{pid := ClientPid} | Rest], OpsPerClient, SuccessAcc, FailAcc) ->
    {Success, Fail} = run_client_prompt_ops(ClientPid, OpsPerClient, 0, 0),
    run_prompt_operations(Rest, OpsPerClient, SuccessAcc + Success, FailAcc + Fail).

run_client_prompt_ops(_ClientPid, 0, SuccessAcc, FailAcc) ->
    {SuccessAcc, FailAcc};
run_client_prompt_ops(ClientPid, Count, SuccessAcc, FailAcc) ->
    %% Test list and get prompts
    Result = case rand:uniform(2) of
        1 -> erlmcp_client:list_prompts(ClientPid);
        2 -> erlmcp_client:get_prompt(ClientPid, <<"hello">>, #{name => <<"World">>})
    end,

    case Result of
        {ok, _} ->
            run_client_prompt_ops(ClientPid, Count - 1, SuccessAcc + 1, FailAcc);
        {error, _} ->
            run_client_prompt_ops(ClientPid, Count - 1, SuccessAcc, FailAcc + 1)
    end.

%%====================================================================
%% Test Case 6: Roundtrip Latency Analysis
%%====================================================================

test_roundtrip_latency() ->
    ToolLatencies = get(tool_latencies),
    SuccessCount = get(tool_success_count),
    TotalOps = length(ToolLatencies),

    %% Verify: Latency metrics are reasonable
    AvgLatency = calculate_average(ToolLatencies),
    MinLatency = lists:min(ToolLatencies),
    MaxLatency = lists:max(ToolLatencies),

    %% Verify: Average latency < 100ms (reasonable for localhost TCP)
    ?assert(AvgLatency < 100000),  %% < 100ms in microseconds

    %% Verify: No extreme outliers (max < 1 second)
    ?assert(MaxLatency < 1000000),  %% < 1 second

    %% Calculate throughput (operations per second)
    TotalTimeUs = lists:sum(ToolLatencies),
    Throughput = case TotalTimeUs of
        0 -> 0;
        _ -> (TotalOps * 1000000) div TotalTimeUs
    end,

    io:format("~n=== Batch ~p: Roundtrip Latency ===~n", [?BATCH_ID]),
    io:format("  Total operations: ~p~n", [TotalOps]),
    io:format("  Avg latency: ~.2f ms~n", [AvgLatency / 1000]),
    io:format("  Min latency: ~.2f ms~n", [MinLatency / 1000]),
    io:format("  Max latency: ~.2f ms~n", [MaxLatency / 1000]),
    io:format("  Throughput: ~p req/s~n", [Throughput]),
    io:format("  Success rate: ~.2f%~n", [(SuccessCount / TotalOps) * 100]).

%%====================================================================
%% Test Case 7: Concurrent Operations (Load Test)
%%====================================================================

test_concurrent_operations() ->
    Clients = get(clients),
    ConcurrentOps = 10,  %% 10 concurrent ops per client

    StartTime = erlang:monotonic_time(microsecond),

    %% Spawn concurrent operations for all clients
    Results = lists:map(
        fun(#{pid := ClientPid}) ->
            spawn_monitor(fun() ->
                run_concurrent_ops(ClientPid, ConcurrentOps)
            end)
        end,
        Clients
    ),

    %% Wait for all concurrent operations to complete
    {CompleteCount, TimeoutCount} = wait_for_concurrent(Results, 0, 0),

    EndTime = erlang:monotonic_time(microsecond),
    TotalTime = EndTime - StartTime,

    %% Verify: All operations completed
    TotalConcurrentOps = ?TOTAL_CLIENTS * ConcurrentOps,
    ?assertEqual(TotalConcurrentOps, CompleteCount),

    %% Verify: No timeouts
    ?assertEqual(0, TimeoutCount),

    io:format("~n=== Batch ~p: Concurrent Operations ===~n", [?BATCH_ID]),
    io:format("  Total concurrent ops: ~p~n", [TotalConcurrentOps]),
    io:format("  Completed: ~p~n", [CompleteCount]),
    io:format("  Timeouts: ~p~n", [TimeoutCount]),
    io:format("  Total time: ~.2f ms~n", [TotalTime / 1000]).

run_concurrent_ops(ClientPid, Count) ->
    lists:foreach(
        fun(_) ->
            erlmcp_client:list_tools(ClientPid),
            timer:sleep(rand:uniform(10))  %% Small random delay
        end,
        lists:seq(1, Count)
    ).

wait_for_concurrent([], CompleteAcc, TimeoutAcc) ->
    {CompleteAcc, TimeoutAcc};
wait_for_concurrent([{Pid, Ref} | Rest], CompleteAcc, TimeoutAcc) ->
    receive
        {'DOWN', Ref, process, Pid, normal} ->
            wait_for_concurrent(Rest, CompleteAcc + 1, TimeoutAcc);
        {'DOWN', Ref, process, Pid, _Reason} ->
            wait_for_concurrent(Rest, CompleteAcc, TimeoutAcc + 1)
    after 30000 ->  %% 30 second timeout
        exit(Pid, kill),
        wait_for_concurrent(Rest, CompleteAcc, TimeoutAcc + 1)
    end.

%%====================================================================
%% Test Case 8: Server Cleanup (Supervision)
%%====================================================================

test_server_cleanup() ->
    Servers = get(servers),

    %% Verify: All servers still alive after load test
    AliveServers = lists:filter(
        fun(#{pid := Pid}) -> is_process_alive(Pid) end,
        Servers
    ),
    ?assertEqual(?SERVER_COUNT, length(AliveServers)),

    io:format("~n=== Batch ~p: Server Cleanup ===~n", [?BATCH_ID]),
    io:format("  Servers still running: ~p/~p~n", [length(AliveServers), ?SERVER_COUNT]).

%%====================================================================
%% Helper Functions - Server Setup
%%====================================================================

add_calculator_tools(ServerPid) ->
    %% Add tool
    AddTool = #mcp_tool{
        name = <<"calculator_add">>,
        description = <<"Add two numbers">>,
        input_schema = #{
            type => <<"object">>,
            properties => #{
                a => #{type => <<"number">>},
                b => #{type => <<"number">>}
            },
            required => [<<"a">>, <<"b">>]
        }
    },
    AddHandler = fun(Args) ->
        A = maps:get(<<"a">>, Args, 0),
        B = maps:get(<<"b">>, Args, 0),
        jsx:encode(#{result => A + B})
    end,
    erlmcp_server:add_tool(ServerPid, AddTool, AddHandler),

    %% Subtract tool
    SubTool = #mcp_tool{
        name = <<"calculator_subtract">>,
        description = <<"Subtract two numbers">>,
        input_schema => #{
            type => <<"object">>,
            properties => #{
                a => #{type => <<"number">>},
                b => #{type => <<"number">>}
            },
            required => [<<"a">>, <<"b">>]
        }
    },
    SubHandler = fun(Args) ->
        A = maps:get(<<"a">>, Args, 0),
        B = maps:get(<<"b">>, Args, 0),
        jsx:encode(#{result => A - B})
    end,
    erlmcp_server:add_tool(ServerPid, SubTool, SubHandler),

    %% Multiply tool
    MulTool = #mcp_tool{
        name = <<"calculator_multiply">>,
        description = <<"Multiply two numbers">>,
        input_schema => #{
            type => <<"object">>,
            properties => #{
                a => #{type => <<"number">>},
                b => #{type => <<"number">>}
            },
            required => [<<"a">>, <<"b">>]
        }
    },
    MulHandler = fun(Args) ->
        A = maps:get(<<"a">>, Args, 0),
        B = maps:get(<<"b">>, Args, 0),
        jsx:encode(#{result => A * B})
    end,
    erlmcp_server:add_tool(ServerPid, MulTool, MulHandler),

    ok.

add_file_resources(ServerPid) ->
    %% Add file resource
    FileResource = #mcp_resource{
        uri = <<"file://test.txt">>,
        name = <<"Test File">>,
        description = <<"A test file resource">>,
        mime_type = <<"text/plain">>
    },
    FileHandler = fun(_Uri) ->
        #{
            contents => [
                #{
                    uri => <<"file://test.txt">>,
                    text => <<"Hello from MCP Server!">>
                }
            ]
        }
    end,
    erlmcp_server:add_resource(ServerPid, FileResource, FileHandler),

    ok.

add_hello_prompt(ServerPid) ->
    %% Add hello prompt
    HelloPrompt = #mcp_prompt{
        name = <<"hello">>,
        description = <<"Say hello to someone">>
    },
    HelloHandler = fun(Args) ->
        Name = maps:get(<<"name">>, Args, <<"World">>),
        [#{
            role => <<"user">>,
            content => #mcp_content{
                type = <<"text">>,
                text = <<"Hello, ", Name/binary, "!">>
            }
        }]
    end,
    Arguments = [
        #mcp_prompt_argument{
            name = <<"name">>,
            description => <<"Name to greet">>,
            required = false
        }
    ],
    erlmcp_server:add_prompt_with_args(ServerPid, HelloPrompt, HelloHandler, Arguments),

    ok.

%%====================================================================
%% Helper Functions - Statistics
%%====================================================================

print_latency_stats(Latencies) when length(Latencies) =:= 0 ->
    io:format("  No latency data~n");
print_latency_stats(Latencies) ->
    Sorted = lists:sort(Latencies),
    Count = length(Sorted),
    Avg = calculate_average(Latencies),
    Min = lists:min(Sorted),
    Max = lists:max(Sorted),
    P50 = lists:nth(max(1, trunc(Count * 0.50)), Sorted),
    P95 = lists:nth(max(1, trunc(Count * 0.95)), Sorted),
    P99 = lists:nth(max(1, trunc(Count * 0.99)), Sorted),

    io:format("  Latency (ms):~n"),
    io:format("    Avg: ~.2f~n", [Avg / 1000]),
    io:format("    Min: ~.2f~n", [Min / 1000]),
    io:format("    Max: ~.2f~n", [Max / 1000]),
    io:format("    P50: ~.2f~n", [P50 / 1000]),
    io:format("    P95: ~.2f~n", [P95 / 1000]),
    io:format("    P99: ~.2f~n", [P99 / 1000]).

calculate_average([]) ->
    0;
calculate_average(List) ->
    lists:sum(List) div length(List).

%%====================================================================
%% Final Report Generator
%%====================================================================

generate_batch1_report() ->
    Servers = get(servers),
    Clients = get(clients),
    ToolLatencies = get(tool_latencies),
    ToolSuccessCount = get(tool_success_count),
    ResourceSuccessCount = get(resource_success_count),
    PromptSuccessCount = get(prompt_success_count),

    TotalServers = length(Servers),
    TotalClients = length(Clients),
    TotalOps = length(ToolLatencies),
    SuccessCount = ToolSuccessCount,
    SuccessRate = (SuccessCount / TotalOps) * 100,

    AvgLatency = calculate_average(ToolLatencies),
    MinLatency = lists:min(ToolLatencies),
    MaxLatency = lists:max(ToolLatencies),

    TotalTimeUs = lists:sum(ToolLatencies),
    Throughput = case TotalTimeUs of
        0 -> 0;
        _ -> (TotalOps * 1000000) div TotalTimeUs
    end,

    io:format("~n"),
    io:format("=== Batch ~p Results (Servers 1-~p) ===~n", [?BATCH_ID, TotalServers]),
    io:format("Servers Spawned: ~p/~p~n", [TotalServers, ?SERVER_COUNT]),
    io:format("Clients Spawned: ~p/~p~n", [TotalClients, ?TOTAL_CLIENTS]),
    io:format("Operations: ~p/~p~n", [TotalOps, ?TOTAL_OPERATIONS]),
    io:format("Avg Latency: ~.2f ms~n", [AvgLatency / 1000]),
    io:format("Min Latency: ~.2f ms~n", [MinLatency / 1000]),
    io:format("Max Latency: ~.2f ms~n", [MaxLatency / 1000]),
    io:format("Throughput: ~p req/s~n", [Throughput]),
    io:format("Success Rate: ~.2f%~n", [SuccessRate]),
    io:format("Tool Operations: ~p successful~n", [ToolSuccessCount]),
    io:format("Resource Operations: ~p successful~n", [ResourceSuccessCount]),
    io:format("Prompt Operations: ~p successful~n", [PromptSuccessCount]),
    io:format("~n").

%%====================================================================
%% Standalone Test Runner (for direct execution)
%%====================================================================

run_batch1_test() ->
    eunit:test(?MODULE, [verbose]).
